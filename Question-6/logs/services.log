{"ok":true,"entities":[{"identifier":"cloud-developer","title":"cloud-developer","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# cloud-developer\ncontent for Udacity's cloud developer nanodegree\n","url":"https://github.com/toluwalase09/cloud-developer","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:14.997Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:14.997Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"udacity","title":"udacity","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# udacity\r\n\r\nUdagramdev-env.eba-vmf3pusp.us-east-1.elasticbeanstalk.com","url":"https://github.com/toluwalase09/udacity","language":"TypeScript","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.132Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.132Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"udagram-microservice-project-main","title":"udagram-microservice-project-main","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# udagram-microservice-project-main","url":"https://github.com/toluwalase09/udagram-microservice-project-main","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.139Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.139Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"results","title":"results","icon":null,"blueprint":"service","team":[],"properties":{"readme":"#decription\n# writting JSON file from the web to a file in your directories\n\nusing a fetch module of the node to get the json file \nwhile writting in streams to a file called posts.json\nthen piping the result to the respond\n","url":"https://github.com/toluwalase09/results","language":"JavaScript","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.139Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.139Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"SUCCESS","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":true},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Silver"}},"scorecardsStats":66.667,"scorecardsRuleCount":3},{"identifier":"tutoringApp","title":"tutoringApp","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# tutoringApp\nlearning node js\n","url":"https://github.com/toluwalase09/tutoringApp","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.177Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.177Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"developer-roadmap","title":"developer-roadmap","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/developer-roadmap","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.196Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.196Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"udacity-infracture-project","title":"udacity-infracture-project","icon":null,"blueprint":"service","team":[],"properties":{"readme":"load balancer link = http://serve-webap-qkvgb9f1w549-429379062.us-east-1.elb.amazonaws.com/\n","url":"https://github.com/toluwalase09/udacity-infracture-project","language":"Shell","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.215Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.215Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"30-Days-Of-JavaScript","title":"30-Days-Of-JavaScript","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/30-Days-Of-JavaScript","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.220Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.220Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"BenEaterVHDL","title":"BenEaterVHDL","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/BenEaterVHDL","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.256Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.256Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"learn-to-cloud","title":"learn-to-cloud","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# Welcome\n\n**[Web version here](https://learntocloud.guide)**\n\nThis is a guide based on our experiences getting into Cloud and DevOps. Once done, you should have the technical knowledge for roles like:\n\n- System administrator.\n- Cloud Support Engineer.\n- Cloud Administrator.\n\nYou can learn more about our journeys into cloud here:\n- [Rishab's journey from help desk to DevOps engineer without a degree](https://youtu.be/LZuWZ0SBYm8) \n- [Gwyn's journey from help desk to Cloud engineer without a degree](https://youtu.be/kluKaLXJ2lg)\n\nWe tried to keep it as general and using the most popular options (in terms of content, community, and jobs) as possible. The 6 month timeline is something we put in place to help people with planning and accountability. It may take you more or less time for each phase and if it does, that is completely fine.\n\n\n| Order | Topic                           | Time commitment |\n|-------|---------------------------------|-------------------|\n| [0](phase0/README.md)     | Start from zero tech experience  | optional \n| [1](phase1/README.md)     | Linux, Networking, and Scripting fundamentals | 4 weeks           |\n| [2](phase2/README.md)     | Programming fundamentals | 4 weeks           |\n| [3](phase3/README.md)    | Cloud Platform fundamentals| 8 weeks           |\n| [4](phase4/README.md)     | DevOps fundamentals         | 8 weeks           |\n\n\n\n\n### [Go to Phase 1: Linux and Networking fundamentals](phase1/README.md)\n","url":"https://github.com/toluwalase09/learn-to-cloud","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.276Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.276Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"crud_app","title":"crud_app","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# crud_app\n\nGET-ROUTE\nThis route was used to get all the JSON data from the mongo db and the data was viewed with postman \nthe find({}) method was used to select all the datas and the toArray() method was used to convert all object to array\n\nPOST-ROUTE\nThis route was used to deploy object from the server through the request\nit uses a insertone() method with the json object of the data being requested\n\nDELETE-ROUTE\nThis route was used to remove a json object from the mongo database\nit used a remove() method to delete the object from the database\n\n#HEROKU LINK\nhttps://dashboard.heroku.com/apps/stark-crag-34921\n","url":"https://github.com/toluwalase09/crud_app","language":"JavaScript","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.281Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.281Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"SUCCESS","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":true},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Silver"}},"scorecardsStats":66.667,"scorecardsRuleCount":3},{"identifier":"simple-node-travis","title":"simple-node-travis","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# Overview\nThis is a very simple, bare-bones NodeJS project created for you to use with Docker.\n\n# Local Setup\n* Install dependencies: `npm install`\n* Run server: `node server.js`\n\n# Container Setup\n* Build image: `docker build .`\n* Run container with image: `docker run {image_id}` where `image_id` can be retrieved by running `docker images` and found under the column `IMAGE ID`\n\n# Container teardown\n* Remove container: `docker kill {container_id}` where `container_id` can be retrieved by running `docker ps` and found under the column `CONTAINER ID`\n","url":"https://github.com/toluwalase09/simple-node-travis","language":"Dockerfile","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.308Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.308Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"bookstore","title":"bookstore","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# bookstore","url":"https://github.com/toluwalase09/bookstore","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.326Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.326Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"docker-flask-locust","title":"docker-flask-locust","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# docker-flask-locust\nA docker + flask + locust demo project\n\n[Flask + Locust YouTube Walkthrough](https://www.youtube.com/watch?v=bUEYe6AqlXE)\n\n\n![Screen Shot 2020-02-07 at 7 08 49 PM](https://user-images.githubusercontent.com/58792/74074716-65a2f580-49dd-11ea-943d-f91229a690ef.png)\n\n\n![Screen Shot 2020-02-07 at 7 12 18 PM](https://user-images.githubusercontent.com/58792/74074801-c7635f80-49dd-11ea-9273-a04b587bbc05.png)\n\n\n## This is one of my recipes in the upcoming book Cloud Computing for Data\n\n### [Cloud Computing for Data Analysis Book](https://leanpub.com/cloud4data)\nThis book is being written \"just in time\", with a weekly release schedule.\n\n![cloud4data books](https://d2sofvawe08yqg.cloudfront.net/cloud4data/hero2x?1578933644)\n","url":"https://github.com/toluwalase09/docker-flask-locust","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.360Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.360Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"prime_factor","title":"prime_factor","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/prime_factor","language":"Shell","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.361Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.361Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"nd9991-c3-hello-world-exercise-solution","title":"nd9991-c3-hello-world-exercise-solution","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# hello-world\n\n>**Before you proceed:** Fork this repository and set it up as a project in [CircleCI](https://app.circleci.com/projects/) dashboard. Feel free to submit PRs if you find any improvements. \n\n\nHere is the list of files and corresponding exercises. \n```bash\n├── ansible.cfg             ### 4. Exercise: Config and Deployment\n├── bucket.yml              ### 7. Exercise: Promote to Production\n├── cloudfront.yml\n├── error.html\n├── index.html\n├── inventory.txt           ### 2. Exercise: Remote Control Using Ansible\n├── main1.yml               ### 1. Classroom Demo: Design an Ansible Playbook \n├── main2.yml               ### 1. Exercise: Define Ansible Playbook \n├── main3.yml               ### 2. Classroom Demo: Remote Control Using Ansible\n├── main4.yml               ### 2. Exercise: Remote Control Using Ansible\n├── roles                   ### Ansible exercises\n│   ├── apache              ### 2. Classroom Demo: Remote Control Using Ansible\n│   │   ├── files\n│   │   │   └── index.html\n│   │   └── tasks\n│   │       └── main.yml\n│   ├── configure-server    ### 1. Classroom Demo: Design an Ansible Playbook \n│   │   └── tasks\n│   │       └── main.yml\n│   ├── prepare             ### 2. Classroom Demo: Remote Control Using Ansible\n│   │   └── tasks\n│   │       └── main.yml\n│   ├── print               ### 1. Exercise: Define Ansible Playbook \n│   │   └── tasks\n│   │       └── main.yml\n│   └── setup               ### 2. Exercise: Remote Control Using Ansible\n│       ├── files\n│       │   └── index.js\n│       └── tasks\n│           └── main.yml\n└── template.yml            ### 3. Exercise: Infrastructure Creation\n└── .circleci\n    └── config.yml          ### CircleCI exercises\n```\n\n> **Note**: When you attempt any CircleCI exercise, you should comment out the Jobs and Workflows from other exercises. This will ensure that you do not end up creating unnecessary EC2, S3, CloudFront resources in your AWS console. \n\n\n### 1. Exercise: Define Ansible Playbook\nFiles relevant for this exercise are:\n```bash\n├── main2.yml   # Playbook file\n└── roles\n    └── print\n        └── tasks\n            └── main.yml\n```\n\n### 2. Exercise: Remote Control Using Ansible\n**Prerequisite**: \n- A linux EC2 instance with port 3000 open for the inbound access. \n- Public IP address of an EC2 instance in your AWS account.\n- A key pair to connect your EC2 instance\n\nFiles relevant for this exercise are:\n```bash\n├── main4.yml     # Playbook file\n└── roles\n    └── setup\n        ├── files\n        │   └── index.js\n        └── tasks\n            └── main.yml\n```\n\n### 3. Exercise: Infrastructure Creation\nFiles relevant for this exercise are:\n```bash\n└── template.yml            # Change the KeyName property value, as applicable to you\n└── .circleci\n    └── config.yml          # Look for the create_infrastructure Job\n```\n\n\n### 4. Exercise: Config and Deployment\n**Prerequisite**: \n- Create an EC2 instance and note it's public IP address\n- Add the contents of your PEM file to the SSH keys in your Circle CI account to get the fingerprints\n\nFiles relevant for this exercise are:\n```bash        \n├── ansible.cfg             \n└── .circleci\n    └── config.yml          # Look for the configure_infrastructure Job\n```\n\n\n### 5. Exercise: Smoke Testing\nFiles relevant for this exercise are:\n```bash           \n└── .circleci\n    └── config.yml          # Look for the smoke_test Job\n```\n\n\n### 6. Exercise - Rollback\nFiles relevant for this exercise are:\n```bash    \n└── template.yml            # Change the KeyName property value, as applicable to you       \n└── .circleci\n    └── config.yml          # Look for the create_infrastructure Job and destroy_environment command. \n```\n\n\n### 7. Exercise: Promote to Production\n**Prerequisite**: \n- An S3 bucket (say `mybucket644752792305`) containing a sample `index.html` file created manually in your AWS console. \n- Enable the Static website hosting in that bucket.\n- Use the command below to create a  CloudFront Distribution\n```bash\n aws cloudformation deploy \\\n --template-file cloudfront.yml \\\n --stack-name production-distro \\\n --parameter-overrides PipelineID=\"mybucket644752792305\"\n ```\nFiles relevant for this exercise are:\n```bash  \n├── bucket.yml          # Creates a new bucket and bucket policy.       \n├── cloudfront.yml      # Creates a Cloudfront Distribution that will connect to the existing ^ bucket.\n├── error.html\n├── index.html  \n# Four Jobs: create_and_deploy_front_end, get_last_deployment_id, promote_to_production, and clean_up_old_front_end\n└── .circleci\n    └── config.yml\n```\n","url":"https://github.com/toluwalase09/nd9991-c3-hello-world-exercise-solution","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.385Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.385Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"circleci-demo-javascript-express","title":"circleci-demo-javascript-express","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# CircleCI Demo JavaScript/Express.js [![CircleCI](https://circleci.com/gh/CircleCI-Public/circleci-demo-javascript-express.svg?style=shield)](https://circleci.com/gh/CircleCI-Public/circleci-demo-javascript-express) [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)\n\nThis project was built from a MERN Starter  yh bkit (original URLs broken). Discussions still [active here](https://hashnode.com/n/mern). MERN is Mongo, Express, React and NodeJS.\n\nSee the [JavaScript language guide for CircleCI here](https://circleci.com/docs/2.0/language-javascript/).\n\n## Quickstart\n\n```\n  npm install -g mern-cli\n  mern init your_new_app\n  cd your_new_app\n  npm install\n  npm start\n```\n\n**Note : Please make sure your MongoDB is running.** For MongoDB installation guide see [this](https://docs.mongodb.org/v3.0/installation/). Also `npm3` is required to install dependencies properly.\n\n## Available Commands\n\n1. `npm run start` - starts the development server with hot reloading enabled\n\n2. `npm run bs` - bundles the code and starts the production server\n\n3. `npm run test` - start the test runner\n\n4. `npm run watch:test` - start the test runner with watch mode\n\n5. `npm run cover` - generates test coverage report\n\n6. `npm run lint` - runs linter to check for lint errors\n\n## File Structure\n\n### Webpack Configs\n\nMERN uses Webpack for bundling modules. There are four types of Webpack configs provided `webpack.config.dev.js` (for development), `webpack.config.prod.js` (for production), `webpack.config.server.js` (for bundling server in production) and `webpack.config.babel.js` (for [babel-plugin-webpack-loaders](https://github.com/istarkov/babel-plugin-webpack-loaders) for server rendering of assets included through webpack).\n\nThe Webpack configuration is minimal and beginner-friendly. You can customise and add more features to it for production build.\n\n### Server\n\nMERN uses express web framework. Our app sits in server.js where we check for NODE_ENV.\n\nIf NODE_ENV is development, we apply Webpack middlewares for bundling and Hot Module Replacement.\n\n#### Server Side Rendering\n\nWe use React Router's match function for handling all page requests so that browser history works.\n\nAll the routes are defined in `client/routes.js`. React Router renders components according to route requested.\n\n```js\n// Server Side Rendering based on routes matched by React-router.\napp.use((req, res) => {\n    match({\n        routes,\n        location: req.url\n    }, (err, redirectLocation, renderProps) => {\n        if (err) {\n            return res.status(500).end('Internal server error');\n        }\n\n        if (!renderProps) {\n            return res.status(404).end('Not found!');\n        }\n\n        const initialState = {\n            posts: [],\n            post: {}\n        };\n\n        const store = configureStore(initialState);\n\n        fetchComponentData(store.dispatch, renderProps.components, renderProps.params).then(() => {\n            const initialView = renderToString(\n                <Provider store = {store} >\n                  <RouterContext {...renderProps}/>\n                </Provider>\n            );\n\n            const finalState = store.getState();\n\n            res.status(200).end(renderFullPage(initialView, finalState));\n        }).catch(() => {\n            res.end(renderFullPage('Error', {}));\n        });\n    });\n});\n```\n\n`match` takes two parameters, first is an object that contains routes, location and history and second is a callback function which is called when routes have been matched to a location.\n\nIf there's an error in matching we return 500 status code, if no matches are found we return 404 status code. If a match is found then, we need to create a new Redux Store instance.\n\n**Note:** A new Redux Store has populated afresh on every request.\n\n`fetchComponentData` is the essential function. It takes three params: first is a dispatch function of Redux store, the second is an array of components that should be rendered in current route and third is the route params. `fetchComponentData` collects all the needs (need is an array of actions that are required to be dispatched before rendering the component) of components in the current route. It returns a promise when all the required actions are dispatched. We render the page and send data to the client for client-side rendering in `window.__INITIAL_STATE__`.\n\n### Client\n\nClient directory contains all the shared components, routes, modules.\n\n#### components\nThis folder contains all the common components which are used throughout the project.\n\n#### index.js\nIndex.js simply does client side rendering using the data provided from `window.__INITIAL_STATE__`.\n\n#### modules\nModules are the way of organising different domain-specific modules in the project. A typical module contains the following\n```\n| - Post\n  | - __tests__ // all the tests for this module goes here\n      | - components // Sub components of this module\n          | - Post.spec.js\n          | - PostList.spec.js\n          | - PostItem.spec.js\n          | - PostImage.spec.js\n      | - pages\n          | - PostPage.spec.js\n          | - PostViewPage.spec.js\n      | - PostReducer.spec.js\n      | - PostActions.spec.js\n  | - components // Sub components of this module\n      | - Post.js\n      | - PostList.js\n      | - PostItem.js\n      | - PostImage.js\n  | - pages // React Router Pages from this module\n      | - PostPage\n          | - PostPage.js\n          | - PostPage.css\n      | - PostViewPage\n          | - PostViewPage.js\n          | - PostViewPage.css\n  | - PostReducer.js\n  | - PostActions.js\n```\n\n## Misc\n\n### Importing Assets\nAssets can be kept where you want and can be imported into your js files or css files. Those fill be served by webpack in development mode and copied to the dist folder during production.\n\n### ES6 support\nWe use babel to transpile code in both server and client with `stage-0` plugin. So, you can use both ES6 and experimental ES7 features.\n\n### Docker\nThere are docker configurations for both development and production.\n\nTo run docker for development,\n```\ndocker-compose -f docker-compose-development.yml build\ndocker-compose -f docker-compose-development.yml up\n```\n\nTo run docker for production,\n```\ndocker-compose build\ndocker-compose up\n```\n\n### Make your MERN\nIn this version, we enabled the `mern-cli` to clone not only this project but also the variants of `mern-starter` like one project with MaterialUI or JWT auth. To make your version of MERN, follow these steps\n\n1. Clone this project\n    ```\n    git clone https://github.com/Hashnode/mern-starter\n    ```\n\n2. Make your changes. Add a package, add authentication, modify the file structure, replace Redux with MobX or anything else.\n\n3. In this version, we also added code generators. Blueprints for those generators are located at `config/blueprints`, and config is located at `mern.json`. Make sure to edit them if necessary after your made modifications in the previous step. There is a section below which explains how to modify generators.\n\n4. Next clone `mern-cli` project\n    ```\n    git clone https://github.com/Hashnode/mern-cli\n    ```\n\n5. Add your project details to `variants.json` in the cloned project and send a pull request.\n\n### Modifying Generators\n\n#### mern.json\nIt contains a blueprints array. Each object in it is the config for a generator. A blueprint config contains the name, description, usage, and files array. An example blueprint config\n```\n{\n  \"name\": \"dumb-s\",\n  \"description\": \"Generates a dumb react component in shared components\",\n  \"usage\": \"dumb-s [component-name]\",\n  \"files\": [\n    {\n      \"blueprint-path\": \"config/blueprints/dumb-component.ejs\",\n      \"target-path\": \"client/components/<%= helpers.capitalize(name) %>.js\"\n    }\n  ]\n}\n```\n\nA file object contains\n\n1. `blueprint-path` - location of the blueprint file\n\n2. `target-path` - location where the file should be generated\n\n3. `parent-path` - optional parameter, used if you want to generate the file inside an already existing folder in your project.\n\nAlso, `target-path` supports [ejs](https://github.com/mde/ejs) and the following variables will be passed while rendering,\n\n1. `name` - `<component-name>` input from user\n\n2. `parent` - in particular special cases where you need to generate files inside an already existing folder, you can obtain this parent variable from the user. A config using that will look like,\n    ```\n    {\n      \"name\": \"dumb-m\",\n      \"description\": \"Generates a dumb react component in a module directory\",\n      \"usage\": \"dumb-m <module-name>/<component-name>\",\n      \"files\": [\n        {\n          \"blueprint-path\": \"config/blueprints/dumb-component.ejs\",\n          \"parent-path\": \"client/modules/<%= helpers.capitalize(parent) %>\",\n          \"target-path\": \"components/<%= helpers.capitalize(name) %>/<%= helpers.capitalize(name) %>.js\"\n        }\n      ]\n    }\n    ```\n    Here, notice the usage. In `<module-name>/<component-name>`, `<module-name>` will be passed as `parent` and `<component-name>` will be passed as `<name>`.\n\n3. `helpers` - an helper object is passed which include common utility functions. For now, it contains `capitalize`. If you want to add more, send a PR to [mern-cli](https://github.com/Hashnode/mern-cli).\n\n#### Blueprint files\nBlueprints are basically [ejs](https://github.com/mde/ejs) templates which are rendered with the same three variables(`name`, optional `parent` and `helpers` object) as above.\n\n### Caveats\n\n#### FOUC (Flash of Unstyled Content)\nTo make the hot reloading of CSS work, we are not extracting CSS in development. Ideally, during server rendering, we will be extracting CSS, and we will get a .css file, and we can use it in the html template. That's what we are doing in production.\n\nIn development, after all scripts get loaded, react loads the CSS as BLOBs. That's why there is a second of FOUC in development.\n\n#### Client and Server Markup Mismatch\nThis warning is visible only on development and totally harmless. This occurs to hash difference in `react-router`. To solve it, react router docs asks you to use `match` function. If we use `match`, `react-hot-reloader` stops working.\n\n## License\nMERN is released under the [MIT License](http://www.opensource.org/licenses/MIT).\n","url":"https://github.com/toluwalase09/circleci-demo-javascript-express","language":"JavaScript","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.385Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.385Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"SUCCESS","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":true},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Silver"}},"scorecardsStats":66.667,"scorecardsRuleCount":3},{"identifier":"my-CICD-app","title":"my-CICD-app","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/my-CICD-app","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.505Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.505Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"cdond-c3-projectstarter","title":"cdond-c3-projectstarter","icon":null,"blueprint":"service","team":[],"properties":{"readme":"We are archiving this repository because we do not want learners to push personal development to the current repository. If you have any issues or suggestions to make, feel free to:\n- Utilize the https://knowledge.udacity.com/ forum to seek help on content-specific issues.\n- [Submit a support ticket](https://udacity.zendesk.com/hc/en-us/requests/new) along with the link to your forked repository. \n- If you are an enterprise learner, please [Submit a support ticket here](https://udacityenterprise.zendesk.com/hc/en-us/requests/new?ticket_form_id=360000279131)\n\n## Give your Application Auto-Deploy Superpowers\n\nIn this project, you will prove your mastery of the following learning objectives:\n\n- Explain the fundamentals and benefits of CI/CD to achieve, build, and deploy automation for cloud-based software products.\n- Utilize Deployment Strategies to design and build CI/CD pipelines that support Continuous Delivery processes.\n- Utilize a configuration management tool to accomplish deployment to cloud-based servers.\n- Surface critical server errors for diagnosis using centralized structured logging.\n\n![Diagram of CI/CD Pipeline we will be building.](udapeople.png)\n\n### Instructions\n\n* [Selling CI/CD](instructions/0-selling-cicd.md)\n* [Getting Started](instructions/1-getting-started.md)\n* [Deploying Working, Trustworthy Software](instructions/2-deploying-trustworthy-code.md)\n* [Configuration Management](instructions/3-configuration-management.md)\n* [Turn Errors into Sirens](instructions/4-turn-errors-into-sirens.md)\n\n### Project Submission\n\nFor your submission, please submit the following:\n\n- A text file named `urls.txt` including:\n  1. Public Url to GitHub repository (not private) [URL01]\n  1. Public URL for your S3 Bucket (aka, your green candidate front-end) [URL02]\n  1. Public URL for your CloudFront distribution (aka, your blue production front-end) [URL03]\n  1. Public URLs to deployed application back-end in EC2 [URL04]\n  1. Public URL to your Prometheus Server [URL05]\n- Your screenshots in JPG or PNG format, named using the screenshot number listed in the instructions. These screenshots should be included in your code repository in the root folder.\n  1. Job failed because of compile errors. [SCREENSHOT01]\n  1. Job failed because of unit tests. [SCREENSHOT02]\n  1. Job that failed because of vulnerable packages. [SCREENSHOT03]\n  1. An alert from one of your failed builds. [SCREENSHOT04]\n  1. Appropriate job failure for infrastructure creation. [SCREENSHOT05]\n  1. Appropriate job failure for the smoke test job. [SCREENSHOT06]\n  1. Successful rollback after a failed smoke test. [SCREENSHOT07]  \n  1. Successful promotion job. [SCREENSHOT08]\n  1. Successful cleanup job. [SCREENSHOT09]\n  1. Only deploy on pushed to `master` branch. [SCREENSHOT10]\n  1. Provide a screenshot of a graph of your EC2 instance including available memory, available disk space, and CPU usage. [SCREENSHOT11]\n  1. Provide a screenshot of an alert that was sent by Prometheus. [SCREENSHOT12]\n\n- Your presentation should be in PDF format named \"presentation.pdf\" and should be included in your code repository root folder. \n\nBefore you submit your project, please check your work against the project rubric. If you haven’t satisfied each criterion in the rubric, then revise your work so that you have met all the requirements. \n\n### Built With\n\n- [Circle CI](www.circleci.com) - Cloud-based CI/CD service\n- [Amazon AWS](https://aws.amazon.com/) - Cloud services\n- [AWS CLI](https://aws.amazon.com/cli/) - Command-line tool for AWS\n- [CloudFormation](https://aws.amazon.com/cloudformation/) - Infrastrcuture as code\n- [Ansible](https://www.ansible.com/) - Configuration management tool\n- [Prometheus](https://prometheus.io/) - Monitoring tool\n\n### License\n\n[License](LICENSE.md)\n","url":"https://github.com/toluwalase09/cdond-c3-projectstarter","language":"TypeScript","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.519Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.519Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"Ansible_lab_1","title":"Ansible_lab_1","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/Ansible_lab_1","language":"HTML","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.541Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.541Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"circleciproj","title":"circleciproj","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# circleciproj","url":"https://github.com/toluwalase09/circleciproj","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.562Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.562Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"DevOps_Microservices","title":"DevOps_Microservices","icon":null,"blueprint":"service","team":[],"properties":{"readme":"## Cloud DevOps ND - C4- Microservices at Scale using AWS & Kubernetes - Supporting Material and Project Starter\n\nThis repository is associated with Cloud DevOps ND - Course 04 - Microservices at Scale using AWS & Kubernetes. In here, you'll find:\n1. Supporting material used in the video demonstration in the course \n1. Starting code for a project, in which you can containerize and deploy a machine learning srevice using Kubernetes.\n\n---\n\n### A. Dependencies\n#### A.1. Python\n[Download and install the python](https://www.python.org/downloads/). \n\n#### A.2. Docker Desktop\nYou would require you to install Docker Desktop to create containers for individual microservices. Refer the following links for instructions \n* [macOS](https://docs.docker.com/docker-for-mac/install/), \n* [Windows 10 64-bit: Pro, Enterprise, or Education](https://docs.docker.com/docker-for-windows/install/), \n* [Windows  10 64-bit Home](https://docs.docker.com/toolbox/toolbox_install_windows/). \n* You can find installation instructions for other operating systems at:  https://docs.docker.com/install/\n\n#### A.3. Kubernetes \nYou would need to install any one tool for creating a Kubernetes cluster - KubeOne / Minikube / kubectl on top of Docker Desktop:\n1. [Install and Set Up kubectl](https://kubernetes.io/docs/tasks/tools/install-kubectl/) directly on top of Docker desktop - For Windows/macOS\n2. [Install Minikube](https://kubernetes.io/docs/tasks/tools/install-minikube/) - For Linux/macOS\n\n#### A.4. AWS account to access AWS Lambda\nYou'll need an [AWS account](https://aws.amazon.com/free/?all-free-tier.&all-free-tier.sort-by=item.additionalFields.SortRank&all-free-tier.sort-order=asc) to get started with [AWS Lambda](https://aws.amazon.com/lambda/), which is a serverless computing platform on cloud.  \n\n#### A.5. An account with Circle CI\nYou may sign up on [CircleCI.com](https://circleci.com/signup/) with your GitHub credentials. \n\n---\n\n### B. The Overarching Diagram\n\n![Overview](https://camo.githubusercontent.com/bb29cd924f9eb66730bbf7b0ed069a6ae03d2f1a/68747470733a2f2f757365722d696d616765732e67697468756275736572636f6e74656e742e636f6d2f35383739322f35353335343438332d62616537616638302d353437612d313165392d393930392d6135363231323531303635622e706e67)\n\n---\n\n### C. Tutorials\n\n#### C.1. AWS Lambda & Serverless\n\n* [Making Change](https://github.com/udacity/DevOps_Microservices/tree/master/lambda-functions/make-change-tutorial): Create and deploy a serverless lambda function that responds to an input request; this example creates the correct amount of change to make up a value in US dollars.\n* [Wikipedia Query](https://github.com/udacity/DevOps_Microservices/tree/master/lambda-functions/wikipedia-query): Deploy a lambda function that responds to an input, wikipedia page query; this example returns the first sentence of a specific wikipedia page upon being queried.\n\n\n### D. Project Instructions\n\n* [Operationalize a Machine Learning Microservice API](https://github.com/udacity/DevOps_Microservices/tree/master/project-ml-microservice-kubernetes): Deploy a containerized, machine learning application using Kubernetes.\n\nTo run any project code, you'll have to set up a virtual environment with the project dependencies. All of the following instructions are to be completed via a terminal/command line prompt. \n\n### E. Create and Activate an Environment\n\n#### E.1. Git and version control\nThese instructions also assume you have `git` installed for working with Github from a terminal window, but if you do not, you can download that first from this [Github installation page](https://www.atlassian.com/git/tutorials/install-git).\n\n**Now, you're ready to create your local environment!**\n\n1. If you haven't already done so, clone the project repository, and navigate to the main project folder. \n```bash\ngit clone https://github.com/udacity/DevOps_Microservices.git\ncd DevOps_Microservices/project-ml-microservice-kubernetes\n```\n\n2. Create (and activate) a new environment, named `.devops` with Python 3. If prompted to proceed with the install `(Proceed [y]/n)` type y.\n```bash\npython3 -m venv ~/.devops\nsource ~/.devops/bin/activate\n```\n\nAt this point your command line should look something like: `(.devops) <User>:project-ml-microservice-kubernetes<user>$`. The `(.devops)` indicates that your environment has been activated, and you can proceed with further package installations.\n\n3. Installing dependencies via project `Makefile`. Many of the project dependencies are listed in the file `requirements.txt`; these can be installed using `pip` commands in the provided `Makefile`. While in your project directory, type the following command to install these dependencies.\n```bash\nmake install\n```\n\nNow most of the `.devops` libraries are available to you. There are a couple of other libraries that we'll be using, which can be downloaded as specified, below. \n\n---\n\n#### E.2. Other Libraries\n\nWhile you still have your `.devops` environment activated, you will still need to install:\n* Docker\n* Hadolint\n* Kubernetes ([Minikube](https://kubernetes.io/docs/tasks/tools/install-minikube/) if you want to run Kubernetes locally)\n\n#### E.3. Docker\n\nYou will need to use Docker to build and upload a containerized application. If you already have this installed and created a docker account, you may skip this step.\n\n1. You’ll need to [create a free docker account](https://hub.docker.com/signup), where you’ll choose a unique username and link your email to a docker account. **Your username is your unique docker ID.**\n\n2. To install the latest version of docker, choose the Community Edition (CE) for your operating system, [on docker’s installation site](https://docs.docker.com/v17.12/install/). It is also recommended that you install the latest, **stable** release:\n\n3. After installation, you can verify that you’ve successfully installed docker by printing its version in your terminal: `docker --version`\n\n#### E.4. Run Lint Checks\n\nThis project also must pass two lint checks; `hadolint` checks the Dockerfile for errors and `pylint` checks the `app.py` source code for errors.\n\n1. Install `hadolint` following the instructions, [on hadolint's page]( https://github.com/hadolint/hadolint): \n\n**For Mac:**\n```bash\nbrew install hadolint\n```\n**For Windows:**\n```bash\nscoop install hadolint\n```\n2. In your terminal, type: `make lint` to run lint checks on the project code. If you haven’t changed any code, all requirements should be satisfied, and you should see a printed statement that rates your code (and prints out any additional comments):\n\n```bash\n------------------------------------\nYour code has been rated at 10.00/10\n```\n\nThat's about it! When working with kubernetes, you may need to install some other libraries, but these instructions will set you up with an environment that can build and deploy Docker containers.\n\n","url":"https://github.com/toluwalase09/DevOps_Microservices","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.593Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.593Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"devops-master-class","title":"devops-master-class","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/devops-master-class","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.600Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.600Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"90DaysOfDevOps","title":"90DaysOfDevOps","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# 90DaysOfDevOps\n\n<p align=\"center\">\n <img src=\"logo.png?raw=true\" alt=\"90DaysOfDevOps Logo\" width=\"50%\" height=\"50%\" />\n</p>\n\nEnglish Version | [中文版本](zh_cn/README.md) | [繁體中文版本](zh_tw/README.md)| [日本語版](ja/README.md) | [Wersja Polska](pl/README.md)\n\nThis repository is used to document my journey on getting a better foundational knowledge of \"DevOps\". I will be starting this journey on the 1st January 2022 but the idea is that we take 90 days which just so happens to be January 1st to March 31st.\n\nThe reason for documenting these days is so that others can take something from it and also hopefully enhance the resources.\n\nThe goal is to take 90 days, 1 hour each a day, to tackle over 13 areas of \"DevOps\" to a foundational knowledge.\n\nThis will **not cover all things** \"DevOps\" but it will cover the areas that I feel will benefit my learning and understanding overall.\n\n[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/N4N33YRCS)\n\nThe quickest way to get in touch is going to be via Twitter, my handle is [@MichaelCade1](https://twitter.com/MichaelCade1)\n\n## Progress\n\n- [✔️] ♾️ 1 > [Introduction](Days/day01.md)\n\n### What is and why do we use DevOps\n\n- [✔️] ♾️ 2 > [Responsibilities of a DevOps Engineer](Days/day02.md)\n- [✔️] ♾️ 3 > [DevOps Lifecycle - Application Focused](Days/day03.md)\n- [✔️] ♾️ 4 > [DevOps & Agile](Days/day04.md)\n- [✔️] ♾️ 5 > [Plan > Code > Build > Testing > Release > Deploy > Operate > Monitor >](Days/day05.md)\n- [✔️] ♾️ 6 > [DevOps - The real stories](Days/day06.md)\n\n### Learning a Programming Language\n\n- [✔️] ⌨️ 7 > [The Big Picture: DevOps & Learning a Programming Language](Days/day07.md)\n- [✔️] ⌨️ 8 > [Setting up your DevOps environment for Go & Hello World](Days/day08.md)\n- [✔️] ⌨️ 9 > [Let's explain the Hello World code](Days/day09.md)\n- [✔️] ⌨️ 10 > [The Go Workspace & Compiling & running code](Days/day10.md)\n- [✔️] ⌨️ 11 > [Variables, Constants & Data Types](Days/day11.md)\n- [✔️] ⌨️ 12 > [Getting user input with Pointers and a finished program](Days/day12.md)\n- [✔️] ⌨️ 13 > [Tweet your progress with our new App](Days/day13.md)\n\n### Knowing Linux Basics\n\n- [✔️] 🐧 14 > [The Big Picture: DevOps and Linux](Days/day14.md)\n- [✔️] 🐧 15 > [Linux Commands for DevOps (Actually everyone)](Days/day15.md)\n- [✔️] 🐧 16 > [Managing your Linux System, Filesystem & Storage](Days/day16.md)\n- [✔️] 🐧 17 > [Text Editors - nano vs vim](Days/day17.md)\n- [✔️] 🐧 18 > [SSH & Web Server(LAMP)](Days/day18.md)\n- [✔️] 🐧 19 > [Automate tasks with bash scripts](Days/day19.md)\n- [✔️] 🐧 20 > [Dev workstation setup - All the pretty things](Days/day20.md)\n\n### Understand Networking\n\n- [✔️] 🌐 21 > [The Big Picture: DevOps and Networking](Days/day21.md)\n- [✔️] 🌐 22 > [The OSI Model - The 7 Layers](Days/day22.md)\n- [✔️] 🌐 23 > [Network Protocols](Days/day23.md)\n- [✔️] 🌐 24 > [Network Automation](Days/day24.md)\n- [✔️] 🌐 25 > [Python for Network Automation](Days/day25.md)\n- [✔️] 🌐 26 > [Building our Lab](Days/day26.md)\n- [✔️] 🌐 27 > [Getting Hands-On with Python & Network](Days/day27.md)\n\n### Stick to one Cloud Provider\n\n- [✔️] ☁️ 28 > [The Big Picture: DevOps & The Cloud](Days/day28.md)\n- [✔️] ☁️ 29 > [Microsoft Azure Fundamentals](Days/day29.md)\n- [✔️] ☁️ 30 > [Microsoft Azure Security Models](Days/day30.md)\n- [✔️] ☁️ 31 > [Microsoft Azure Compute Models](Days/day31.md)\n- [✔️] ☁️ 32 > [Microsoft Azure Storage & Database Models](Days/day32.md)\n- [✔️] ☁️ 33 > [Microsoft Azure Networking Models + Azure Management](Days/day33.md)\n- [✔️] ☁️ 34 > [Microsoft Azure Hands-On Scenarios](Days/day34.md)\n\n### Use Git Effectively\n\n- [✔️] 📚 35 > [The Big Picture: Git - Version Control](Days/day35.md)\n- [✔️] 📚 36 > [Installing & Configuring Git](Days/day36.md)\n- [✔️] 📚 37 > [Gitting to know Git](Days/day37.md)\n- [✔️] 📚 38 > [Staging & Changing](Days/day38.md)\n- [✔️] 📚 39 > [Viewing, unstaging, discarding & restoring](Days/day39.md)\n- [✔️] 📚 40 > [Social Network for code](Days/day40.md)\n- [✔️] 📚 41 > [The Open Source Workflow](Days/day41.md)\n\n### Containers\n\n- [✔️] 🏗️ 42 > [The Big Picture: Containers](Days/day42.md)\n- [✔️] 🏗️ 43 > [What is Docker & Getting installed](Days/day43.md)\n- [✔️] 🏗️ 44 > [Docker Images & Hands-On with Docker Desktop](Days/day44.md)\n- [✔️] 🏗️ 45 > [The anatomy of a Docker Image](Days/day45.md)\n- [✔️] 🏗️ 46 > [Docker Compose](Days/day46.md)\n- [✔️] 🏗️ 47 > [Docker Networking & Security](Days/day47.md)\n- [✔️] 🏗️ 48 > [Alternatives to Docker](Days/day48.md)\n\n### Kubernetes\n\n- [✔️] ☸ 49 > [The Big Picture: Kubernetes](Days/day49.md)\n- [✔️] ☸ 50 > [Choosing your Kubernetes platform](Days/day50.md)\n- [✔️] ☸ 51 > [Deploying your first Kubernetes Cluster](Days/day51.md)\n- [✔️] ☸ 52 > [Setting up a multinode Kubernetes Cluster](Days/day52.md)\n- [✔️] ☸ 53 > [Rancher Overview - Hands On](Days/day53.md)\n- [✔️] ☸ 54 > [Kubernetes Application Deployment](Days/day54.md)\n- [✔️] ☸ 55 > [State and Ingress in Kubernetes](Days/day55.md)\n\n### Learn Infrastructure as Code\n\n- [✔️] 🤖 56 > [The Big Picture: IaC](Days/day56.md)\n- [✔️] 🤖 57 > [An intro to Terraform](Days/day57.md)\n- [✔️] 🤖 58 > [HashiCorp Configuration Language (HCL)](Days/day58.md)\n- [✔️] 🤖 59 > [Create a VM with Terraform & Variables](Days/day59.md)\n- [✔️] 🤖 60 > [Docker Containers, Provisioners & Modules](Days/day60.md)\n- [✔️] 🤖 61 > [Kubernetes & Multiple Environments](Days/day61.md)\n- [✔️] 🤖 62 > [Testing, Tools & Alternatives](Days/day62.md)\n\n### Automate Configuration Management\n\n- [✔️] 📜 63 > [The Big Picture: Configuration Management](Days/day63.md)\n- [✔️] 📜 64 > [Ansible: Getting Started](Days/day64.md)\n- [✔️] 📜 65 > [Ansible Playbooks](Days/day65.md)\n- [✔️] 📜 66 > [Ansible Playbooks Continued...](Days/day66.md)\n- [✔️] 📜 67 > [Using Roles & Deploying a Loadbalancer](Days/day67.md)\n- [✔️] 📜 68 > [Tags, Variables, Inventory & Database Server config](Days/day68.md)\n- [✔️] 📜 69 > [All other things Ansible - Automation Controller, AWX, Vault](Days/day69.md)\n\n### Create CI/CD Pipelines\n\n- [✔️] 🔄 70 > [The Big Picture: CI/CD Pipelines](Days/day70.md)\n- [✔️] 🔄 71 > [What is Jenkins?](Days/day71.md)\n- [✔️] 🔄 72 > [Getting hands on with Jenkins](Days/day72.md)\n- [✔️] 🔄 73 > [Building a Jenkins pipeline](Days/day73.md)\n- [✔️] 🔄 74 > [Hello World - Jenkinsfile App Pipeline](Days/day74.md)\n- [✔️] 🔄 75 > [GitHub Actions Overview](Days/day75.md)\n- [✔️] 🔄 76 > [ArgoCD Overview](Days/day76.md)\n\n### Monitoring, Log Management, and Data Visualisation\n\n- [✔️] 📈 77 > [The Big Picture: Monitoring](Days/day77.md)\n- [✔️] 📈 78 > [Hands-On Monitoring Tools](Days/day78.md)\n- [✔️] 📈 79 > [The Big Picture: Log Management](Days/day79.md)\n- [✔️] 📈 80 > [ELK Stack](Days/day80.md)\n- [✔️] 📈 81 > [Fluentd & FluentBit](Days/day81.md)\n- [✔️] 📈 82 > [EFK Stack](Days/day82.md)\n- [✔️] 📈 83 > [Data Visualisation - Grafana](Days/day83.md)\n\n### Store & Protect Your Data\n\n- [✔️] 🗃️ 84 > [The Big Picture: Data Management](Days/day84.md)\n- [✔️] 🗃️ 85 > [Data Services](Days/day85.md)\n- [✔️] 🗃️ 86 > [Backup all the platforms](Days/day86.md)\n- [✔️] 🗃️ 87 > [Hands-On Backup & Recovery](Days/day87.md)\n- [✔️] 🗃️ 88 > [Application Focused Backups](Days/day88.md)\n- [✔️] 🗃️ 89 > [Disaster Recovery](Days/day89.md)\n- [✔️] 🗃️ 90 > [Data & Application Mobility](Days/day90.md)\n\n## License\n\nShield: [![CC BY-NC-SA 4.0][cc-by-nc-sa-shield]][cc-by-nc-sa]\n\nThis work is licensed under a\n[Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License][cc-by-nc-sa].\n\n[![CC BY-NC-SA 4.0][cc-by-nc-sa-image]][cc-by-nc-sa]\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=MichaelCade/90DaysOfDevOps&type=Timeline)](https://star-history.com/#MichaelCade/90DaysOfDevOps&Timeline)\n\n[cc-by-nc-sa]: http://creativecommons.org/licenses/by-nc-sa/4.0/\n[cc-by-nc-sa-image]: https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png\n[cc-by-nc-sa-shield]: https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg\n","url":"https://github.com/toluwalase09/90DaysOfDevOps","language":"Shell","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.612Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.612Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"DevOps-Lifecycle","title":"DevOps-Lifecycle","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/DevOps-Lifecycle","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.630Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.630Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"Scalable-and-Secure-Web-Application-Architecture","title":"Scalable-and-Secure-Web-Application-Architecture","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/Scalable-and-Secure-Web-Application-Architecture","language":"HCL","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:16.337Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:16.337Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"CFN-GUARD-naming-convention","title":"CFN-GUARD-naming-convention","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# CFN-GUARD\nInvestigate the use of Cloud Formation Guard for the automation of Naming Convention check\n\nnaming convention standard for S3 bucket and values\nBUCKET NAMINGBelow are the S3 buckets which will be created for the EDB. Buckets in the production environment have the region identified (such as the string us-east-2) in its name to enable cross region replication as needed for certain use cases. At this time, cross region replication is not in use.The naming convention followed is <Company>-<ProgramName>-<EnrichmentLevel>-<Region>-<Environment>\nWhere:\nCompany = lly\nProgramName = edb\nEnrichmentLevel\nraw\nrefined\nlanding\nconformed\nexploratory\nlog\ncodeconfig\nArchival\nAthena Results\nWebhosting (Different name for each website)\nRegion – one of the Lilly AWS regions\nExample: us-east-2\nEnvironment = one of the following\ndev\nqa\nprod\n\nInvestigate extraction of S3 bucket from template\n\n  \n  sample code template with in comement of RITM\n  !sub arn:aws:s3:::lly-edp-refined-us-east-2-${pBucketPrefix}/gss_ephub/* #R1TM3662644\n\nRecommedation from jason\nBased on the naming conventions we want to enforce this can potentially be handled by CloudFormation Guard. That should help support most situations, the key is knowing exactly which resources to enforce requirements\n","url":"https://github.com/toluwalase09/CFN-GUARD-naming-convention","language":"Python","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.630Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.630Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"SUCCESS","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":true},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Silver"}},"scorecardsStats":66.667,"scorecardsRuleCount":3},{"identifier":"udacityproject4","title":"udacityproject4","icon":null,"blueprint":"service","team":[],"properties":{"readme":"![toluwalase09](https://circleci.com/gh/toluwalase09/udacityproject4.svg?style=svg)(https://app.circleci.com/pipelines/github/toluwalase09/udacityproject4)\n\n## Project Overview\nThe Operationalize ML project contains a Machine Learning Microservice, built on Scikit-Learn. It contains a model that predicts house prices in Boston according to several features, such as average rooms in a home and data about highway access, teacher-to-pupil ratios, and so on\nIt was deployed and tested through docker and kubernettes \na requirement.txt file which contain all the dependencies for the project to be fully functional and was installed with a maker file\n\nIn this project, you will apply the skills you have acquired in this course to operationalize a Machine Learning Microservice API. \n\nYou are given a pre-trained, `sklearn` model that has been trained to predict housing prices in Boston according to several features, such as average rooms in a home and data about highway access, teacher-to-pupil ratios, and so on. You can read more about the data, which was initially taken from Kaggle, on [the data source site](https://www.kaggle.com/c/boston-housing). This project tests your ability to operationalize a Python flask app—in a provided file, `app.py`—that serves out predictions (inference) about housing prices through API calls. This project could be extended to any pre-trained machine learning model, such as those for image recognition and data labeling.\n\n### Project Tasks\n\nYour project goal is to operationalize this working, machine learning microservice using [kubernetes](https://kubernetes.io/), which is an open-source system for automating the management of containerized applications. In this project you will:\n* Test your project code using linting\n* Complete a Dockerfile to containerize this application\n* Deploy your containerized application using Docker and make a prediction\n* Improve the log statements in the source code for this application\n* Configure Kubernetes and create a Kubernetes cluster\n* Deploy a container using Kubernetes and make a prediction\n* Upload a complete Github repo with CircleCI to indicate that your code has been tested\n\nYou can find a detailed [project rubric, here](https://review.udacity.com/#!/rubrics/2576/view).\n\n**The final implementation of the project will showcase your abilities to operationalize production microservices.**\n\n---\n\n## Setup the Environment\n\n* Create a virtualenv with Python 3.7 and activate it. Refer to this link for help on specifying the Python version in the virtualenv. \n```bash\npython3 -m pip install --user virtualenv\n# You should have Python 3.7 available in your host. \n# Check the Python path using `which python3`\n# Use a command similar to this one:\npython3 -m virtualenv --python=<path-to-Python3.7> .devops\nsource .devops/bin/activate\n```\n* Run `make install` to install the necessary dependencies\n\n### Running `app.py`\n\n1. Standalone:  `python app.py`\n2. Run in Docker:  `./run_docker.sh`\n3. Run in Kubernetes:  `./run_kubernetes.sh`\n\n### Kubernetes Steps\n\n* Setup and Configure Docker locally\n* Setup and Configure Kubernetes locally\n* Create Flask app in Container\n* Run via kubectl\n","url":"https://github.com/toluwalase09/udacityproject4","language":"Python","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.642Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.642Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"SUCCESS","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":true},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Silver"}},"scorecardsStats":66.667,"scorecardsRuleCount":3},{"identifier":"devops-intern-test","title":"devops-intern-test","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# Rise Devops Internship Test\nWe just need to confirm you have what it takes. Good luck \n\n## Rules\n* Fork this repository, so it can stay on Github\n* Commit your changes after every task\n* When you finish, send us link to your repository and wait for an answer\n\n## Prerequisites\n- [Nginx Configs](https://www.nginx.com/)\n\n\n## Testing the application\nBring up a terminal, then go to your project root directory and install local dependencies:\n\n```yarn```\n\nTo start local dev server, type in the following command in your terminal:\n\n```yarn start```\n\nThe application should now be accessible on [http://localhost:3000](http://localhost:3000)\n\n### Task\nAssuming a server has been setup with the NodeJS app running, write an nginx config:\n- serve the HTML files in `public`\n- port-forward the API to the node server\n\n## Send us your repo!\nAfter finishing all tasks, reply the mail that sent you this repo with a link your repo.\n","url":"https://github.com/toluwalase09/devops-intern-test","language":"JavaScript","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.670Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.670Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"SUCCESS","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":true},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Silver"}},"scorecardsStats":66.667,"scorecardsRuleCount":3},{"identifier":"terraform-aws-foundation","title":"terraform-aws-foundation","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# The FP Complete AWS Foundation\n\nA modular, composable, extensible, framework for building secure, highly scalable\nplatforms on AWS. The framework leverages established best practices, modern\ntools and paradigms, supports the ops developer who needs to move fast while\nmaintaining stability, and does not forget how to support your legacy apps.\n\n\n## Project Goals\n\nThis project aims to be..\n\n* an extensible framework for the ops developer under (multiple dimensions\n  of) pressure\n* a highly-scalable and flexible implementation of modern distributed systems\n  architecture and paradigms\n* focused on security, maintainability, repeatability, reliability, and simple\n  but powerful workflows\n* a way for ops to deal with the ever-evolving nature of the ops-landscape,\n  while also continuing to support the legacy apps of yesteryear\n* an example, a reference stack for the ops developer to use in building their\n  own platform\n\n\n## Tools for Relevant Problems\n\nIn pursuit of those goals, the reusable modules documented here form a platform\nby leveraging the following tools:\n\n* [Terraform](https://terraform.io) - Orchestrates resources in the cloud,\n  declarative expression at the core of ops (network, node, cluster, service)\n* [Packer](https://packer.io) - Creates pre-baked VM images for nodes in our\n  network (with the tools we need)\n* [Amazon Auto-Scaling Groups](http://docs.aws.amazon.com/AutoScaling/latest/DeveloperGuide/WhatIsAutoScaling.html)\n- Robust platforms must be self-healing.\n* [Docker](https://docker.com) - Many services/applications run on the platform\n  will do so as docker containers (but not all, legacy apps are easily supported).\n* [Consul](https://consul.io),\n  [consul-template](https://github.com/hashicorp/consul-template),\n  [consulkv](https://github.com/spiritloose/consulkv) - For service discovery,\n  distributed key/value store, and simplifed automation and orchestration in the\n  distributed system.\n* [Vault](https://www.vaultproject.io/) - Managing secrets, short-lived\n  credentials, and TLS certificates, and auditing access to them all.\n* [Kubernetes](http://kubernetes.io/) - Scheduling and resource management for\n  containers.\n* [Nomad](http://nomadproject.io/) - Task scheduling for containers, linux\n  executables, and java applications.\n* [Saltstack](https://saltstack.com),\n  [saltstack-formulas](https://github.com/saltstack-formulas/),\n  [fpco-salt-formula](https://github.com/fpco/fpco-salt-formula),\n  [bootstrap-salt-formula](https://github.com/fpco/bootstrap-salt-formula) - Simple\n  and sane configuration management for nodes at runtime, fault-tolerant\n  (masterless) highly-expressive, and highly-scalable, with optional remote\n  execution to boot.\n\nAs the collection of modules is composable into an endless array of possibilities,\nthere is no explicit requirement to use all of these tools, you can just as easily\nuse the IAM management modules and nothing else, or build a more complete stack\nwith these modules.\n\n\n## Contributing, Issues, and Feature Requests\n\nPlease see [CONTRIBUTING.md](https://github.com/fpco/terraform-aws-foundation/blob/master/CONTRIBUTING.md) for \nmore information.\n","url":"https://github.com/toluwalase09/terraform-aws-foundation","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:16.073Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:16.073Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"robot-shop","title":"robot-shop","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# Sample Microservice Application\n\nStan's Robot Shop is a sample microservice application you can use as a sandbox to test and learn containerised application orchestration and monitoring techniques. It is not intended to be a comprehensive reference example of how to write a microservices application, although you will better understand some of those concepts by playing with Stan's Robot Shop. To be clear, the error handling is patchy and there is not any security built into the application.\n\nYou can get more detailed information from my [blog post](https://www.instana.com/blog/stans-robot-shop-sample-microservice-application/) about this sample microservice application.\n\nThis sample microservice application has been built using these technologies:\n- NodeJS ([Express](http://expressjs.com/))\n- Java ([Spring Boot](https://spring.io/))\n- Python ([Flask](http://flask.pocoo.org))\n- Golang\n- PHP (Apache)\n- MongoDB\n- Redis\n- MySQL ([Maxmind](http://www.maxmind.com) data)\n- RabbitMQ\n- Nginx\n- AngularJS (1.x)\n\nThe various services in the sample application already include all required Instana components installed and configured. The Instana components provide automatic instrumentation for complete end to end [tracing](https://docs.instana.io/core_concepts/tracing/), as well as complete visibility into time series metrics for all the technologies.\n\nTo see the application performance results in the Instana dashboard, you will first need an Instana account. Don't worry a [trial account](https://instana.com/trial?utm_source=github&utm_medium=robot_shop) is free.\n\n## Build from Source\nTo optionally build from source (you will need a newish version of Docker to do this) use Docker Compose. Optionally edit the `.env` file to specify an alternative image registry and version tag; see the official [documentation](https://docs.docker.com/compose/env-file/) for more information.\n\nTo download the tracing module for Nginx, it needs a valid Instana agent key. Set this in the environment before starting the build.\n\n```shell\n$ export INSTANA_AGENT_KEY=\"<your agent key>\"\n```\n\nNow build all the images.\n\n```shell\n$ docker-compose build\n```\n\nIf you modified the `.env` file and changed the image registry, you need to push the images to that registry\n\n```shell\n$ docker-compose push\n```\n\n## Run Locally\nYou can run it locally for testing.\n\nIf you did not build from source, don't worry all the images are on Docker Hub. Just pull down those images first using:\n\n```shell\n$ docker-compose pull\n```\n\nFire up Stan's Robot Shop with:\n\n```shell\n$ docker-compose up\n```\n\nIf you want to fire up some load as well:\n\n```shell\n$ docker-compose -f docker-compose.yaml -f docker-compose-load.yaml up\n```\n\nIf you are running it locally on a Linux host you can also run the Instana [agent](https://docs.instana.io/quick_start/agent_setup/container/docker/) locally, unfortunately the agent is currently not supported on Mac.\n\nThere is also only limited support on ARM architectures at the moment.\n\n## Marathon / DCOS\n\nThe manifests for robotshop are in the *DCOS/* directory. These manifests were built using a fresh install of DCOS 1.11.0. They should work on a vanilla HA or single instance install.\n\nYou may install Instana via the DCOS package manager, instructions are here: https://github.com/dcos/examples/tree/master/instana-agent/1.9\n\n## Kubernetes\nYou can run Kubernetes locally using [minikube](https://github.com/kubernetes/minikube) or on one of the many cloud providers.\n\nThe Docker container images are all available on [Docker Hub](https://hub.docker.com/u/robotshop/).\n\nInstall Stan's Robot Shop to your Kubernetes cluster using the [Helm](K8s/helm/README.md) chart.\n\nTo deploy the Instana agent to Kubernetes, just use the [helm](https://github.com/instana/helm-charts) chart.\n\n## Accessing the Store\nIf you are running the store locally via *docker-compose up* then, the store front is available on localhost port 8080 [http://localhost:8080](http://localhost:8080/)\n\nIf you are running the store on Kubernetes via minikube then, find the IP address of Minikube and the Node Port of the web service.\n\n```shell\n$ minikube ip\n$ kubectl get svc web\n```\n\nIf you are using a cloud Kubernetes / Openshift / Mesosphere then it will be available on the load balancer of that system.\n\n## Load Generation\nA separate load generation utility is provided in the `load-gen` directory. This is not automatically run when the application is started. The load generator is built with Python and [Locust](https://locust.io). The `build.sh` script builds the Docker image, optionally taking *push* as the first argument to also push the image to the registry. The registry and tag settings are loaded from the `.env` file in the parent directory. The script `load-gen.sh` runs the image, it takes a number of command line arguments. You could run the container inside an orchestration system (K8s) as well if you want to, an example descriptor is provided in K8s directory. For more details see the [README](load-gen/README.md) in the load-gen directory.\n\n## Website Monitoring / End-User Monitoring\n\n### Docker Compose\n\nTo enable Website Monioring / End-User Monitoring (EUM) see the official [documentation](https://docs.instana.io/website_monitoring/) for how to create a configuration. There is no need to inject the JavaScript fragment into the page, this will be handled automatically. Just make a note of the unique key and set the environment variable `INSTANA_EUM_KEY` and `INSTANA_EUM_REPORTING_URL` for the web image within `docker-compose.yaml`.\n\n### Kubernetes\n\nThe Helm chart for installing Stan's Robot Shop supports setting the key and endpoint url required for website monitoring, see the [README](K8s/helm/README.md).\n\n## Prometheus\n\nThe cart and payment services both have Prometheus metric endpoints. These are accessible on `/metrics`. The cart service provides:\n\n* Counter of the number of items added to the cart\n\nThe payment services provides:\n\n* Counter of the number of items perchased\n* Histogram of the total number of items in each cart\n* Histogram of the total value of each cart\n\nTo test the metrics use:\n\n```shell\n$ curl http://<host>:8080/api/cart/metrics\n$ curl http://<host>:8080/api/payment/metrics\n```\n\n","url":"https://github.com/toluwalase09/robot-shop","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.646Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.646Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"Ansible_Assignment","title":"Ansible_Assignment","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/Ansible_Assignment","language":"JavaScript","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.666Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.666Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"SUCCESS","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":true},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"Hands-On-Infrastructure-Monitoring-with-Prometheus","title":"Hands-On-Infrastructure-Monitoring-with-Prometheus","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# Hands-On Infrastructure Monitoring with Prometheus \n\n<a href=\"https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus?utm_source=github&utm_medium=repository&utm_campaign=9781789612349\"><img src=\"https://www.packtpub.com/media/catalog/product/cache/e4d64343b1bc593f1c5348fe05efa4a6/b/1/b12751_mockupcover_1.png\" alt=\"Hands-On Infrastructure Monitoring with Prometheus \" height=\"256px\" align=\"right\"></a>\n\nThis is the code repository for [Hands-On Infrastructure Monitoring with Prometheus ](https://www.packtpub.com/virtualization-and-cloud/hands-infrastructure-monitoring-prometheus?utm_source=github&utm_medium=repository&utm_campaign=9781789612349), published by Packt.\n\n**Implement and scale queries, dashboards, and alerting across machines and containers**\n\n## What is this book about?\nPrometheus is an open source monitoring system. It provides a modern time series database, a robust query language, several metric visualization possibilities, and a reliable alerting solution for traditional and cloud-native infrastructure.\n\nThis book covers the following exciting features:\n- Grasp monitoring fundamentals and implement them using Prometheus \n- Discover how to extract metrics from common infrastructure services \n- Find out how to take full advantage of PromQL \n- Design a highly available, resilient, and scalable Prometheus stack \n- Explore the power of Kubernetes Prometheus Operator \n- Understand concepts such as federation and cross-shard aggregation \n- Unlock seamless global views and long-term retention in cloud-native apps with Thanos \n\nIf you feel this book is for you, get your [copy](https://www.amazon.com/dp/1789612349) today!\n\n<a href=\"https://www.packtpub.com/?utm_source=github&utm_medium=banner&utm_campaign=GitHubBanner\"><img src=\"https://raw.githubusercontent.com/PacktPublishing/GitHub/master/GitHub.png\" \nalt=\"https://www.packtpub.com/\" border=\"5\" /></a>\n\n## Instructions and Navigations\nAll of the code is organized into folders. For example, Chapter02.\n\nThe code will look like the following:\n```\nannotations:\n     description: \"Node exporter {{ .Labels.instance }} is down.\"\n     link: \"https://example.com\"\n```\n\n**Following is what you need for this book:**\nIf you’re a software developer, cloud administrator, site reliability engineer, DevOps enthusiast or system admin looking to set up a fail-safe monitoring and alerting system for sustaining infrastructure security and performance, this book is for you. Basic networking and infrastructure monitoring knowledge will help you understand the concepts covered in this book.\n\nWith the following software and hardware list you can run all code files present in the book (Chapter 1-14).\n### Software and Hardware List\n| Chapter | Software required | OS required |\n| -------- | ------------------------------------ | ----------------------------------- |\n| 3-14 | VirtualBox (6.0.4) | Ubuntu 18.04 LTS / macOS 10.14.3 |\n| 3-14 | Vagrant (2.2.4) | Ubuntu 18.04 LTS / macOS 10.14.3 |\n| 3-14 | Minikube (1.0.1) | Ubuntu 18.04 LTS / macOS 10.14.3 |\n| 3-14 | kubectl (1.14.1) | Ubuntu 18.04 LTS / macOS 10.14.3 |\n\nWe also provide a PDF file that has color images of the screenshots/diagrams used in this book. [Click here to download it](https://www.packtpub.com/sites/default/files/downloads/9781789612349_ColorImages.pdf).\n\n### Related products\n* Zabbix 4 Network Monitoring - Third Edition  [[Packt]](https://www.packtpub.com/in/networking-and-servers/zabbix-4-network-monitoring-third-edition?utm_source=github&utm_medium=repository&utm_campaign=9781789340266) [[Amazon]](https://www.amazon.com/dp/1789340268)\n\n* DevOps with Kubernetes - Second Edition  [[Packt]](https://www.packtpub.com/in/virtualization-and-cloud/devops-kubernetes-second-edition?utm_source=github&utm_medium=repository&utm_campaign=9781789533996) [[Amazon]](https://www.amazon.com/dp/1789533996)\n\n## Get to Know the Author\n**Joel Bastos**\nis an open source supporter and contributor, with a background in infrastructure security and automation. He is always striving for the standardization of processes, code maintainability, and code reusability. He has defined, led, and implemented critical, highly available, and fault-tolerant enterprise and web-scale infrastructures in several organizations, with Prometheus as the cornerstone. He has worked at two unicorn companies in Portugal and at one of the largest transaction-oriented gaming companies in the world. Previously, he has supported several governmental entities with projects such as the Public Key Infrastructure for the Portuguese citizen card. You can find his blogs at kintoandar and on Twitter with the handle @kintoandar.\n\n**Pedro Araújo**\nis a site reliability and automation engineer and has defined and implemented several standards for monitoring at scale. His contributions have been fundamental in connecting development teams to infrastructure. He is highly knowledgeable about infrastructure, but his passion is in the automation and management of large-scale, highly-transactional systems. Pedro has contributed to several open source projects, such as Riemann, OpenTSDB, Sensu, Prometheus, and Thanos. You can find him on Twitter with the handle @phcrva.\n\n\n### Suggestions and Feedback\n[Click here](https://docs.google.com/forms/d/e/1FAIpQLSdy7dATC6QmEL81FIUuymZ0Wy9vH1jHkvpY57OiMeKGqib_Ow/viewform) if you have any feedback or suggestions.\n","url":"https://github.com/toluwalase09/Hands-On-Infrastructure-Monitoring-with-Prometheus","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.714Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.714Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"DevOps-projects","title":"DevOps-projects","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# DevOps-projects\nAll DevOps related projects\n","url":"https://github.com/toluwalase09/DevOps-projects","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.729Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.729Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"nd9990-c3-microservices-exercises","title":"nd9990-c3-microservices-exercises","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/nd9990-c3-microservices-exercises","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:19.596Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:19.596Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"jenkins-terraform","title":"jenkins-terraform","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# jenkins-terraform-infra","url":"https://github.com/toluwalase09/jenkins-terraform","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:20.493Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:20.493Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"cfn-pip","title":"cfn-pip","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/cfn-pip","language":"Python","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.740Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.740Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"SUCCESS","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":true},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"Free-Certifications","title":"Free-Certifications","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# Free Certifications\n\nCurated list of free courses &amp; certifications.\n\nThe offers on top of the table are time-limited and will expire soon. So, hurry up and grab them first!\n\n🎉 Brought to you by the [Cloud Study Network](https://www.meetup.com/Cloud-Study-Network/) - a global tech community that shares knowledge, goodies and good vibes! 🎉\n\n| Technology | Provider | Description | Link | Expiration |\n| --- | --- | --- | --- | --- |\n| Nutanix Certification | Nutanix | They are providing free certifications until New year | [Link](https://next.nutanix.com/education-blog-153/kick-start-the-new-year-with-free-certification-exams-40333) | January 31, 2022 |\n| Gitlab Certification | Gitlab | Free Certifications paths and badges | [Link](https://about.gitlab.com/learn/) | Unknown |\n| Google Cloud | Google | One free month at Qwiklabs, Pluralsight & Coursera learning platforms. Pluralsight & Coursera require a credit card. Don’t forget to cancel in time.   (Qwiklabs seem still to work. Rest - expired) | [Link](https://inthecloud.withgoogle.com/training-discount/register.html) | ?31-May-2020? |\n| Agile | Atlassian | Free access to Atlassian’s on-demand courses ($300 value each). | [Link](https://training.atlassian.com/free-training-catalog) | 30-Jun-2020 |\n| Programming | Packt | 15 free programming & data science certificate courses by Packt ($20 value each). | [Link](https://courses.packtpub.com/pages/free) | 31-Jul-2020 |\n| Azure | Microsoft | Complete any one or more challenges and update your skills on LinkedIn on or before October 31, 2021, and stand a chance to collect your Free Microsoft Certification Exam Voucher*  | [Link]( https://www.microsoft.com/en-in/campaign/azuredeveloperleague/)| Oct 31 2021 |\n| IT | CompTIA / Jobs.mo.gov | The CompTIA Mentored Learning Program is a free program for displaced workers offering online instructor-led workshops that cover a technical computer curriculum geared toward IT industry-recognized CompTIA certification. | [Link](https://jobs.mo.gov/content/comptia) | 04-Dec-2020 |\n| HYCU | HYCU | Free Certified Enterprise Cloud HYCU Admin certification for HYCU customers and partners. Free swags for those who complete before end of October 2020. | [Link](https://blog.hycu.com/data-protection/you-asked-we-listened-hycu-learning-center) | 31-Dec-2020 |\n| Kubernetes | Rancher | Free “Certified Rancher Operator: Level 1” on-demand training & certification by Rancher. | [Link](https://academy.rancher.com/courses/course-v1:RANCHER+K101+2019/about) | 14-Jul-2021 |\n| Alibaba Cloud | Alibaba Cloud | Alibaba Cloud Associate (ACA) Cloud Computing Certification Training. | [Link](https://us06web.zoom.us/meeting/register/tZ0sduCurDMpH9CrWYPr-85JiJPFMBl-bLhK?spm=a3c0i.11597099.7300010950.9.1310224acvradr) / [Link](https://edu.alibabacloud.com/training?utm_campaign=eloqua_nonreg_yes_MYS_NovTraining_20211028&utm_medium=email&utm_source=Eloqua&utm_content=eloqua#J_7300010950) | 11-Nov-2021 |\n| Alibaba Cloud | Alibaba Cloud | For the very first time, Alibaba Cloud is offering free Alibaba Cloud Professional (ACP) Cloud Computing Certification Training. | [Link](https://us06web.zoom.us/meeting/register/tZAtd-ipqj0vE9KPEzh5J-T23KSFSsLQxCcY?spm=a3c0i.11597099.7300010950.12.1310224acvradr) / [Link](https://edu.alibabacloud.com/training?utm_campaign=eloqua_nonreg_yes_MYS_NovTraining_20211028&utm_medium=email&utm_source=Eloqua&utm_content=eloqua#J_7300010950) | 17-Nov-2021 |\n| Alibaba Cloud | Alibaba Cloud | Alibaba Cloud Professional (ACP) Container Service Certification Training. | [Link](https://us06web.zoom.us/meeting/register/tZYvduisrD4uGNX-jny2Y06uEBmcg1os9V74?spm=a3c0i.11597099.7300010950.14.1310224acvradr) / [Link](https://edu.alibabacloud.com/training?utm_campaign=eloqua_nonreg_yes_MYS_NovTraining_20211028&utm_medium=email&utm_source=Eloqua&utm_content=eloqua#J_7300010950) | 22-Nov-2021 |\n| Alibaba Cloud | Alibaba Cloud | For the very first time, Alibaba Cloud is offering free Alibaba Cloud Professional (ACP) Cloud Computing Certification Training. | [Link](https://us06web.zoom.us/meeting/register/tZErceisqTsiGty5X5gz8Z0QOGN7pNgsP5CG?spm=a3c0i.11597099.7300010950.17.1310224acvradr) / [Link](https://edu.alibabacloud.com/training?utm_campaign=eloqua_nonreg_yes_MYS_NovTraining_20211028&utm_medium=email&utm_source=Eloqua&utm_content=eloqua#J_7300010950) | 24-Nov-2021 |\n| AWS | AWS | Get AWS Certified Sub-Saharan Africa Challenge. The first 6,000 participants who request vouchers will also be eligible to take a practice exam and take the AWS Cloud Practitioner certification exam free of charge (normally $100). | [Link](https://pages.awscloud.com/EMEA_TC_join-the-ssa-challenge.html) | 3-Dec-2021 |\n| OCI | Oracle | Oracle Cloud Infrastructure 2022 Foundations Associate | [Link](https://education.oracle.com/oracle-cloud-infrastructure-2022-foundations-associate/pexam_1Z0-1085-22) | Unlimited |\n| OCI | Oracle | Oracle Cloud Data Management 2022 Foundations Associate | [Link](https://mylearn.oracle.com/learning-path/become-an-oracle-cloud-data-management-foundations-associate/107013) | Unlimited |\n| Azure | Pluralsight | Free subscription at Pluralsight for Microsoft Azure courses | [Link](https://www.pluralsight.com/partners/microsoft/azure) | 01-Jan-2025 |\n| Cloud Networking | Aviatrix  | Aviatrix ,Free ACE - Multicloud Networking associate Course & Certificate code ACEMULTICLOUD | [Link](https://aviatrix.teachable.com) | Limited Time |\n| Azure | Microsoft | Free AZ-900 Microsoft Azure Fundamentals certification (worth $99) upon completion of the 2 day virtual training. | [Link](https://www.microsoft.com/en-ie/training-days#azure) (\"Fundamentals\" tab) | Limited Time |\n| Microsoft | Build: Azure Developer Challenge | [Link]( https://docs.microsoft.com/en-us/learn/challenges?id=b1ac64ec-f0d3-45fa-beee-f230f9a75e81) |  21-Jun-2022 |\n| Azure | Microsoft | Free DP-900 Microsoft Data Fundamentals certification (worth $99) upon completion of the 2 day virtual training. | [Link](https://www.microsoft.com/en-ie/training-days#azure) (\"Data Fundamentals\" tab) | Limited Time |\n| Azure | Microsoft | Free AI-900 Microsoft AI Fundamentals certification (worth $99) upon completion of the 1 day virtual training. | [Link](https://www.microsoft.com/en-ie/training-days#azure) (\"AI Fundamentals\" tab) | Limited Time |\n| Azure | Microsoft | Free PL-900 Microsoft Power Platform Fundamentals certification (worth $99) upon completion of the 1 day virtual training. | [Link](https://www.microsoft.com/en-ie/training-days#pp) (\"Fundamentals\" tab) | Limited Time |\n| JumpCloud | JumpCloud | Free JumpCloud Core Certification (worth $150). | [Link](https://jumpcloud.com/university/certifications/core) | Limited Time |\n| Google Cloud | QwikLabs | Extra 30 days for Google Cloud labs on Qwiklabs. | [Link](https://go.qwiklabs.com/qwiklabs-free) | Unknown |\n| Automated Testing | Test Automation University | Free certification courses by the Test Automation University. | [Link](https://testautomationu.applitools.com/) | Unknown |\n| Security | Juniper Networks | Courses and certifications for free by Juniper Networks (instead of 150 euros). | [Link](https://learningportal.juniper.net/juniper/user_activity_info.aspx?id=11478) | Unknown |\n| Google Cloud | Qwiklabs | Claim 30 days free Qwiklabs and access to the featured labs. | [Link](https://go.qwiklabs.com/googlecloudsolutions) | Unknown |\n| Huawei Networking | Huawei Academy | Free courses & exams from Huawei Academy for the HCIA, HCIP, and HCIE certifications. | [Link](https://ilearningx.huawei.com/portal/courses) | Unknown |\n| Huawei Networking | Huawei Academ | Free course & certification (HCIA level, $200 value). | [Link](https://e.huawei.com/en/talent/#/ict/partner-details?consultationId=545&consClassCode=AUTH&consTypeCode=consulationRZZX&urlForm=certifi) | Unknown |\n| Programming | JetBrains | Free courses by JetBrains Academy for learning Java, Kotlin & Python. | [Link](https://www.jetbrains.com/academy/) | Unknown |\n| Cloud Monitoring | Elastic | Free access to 11 Elastic Stack courses ($200 value each). | [Link](https://www.elastic.co/training/free) | Unknown |\n| Diverse | Udacity | One free month access to nanodegree programs by Udacity ($400 value). Credit card / PayPal required. Don’t forget to cancel in time. | [Link](https://blog.udacity.com/2020/03/one-month-free-on-nanodegrees.html) | Unknown |\n| Alibaba Cloud | Coursera | “Architecting on Alibaba Cloud Specialization” at Coursera. | [Link](https://www.coursera.org/specializations/alibabacloud) | Unknown |\n| DevOps | The Linux Foundation | The Linux Foundation offers 23 free courses with finalizing exams & confirmations. | [Link](https://training.linuxfoundation.org/resources/?_sft_content_type=free-course) | Unknown |\n| DevOps | CloudBees University | Free training through CloudBees University (Jenkins, DevOps). | [Link](https://standard.cbu.cloudbees.com/) | Unknown |\n| Data Analytics | Sumo Logic | 6 free training courses and certifications by Sumo Logic. | [Link](https://www.sumologic.com/learn/certifications/) | Unlimited |\n| Web Development | Freecodecamp | 6 Free Code Camp learning courses & certifications, incl. RWD, JavaScript, APIs, React… | [Link](https://www.freecodecamp.org/) | Unlimited |\n| Diverse | Udemy | ~670 free courses at Udemy, incl. certificates. | [Link](https://www.udemy.com/courses/free/) | Unlimited |\n| cPanel | Cpanel University | Free cPanel Professional Certification (CPP) awarded simply by successfully completing the full series of video lessons. There is no final certification exam required for the CPP status. | [Link](https://exams.cpanel.net/catalog/info/id:228,cat:38) | Unlimited |\n| Analytics | Google Analytics Academy | Google Analytics Academy free courses with certificates | [Link](https://analytics.google.com/analytics/academy/) | Unlimited |\n| SD-WAN | Silver Peak | Silver Peak , offers Free Training & Certification Exam for SD-WAN Profissional | [Link](https://www.silver-peak.com/support/training) | Unknown |\n| Data Science | IBM Cognitive Class | Data science courses with proof of completion and badge | [Link](https://cognitiveclass.ai/) | Unlimited |\n|  IT sector | Bitdegree | gain or improve digital skills on our eLearning platform | [Link](https://www.bitdegree.org/free-certifications-online) | Unknown |\n| SysTrack | Lakeside Software | Free SysTrack certification and badge upon completion of self-paced courses through their online learning platform. They offer three courses: SysTrack Technician, SysTrack Engineer, and SysTrack Dashboard Designer. | [Link](https://info.lakesidesoftware.com/acton/fs/blocks/showLandingPage/a/31052/p/p-0081/t/page/fm/0) | Unknown |\n| Eggplant | Eggplant | Free Eggplant courses and certifications. | [Link](https://www.eggplantsoftware.com/training-and-certifications) | Unknown |\n| AWS | AWS | Free full-time AWS training with certification and launch a career in cloud computing with AWS re/Start for unemployed and underemployed individuals. | [Link](https://aws.amazon.com/training/restart/) | Unknown |\n| API | API Academy | Free API Designer and API Security Architect certifications. | [Link](https://apiacademy.co/api-certification/) | Unknown |\n| AI | Microsoft AI | Microsoft AI Classroom Series. Microsoft has joined forces with NASSCOM FutureSkills® to deliver Microsoft’s AI, machine learning and data science expertise to students through easy-to-consume modules including demos, hands-on workshop and assignments. | [Link](http://thetechco.in/MicrosoftAIforStudents/index) | Unknown |\n| Zerto | Zerto | Free Zerto Associate Certification on Zerto University. | [Link](https://www.zerto.com/myzerto/training/) | Unknown |\n| Calico | Calico | Certified Calico Operator: Level 1. | [Link](https://academy.tigera.io/course/certified-calico-operator-level-1/) | Unknown |\n| Stepik | Stepik | Several free courses with certificates are available for reference in design, computer science, mathematics, etc. | [Link](https://stepik.org/catalog/search?cert=true&free=true) | Unknown |\n| LoRaWAN | TheThingsNetwork | The Things Fundamentals, The Things Advanced, The Things Security and The Things Network Management. | [Link](https://www.thethingsnetwork.org/achievements/) | Unknown |\n| DevOps-Automation | CHEF | FREE Chef Principles Certification Exam | [Link](https://learn.chef.io/courses/course-v1:chef+CP101+exam/about) | Unknown |\n| Observability | New Relic | FREE Full Stack Observability Exam | [Link](https://learn.newrelic.com/full-stack-observability-exam) | Unknown |\n| Programmability | New Relic | FREE Programmability Certification Exam | [Link](https://learn.newrelic.com/programmability-certification) | Unknown |\n| Chaos | Gremlin | FREE Gremlin Certified Chaos Engineering practitioner Certification| [Link](https://gremlin.coassemble.com/unlock/7Jan8Su#/) | Unknown |\n| Neo4j | Neo4j, Inc. | Become a Neo4j Certified Professional | [Link](https://neo4j.com/graphacademy/neo4j-certification/) | Unknown |\n| Confluent | Confluent | Fundamentals Accreditation | [Link](https://cloud.contentraven.com/confluent/self-userpackage?pid=MTI5NA%3D%3D) | Unknown |\n| Confluence | Confluence | Fundamentals Accreditation | [Link](https://university.atlassian.com/student/path/861302-confluence-fundamentals) | Unknown |\n| Extreme Networks | Extreme Networks | Extreme Networks Associate: Free training with an Industry Certification from the Extreme Academy | [Link](https://academy.extremenetworks.com/extreme-academy-live-registration/) | Unknown |\n| Gatling | Gatling Academy | Become an ace on Gatling’s Load Testing tool! | [Link](https://academy.gatling.io/) | Unknown |\n| Appium | HeadSpin | Appium Advanced Certifications | [Link](https://www.headspin.io/courses/the-appium-webinar-collection) | Unknown |\n| Selenium | LambdaTest | Selenium Advanced Certifications | [Link](https://www.lambdatest.com/certifications/) | Unknown |\n| DeepLearning AI | Deep Learning | Deep Learning Specialization. Master Deep Learning, and Break into AI | [Link](https://www.coursera.org/specializations/deep-learning?ranMID=40328&ranEAID=bt30QTxEyjA&ranSiteID=bt30QTxEyjA-xNKOW7m9l8XUKUliBGG59Q&siteID=bt30QTxEyjA-xNKOW7m9l8XUKUliBGG59Q&utm_content=10&utm_medium=partners&utm_source=linkshare&utm_campaign=bt30QTxEyjA) | Unknown | \n| Kubernetes | Kasten.io by Veeam | Free Kubernetes Training | [Link](https://learning.kasten.io/) | Unknown |\n| GraphQL & Apollo | Odyssey by Apollo | Apollo Graph Developer - Associate Certification | [Link](https://odyssey.apollographql.com/certifications/apollo-graph-associate) | Unknown |\n| GitOps | codefresh.io | GitOps Fundamental certificate | [Link](https://codefresh.io/codefresh-news/get-gitops-certified-with-argo/) | Unknown |\n| Azure DevOps | Microsoft| Microsoft Azure Devops Expert Certification, Register and complete the learning path within start amd end dtae to get Free voucher to take the Microsoft Associate certification | [Link](https://learn.microsoft.com/en-us/training/challenges?id=909beffb-ac11-414a-9287-a4158b5d6cf9&WT.mc_id=cloudskillschallenge_909beffb-ac11-414a-9287-a4158b5d6cf9&ocid=ignite22_CSCLinkedIn_organicsocial_wwl?wt.mc_id=studentamb_24964) |  2023 |\n\n## Security\n\n| Provider | Description | Link | Expiration |\n| --- | --- | --- | --- |\n| Palo Alto Networks | Free certification exam coupon code upon completion of certification prep training during the event. | [Link](https://ignite.paloaltonetworks.com/) | 18-Nov-2020 |\n| Fortinet | Free Network Security training courses & certifications by Fortinet / NSE Institute. | [Link](https://www.fortinet.com/corporate/about-us/newsroom/press-releases/2020/fortinet-makes-all-online-cybersecurity-training-courses-available-for-free.html) | 31-Dec-2020 |\n| The Academic Council Of uLektz | Free Cyber Security training and certification. | [Link](https://www.ulektzskills.com/skills/The-Academic-Council-Of-uLektz/Cyber-Security-NTA4Mg==) | Unknown |\n| APMG International | Free Certified Cyber Professional (CCP) Specialism Pilot certification for **eligible indiviuals** (see link for info). | [Link](https://apmg-international.com/article/certified-cyber-professional-ccp-specialism-pilot) | Unknown |\n| Cisco Networking Academy | Free Introduction to Cybersecurity course with Networking Academy badge for completing this course. | [Link](https://www.netacad.com/courses/cybersecurity/introduction-cybersecurity) | Unlimited |\n| SkillFront | Free ISO/IEC 27001 Information Security Associate™ | [Link](https://www.skillfront.com/ISO-IEC-27001-Information-Security-Associate) | Unlimited |\n| Azure | Microsoft | Free SC-900 Microsoft Certified: Security, Compliance, and Identity Fundamentals (worth $99) upon completion of the 2 day virtual training. | [Link](https://www.microsoft.com/en-ie/training-days#security) (\"Security\" tab) | Limited/Varying Times |\n| Azure | Microsoft Azure Associate Level  Certification, Register and complete the learning path within start amd end dtae to get Free voucher to take any Microsoft Associate certification | [Link](https://learn.microsoft.com/en-us/training/challenges?id=909beffb-ac11-414a-9287-a4158b5d6cf9&WT.mc_id=cloudskillschallenge_909beffb-ac11-414a-9287-a4158b5d6cf9&ocid=ignite22_CSCLinkedIn_organicsocial_wwl?wt.mc_id=studentamb_24964) | 2023 I \n\n## Project Management\n\n| Provider | Description | Link | Expiration |\n| --- | --- | --- | --- |\n| Certiprof | Free “Scrum Foundations Professional Certificate (SFPC)” certification. Available in en, pt-br & es. Use the code “COVID19Support” | [Link](https://certiprof.com/pages/scrum-foundations-professional-certificate-sfpc-english) | Unknown |\n| Six Sigma Online | Free Six Sigma White Belt Training & Certification. | [Link](https://www.sixsigmaonline.org/six-sigma-white-belt-certification/) | Unknown |\n| OHSC | Free Project Management course and certificate by Oxford Home Study Centre (OHSC). | [Link](https://www.oxfordhomestudy.com/courses/project-management-courses-online/free-online-courses-with-certificates-in-project-management) | Unlimited |\n| Msicertified | Free Project Management Essentials Certified (PMEC) training & certification.  | [Link](https://www.msicertified.com/free-project-management-certification.html) | Unlimited |\n| 6sigmastudy | Free Six Sigma Yellow Belt course & certification. | [Link](http://www.6sigmastudy.com/Six-Sigma-Yellow-Belt.asp) | Unlimited |\n| ScrumStudy | Free “Scrum Fundamentals Certified (SFC™)” training course & certification | [Link](https://www.scrumstudy.com/certification/scrum-fundamentals-certified) | Unlimited |\n| SkillFront | Free Certified Associate In Scrum Fundamentals™ (CASF™) | [Link](https://www.skillfront.com/CASF-Certified-Associate-In-Scrum-Fundamentals) | Unlimited |\n\n## Marketing\n\n| Provider | Description | Link | Expiration |\n| --- | --- | --- | --- |\n| Google | Fundamentals of Digital Marketing free course & certificate by Google. | [Link](https://learndigital.withgoogle.com/digitalgarage/course/digital-marketing) | Unlimited |\n| Microsoft | Microsoft Advertising certification and training. | [Link](https://about.ads.microsoft.com/en-us/resources/training/get-certified) | Unlimited |\n| SMstudy | 4 free marketing related fundamental certifications by SMstudy. | [Link](https://www.smstudy.com/freeresources/earn-4-free-certifications) | Unlimited |\n| DMAC | Free Facebook & Instagram Marketing course and certification by DMAC (Digital Marketing Academy of Canada). | [Link](https://www.yourdmac.com/free-online-social-media-marketing-course) | Limited Time |\n| Hootsuite | **[Students only]** Free Hootsuite Platform Certification (worth $99) and Social Marketing Certification (worth $199) through Hootsuite's Student Program. | [Link](https://hootsuite.com/pages/landing/student-program) | Unlimited |\n| HubSpot Academy | Free marketing & sales courses with certification. | [Link](https://academy.hubspot.com/courses?page=1#certsOnly=true) | Unlimited |\n| SEMrush | Free Online Digital Marketing Courses and Exams. | [Link](https://www.semrush.com/academy/) | Unlimited |\n\n## Database\n\n| Provider | Description | Link | Expiration |\n| --- | --- | --- | --- |\n| Exasol | Free Exasol training courses and certifications (€150 value each). | [Link](https://www.exasol.com/portal/display/TRAINING/Exasol+Training+and+Certification) | 30-Jun-2020 |\n| Mongodb | 12 free MongoDB courses with proof of completion. | [Link](https://university.mongodb.com/courses/catalog) | Unlimited |\n| CockcroachLab University | Free Cert - the core concepts behind distributed databases and give you all the tools you need to get started with CockroachDB | [Link](https://university.cockroachlabs.com/course/getting-started-with-cockroachdb) | Unknown |\n| CockcroachLab University | Free Cert - you will build a full-stack ride-sharing application in Python using the popular SQLAlchemy ORM and CockroachDB | [Link](https://university.cockroachlabs.com/course/cockroachdb-for-python-developers) | Unknown |\n| Liquibase |  Learn all about Liquibase fundamentals from free online courses by Liquibase experts and see how to apply them in the real world. | [Link](https://learn.liquibase.com/index) | Unknown |\n\n## Others\n\n| Provider | Description | Link | Expiration |\n| --- | --- | --- | --- |\n| Salesforce | Free Salesforce courses with career learning paths and _superbadges_. Also, free half-day [Salesforce Certification preparation webinar](https://trailhead.salesforce.com/credentials/cert-days), offering $70 discount coupon for any $200 exam for all attendees. | [Link](https://trailhead.salesforce.com/en/home) | Unlimited |\n| Revenera | Revenera Certification free of charge to approved members of the legal community. | [Link](https://info.revenera.com/SCA-Legal-Certification-Program-Request) | Unlimited |\n| Kahoot! | Kahoot! Certified for schools, free program designed to help teachers become the ultimate Kahoot! superheroes. | [Link](https://kahoot.com/blog/2020/09/18/kahoot-certified-for-schools-better-than-before/) | Unlimited |\n| Explain Everything | Free Explain Everything course and certification. | [Link](https://explaineverything.com/the-explain-everything-certification-course-is-here/) | Unlimited |\n| SkillFront | Free SkillFront Entrepreneur Program™: Foundations Of Business And Entrepreneurship™ | [Link](https://www.skillfront.com/Free-Business-Entrepreneurship-Program-Certification) | Unlimited |\n| CertiProf| Free Remote Work and Virtual Collaboration - RWVCPC | [Link](https://certiprof.com/pages/remote-work-and-virtual-collaboration-certificate-rwvcpc) | Unknown | \n| Slack | Free Slack Skill Learning Paths and Badges (issued by accredible.com - these are not certifications but badges for skill specialists) | [Link](https://www.slackcertified.com/page/slack-skills) | Unknown |\n| Reuters | Reuters Training Course: Introduction to Digital Journalism | [Link](https://reutersdigitaljournalism.com/) | Unknown\n| OpenSAP | openSAP is SAP's free learning platform for everyone interested in learning about SAP's latest innovations and how to survive in the digital economy. | [Link](https://open.sap.com/) | Unknown\n| Kami | Free online training courses to build your Kami skills and grow as a leader in your professional learning community | [Link](https://www.kamiapp.com/certified/) | 31-Oct-2021 |\n| Miro | Miro essentials | [Link](https://academy.miro.com/learning-paths/miro-essentials) | Unknown |\n| Miro | Collaborative meetings | [Link](https://academy.miro.com/learning-paths/collaborative-meetings-in-miro) | Unknown |\n| Miro | Mapping and diagramming | [Link](https://academy.miro.com/learning-paths/mapping-and-diagramming-in-miro) | Unknown |\n","url":"https://github.com/toluwalase09/Free-Certifications","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.748Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.748Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"alx-system_engineering-devops","title":"alx-system_engineering-devops","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# System Engineering\n\n## Shell Basics\nTerminals are a link to shells.\n\n## Shell Permissions\nUser, Group and Others can have permissions to read write or execute a file / directory\n\n## Shell Redirections\nOutput of commands can be redirected to files.  Files can be used as input to commands.\n\n## Shell, init files, variables and expansions\nWorking with variables and expansions on the shell.\n\n## Loops, Conditions and Parsing\nFor and While loop in Shell Scripting.\n\n## Processes and Signals\nProcess creation, killing processes. Signals such as SIGINT are also covered.\n\n## Regular Expressions\n\nA regular expression, commonly called a “regexp”, is a sequence of characters that define a search pattern.  It is mainly for use in pattern matching with strings, or string matching (i.e. it operates like a “find and replace” command). While it is a very powerful tool, it is also very dangerous because of its complexity.\n\n## Networking Basics\n\nOSI (Open Systems Interconnection) is an abstract model to describe layered communication and computer network design.\n## Alx-system_engineering-devops\n- [x] Bash Scripting\n\n","url":"https://github.com/toluwalase09/alx-system_engineering-devops","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:16.007Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:16.007Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"Web-Dev-For-Beginners","title":"Web-Dev-For-Beginners","icon":null,"blueprint":"service","team":[],"properties":{"readme":"[![GitHub license](https://img.shields.io/github/license/microsoft/Web-Dev-For-Beginners.svg)](https://github.com/microsoft/Web-Dev-For-Beginners/blob/master/LICENSE)\n[![GitHub contributors](https://img.shields.io/github/contributors/microsoft/Web-Dev-For-Beginners.svg)](https://GitHub.com/microsoft/Web-Dev-For-Beginners/graphs/contributors/)\n[![GitHub issues](https://img.shields.io/github/issues/microsoft/Web-Dev-For-Beginners.svg)](https://GitHub.com/microsoft/Web-Dev-For-Beginners/issues/)\n[![GitHub pull-requests](https://img.shields.io/github/issues-pr/microsoft/Web-Dev-For-Beginners.svg)](https://GitHub.com/microsoft/Web-Dev-For-Beginners/pull/)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)\n\n[![GitHub watchers](https://img.shields.io/github/watchers/microsoft/Web-Dev-For-Beginners.svg?style=social&label=Watch&maxAge=2592000)](https://GitHub.com/microsoft/Web-Dev-For-Beginners/watchers/)\n[![GitHub forks](https://img.shields.io/github/forks/microsoft/Web-Dev-For-Beginners.svg?style=social&label=Fork&maxAge=2592000)](https://GitHub.com/microsoft/Web-Dev-For-Beginners/network/)\n[![GitHub stars](https://img.shields.io/github/stars/microsoft/Web-Dev-For-Beginners.svg?style=social&label=Star&maxAge=2592000)](https://GitHub.com/microsoft/Web-Dev-For-Beginners/stargazers/)\n\n\n# Web Development for Beginners - A Curriculum\n\nAzure Cloud Advocates at Microsoft are pleased to offer a 12-week, 24-lesson curriculum all about JavaScript, CSS, and HTML basics. Each lesson includes pre- and post-lesson quizzes, written instructions to complete the lesson, a solution, an assignment and more. Our project-based pedagogy allows you to learn while building, a proven way for new skills to 'stick'.\n\n**Hearty thanks to our authors Jen Looper, Chris Noring, Christopher Harrison, Jasmine Greenaway, Yohan Lasorsa, Floor Drees, and sketchnote artist Tomomi Imura!**\n\n> **Teachers**, we have [included some suggestions](for-teachers.md) on how to use this curriculum. If you would like to create your own lessons, we have also included a [lesson template](lesson-template/README.md)\n\n> **Students**, to use this curriculum on your own, fork the entire repo and complete the exercises on your own, starting with a pre-lecture quiz, then reading the lecture and completing the rest of the activities. Try to create the projects by comprehending the lessons rather than copying the solution code; however that code is available in the /solutions folders in each project-oriented lesson. Another idea would be to form a study group with friends and go through the content together. For further study, we recommend [Microsoft Learn](https://docs.microsoft.com/users/jenlooper-2911/collections/jg2gax8pzd6o81?WT.mc_id=academic-13441-cxa) and by watching the videos mentioned below.\n\n[![Promo video](screenshot.png)](https://youtube.com/watch?v=R1wrdtmBSII \"Promo video\")\n\n> Click the image above for a video about the project and the folks who created it!\n\n## Pedagogy\n\nWe have chosen two pedagogical tenets while building this curriculum: ensuring that it is project-based and that it includes frequent quizzes. By the end of this series, students will have built a typing game, a virtual terrarium, a 'green' browser extension, a 'space invaders' type game, and a business-type banking app, and will have learned the basics of JavaScript, HTML, and CSS along with the modern toolchain of today's web developer. \n\nBy ensuring that the content aligns with projects, the process is made more engaging for students and retention of concepts will be augmented. We also wrote several starter lessons in JavaScript basics to introduce concepts, paired with video from the \"[Beginners Series to: JavaScript](https://channel9.msdn.com/Series/Beginners-Series-to-JavaScript?WT.mc_id=academic-13441-cxa)\" collection of video tutorials, some of whose authors contributed to this curriculum.\n\nIn addition, a low-stakes quiz before a class sets the intention of the student towards learning a topic, while a second quiz after class ensures further retention. This curriculum was designed to be flexible and fun and can be taken in whole or in part. The projects start small and become increasingly complex by the end of the 12 week cycle.\n\nWhile we have purposefully avoided introducing JavaScript frameworks so as to concentrate on the basic skills needed as a web developer before adopting a framework, a good next step to completing this curriculum would be learning about Node.js via another collection of videos: \"[Beginner Series to: Node.js](https://channel9.msdn.com/Series/Beginners-Series-to-Nodejs?WT.mc_id=academic-13441-cxa)\".\n\n> Find our [Code of Conduct](CODE_OF_CONDUCT.md), [Contributing](CONTRIBUTING.md), and [Translation](TRANSLATIONS.md) guidelines. We welcome your constructive feedback!\n>\n## Each lesson includes:\n\n- optional sketchnote\n- optional supplemental video\n- pre-lesson warmup quiz\n- written lesson\n- for project-based lessons, step-by-step guides on how to build the project\n- knowledge checks\n- a challenge\n- supplemental reading\n- assignment\n- post-lesson quiz\n\n> **A note about quizzes**: All quizzes are contained [in this app](https://nice-beach-0fe9e9d0f.azurestaticapps.net/), for 48 total quizzes of three questions each. They are linked from within the lessons but the quiz app can be run locally; follow the instruction in the `quiz-app` folder. They are gradually being localized.\n\n## Lessons\n\n|       |                       Project Name                       |                            Concepts Taught                             | Learning Objectives                                                                                                                 |                                                         Linked Lesson                                                          | Written Lesson | Sketchnote | Assignment | Starting Quiz | Ending Quiz | Video |         Author          |\n| :---: | :------------------------------------------------------: | :--------------------------------------------------------------------: | ----------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------: | :------------: | :--------: | :--------: | :-----------: | :---------: | :---: | :---------------------: |\n|  01   |                     Getting Started                      |           Introduction to Programming and Tools of the Trade           | Learn the basic underpinnings behind most programming languages and about software that helps professional developers do their jobs | [Intro to Programming Languages and Tools of the Trade](/1-getting-started-lessons/1-intro-to-programming-languages/README.md) |       ✅        |     ✅      |     ✅      |       ✅       |      ✅      |   ✅   |         Jasmine         |\n|  02   |                     Getting Started                      |             Basics of GitHub, includes working with a team             | How to use GitHub in your project, how to collaborate with others on a code base                                                    |                            [Intro to GitHub](/1-getting-started-lessons/2-github-basics/README.md)                             |       ✅        |     ✅      |     ✅      |       ✅       |      ✅      |   🛑   |          Floor          |\n|  03   |                     Getting Started                      |                             Accessibility                              | Learn the basics of web accessibility                                                                                               |                       [Accessibility Fundamentals](/1-getting-started-lessons/3-accessibility/README.md)                       |       ✅        |     ✅      |     ✅      |       ✅       |      ✅      |   🛑   |       Christopher       |\n|  04   |                        JS Basics                         |                         JavaScript Data Types                          | The basics of JavaScript data types                                                                                                 |                                       [Data Types](/2-js-basics/1-data-types/README.md)                                        |       ✅        |     ✅      |     ✅      |       ✅       |      ✅      |   ✅   |         Jasmine         |\n|  05   |                        JS Basics                         |                         Functions and Methods                          | Learn about functions and methods to manage an application's logic flow                                                             |                              [Functions and Methods](/2-js-basics/2-functions-methods/README.md)                               |       ✅        |     ✅      |     ✅      |       ✅       |      ✅      |   ✅   | Jasmine and Christopher |\n|  06   |                        JS Basics                         |                        Making Decisions with JS                        | Learn how to create conditions in your code using decision-making methods                                                           |                                 [Making Decisions](/2-js-basics/3-making-decisions/README.md)                                  |       ✅        |     ✅      |     ✅      |       ✅       |      ✅      |   ✅   |         Jasmine         |\n|  07   |                        JS Basics                         |                            Arrays and Loops                            | Work with data using arrays and loops in JavaScript                                                                                 |                                   [Arrays and Loops](/2-js-basics/4-arrays-loops/README.md)                                    |       ✅        |     ✅      |     ✅      |       ✅       |      ✅      |   ✅   |         Jasmine         |\n|  08   |       [Terrarium](/3-terrarium/solution/README.md)       |                            HTML in Practice                            | Build the HTML to create an online terrarium, focusing on building a layout                                                         |                                 [Introduction to HTML](/3-terrarium/1-intro-to-html/README.md)                                 |       ✅        |     ✅      |     ✅      |       ✅       |      ✅      |   🛑   |           Jen           |\n|  09   |       [Terrarium](/3-terrarium/solution/README.md)       |                            CSS in Practice                             | Build the CSS to style the online terrarium, focusing on the basics of CSS including making the page responsive                     |                                  [Introduction to CSS](/3-terrarium/2-intro-to-css/README.md)                                  |       ✅        |     ✅      |     ✅      |       ✅       |      ✅      |   🛑   |           Jen           |\n|  10   |            [Terrarium](/3-terrarium/solution)            |                 JavaScript Closures, DOM manipulation                  | Build the JavaScript to make the terrarium function as a drag/drop interface, focusing on closures and DOM manipulation             |                  [JavaScript Closures, DOM manipulation](/3-terrarium/3-intro-to-DOM-and-closures/README.md)                   |       ✅        |     ✅      |     ✅      |       ✅       |      ✅      |   🛑   |           Jen           |\n|  11   |          [Typing Game](/4-typing-game/solution)          |                          Build a Typing Game                           | Learn how to use keyboard events to drive the logic of your JavaScript app                                                          |                                [Event-Driven Programming](/4-typing-game/typing-game/README.md)                                |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |   ✅   |       Christopher       |\n|  12   | [Green Browser Extension](/5-browser-extension/solution) |                         Working with Browsers                          | Learn how browsers work, their history, and how to scaffold the first elements of a browser extension                               |                               [About Browsers](/5-browser-extension/1-about-browsers/README.md)                                |       ✅        |     ✅      |     ✅      |       ✅       |      ✅      |   🛑   |           Jen           |\n|  13   | [Green Browser Extension](/5-browser-extension/solution) | Building a form, calling an API and storing variables in local storage | Build the JavaScript elements of your browser extension to call an API using variables stored in local storage                      |                [APIs, Forms, and Local Storage](/5-browser-extension/2-forms-browsers-local-storage/README.md)                 |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |   ✅   |           Jen           |\n|  14   | [Green Browser Extension](/5-browser-extension/solution) |          Background processes in the browser, web performance          | Use the browser's background processes to manage the extension's icon; learn about web performance and some optimizations to make   |             [Background Tasks and Performance](/5-browser-extension/3-background-tasks-and-performance/README.md)              |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |   🛑   |           Jen           |\n|  15   |           [Space Game](/6-space-game/solution)           |             More Advanced Game Development with JavaScript             | Learn about Inheritance using both Classes and Composition and the Pub/Sub pattern, in preparation for building a game              |                      [Introduction to Advanced Game Development](/6-space-game/1-introduction/README.md)                       |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |   🛑   |          Chris          |\n|  16   |           [Space Game](/6-space-game/solution)           |                           Drawing to canvas                            | Learn about the Canvas API, used to draw elements to a screen                                                                       |                                [Drawing to Canvas](/6-space-game/2-drawing-to-canvas/README.md)                                |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |   🛑   |          Chris          |\n|  17   |           [Space Game](/6-space-game/solution)           |                   Moving elements around the screen                    | Discover how elements can gain motion using the cartesian coordinates and the Canvas API                                            |                           [Moving Elements Around](/6-space-game/3-moving-elements-around/README.md)                           |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |   🛑   |          Chris          |\n|  18   |           [Space Game](/6-space-game/solution)           |                          Collision detection                           | Make elements collide and react to each other using keypresses and provide a cooldown function to ensure performance of the game    |                              [Collision Detection](/6-space-game/4-collision-detection/README.md)                              |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |   🛑   |          Chris          |\n|  19   |           [Space Game](/6-space-game/solution)           |                             Keeping score                              | Perform math calculations based on the game's status and performance                                                                |                                    [Keeping Score](/6-space-game/5-keeping-score/README.md)                                    |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |   🛑   |          Chris          |\n|  20   |           [Space Game](/6-space-game/solution)           |                     Ending and restarting the game                     | Learn about ending and restarting the game, including cleaning up assets and resetting variable values                              |                                [The Ending Condition](/6-space-game/6-end-condition/README.md)                                 |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |   🛑   |          Chris          |\n|  21   |         [Banking App](/7-bank-project/solution)          |                 HTML Templates and Routes in a Web App                 | Learn how to create the scaffold of a multipage website's architecture using routing and HTML templates                             |                            [HTML Templates and Routes](/7-bank-project/1-template-route/README.md)                             |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |   ✅   |          Yohan          |\n|  22   |         [Banking App](/7-bank-project/solution)          |                  Build a Login and Registration Form                   | Learn about building forms and handing validation routines                                                                          |                                           [Forms](/7-bank-project/2-forms/README.md)                                           |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |   ✅   |          Yohan          |\n|  23   |         [Banking App](/7-bank-project/solution)          |                   Methods of Fetching and Using Data                   | How data flows in and out of your app, how to fetch it, store it, and dispose of it                                                 |                                            [Data](/7-bank-project/3-data/README.md)                                            |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |   ✅   |          Yohan          |\n|  24   |         [Banking App](/7-bank-project/solution)          |                      Concepts of State Management                      | Learn how your app retains state and how to manage it programmatically                                                              |                                [State Management](/7-bank-project/4-state-management/README.md)                                |       ✅        |     🛑      |     ✅      |       ✅       |      ✅      |       |          Yohan          |\n\n## Offline access\n\nYou can run this documentation offline by using [Docsify](https://docsify.js.org/#/). Fork this repo, [install Docsify](https://docsify.js.org/#/quickstart) on your local machine, and then in the root folder of this repo, type `docsify serve`. The website will be served on port 3000 on your localhost: `localhost:3000`.\n\n","url":"https://github.com/toluwalase09/Web-Dev-For-Beginners","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.761Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.761Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"terraform-jenkinss","title":"terraform-jenkinss","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# terraform-jenkinss","url":"https://github.com/toluwalase09/terraform-jenkinss","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.765Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.765Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"helm-chart","title":"helm-chart","icon":null,"blueprint":"service","team":[],"properties":{"readme":"The code  defines a Helm chart that deploys two application containers (a frontend app and its backend) into a Kubernetes cluster and configures Ingress to access the applications using sample Docker images for the frontend, backend, and nginx.\n\nThe Helm chart consists of several files:\n\ntemplates/deployment.yaml: This file defines two Deployment resources, one for the frontend application and one for the backend application. Each Deployment resource specifies the Docker image to use for the container, as well as the port that the container will listen on.\n\ntemplates/service.yaml: This file defines two Service resources, one for the frontend application and one for the backend application. Each Service resource uses the ClusterIP type, which exposes the application to other resources within the cluster, but not to external traffic. The Services also define a port for each container, which allows other resources in the cluster to access the application using the specified port.\n\ntemplates/ingress.yaml: This file defines an Ingress resource to expose the frontend application to external traffic. The Ingress resource specifies a hostname and a path that can be used to access the application.\n\ntemplates/ingress-controller.yaml: This file defines an Ingress controller to manage the Ingress resource. The Ingress controller uses an NGINX Ingress controller to handle incoming traffic and route it to the appropriate backend application.\n\n\ninstallation.sh: provides the code to install helm chart, kubernettes and other things needed for the installation on an aws ec2 instance\n\n\ndeploy.sh: This file contains the deployment script for the chart","url":"https://github.com/toluwalase09/helm-chart","language":"Shell","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.844Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.844Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"realworld","title":"realworld","icon":null,"blueprint":"service","team":[],"properties":{"readme":"![RealWorld Example Applications](media/realworld-dual-mode.png)\n\n<p align=\"center\" style=\"margin-top: 30px;\">\n<img src=\"media/stacks_hr.gif\"  />\n</p>\n\n<a href=\"https://demo.realworld.io/\"><img src=\"media/conduit_l.png\" align=\"right\" width=\"250px\" /></a>\n\n### See how _the exact same_ Medium.com clone (called [Conduit](https://demo.realworld.io)) is built using different [frontends](https://codebase.show/projects/realworld?category=frontend) and [backends](https://codebase.show/projects/realworld?category=backend). Yes, you can mix and match them, because **they all adhere to the same [API spec](https://realworld-docs.netlify.app/docs/specs/backend-specs/introduction)** 😮😎\n\nWhile most \"todo\" demos provide an excellent cursory glance at a framework's capabilities, they typically don't convey the knowledge & perspective required to actually build _real_ applications with it.\n\n**RealWorld** solves this by allowing you to choose any frontend (React, Angular, & more) and any backend (Node, Django, & more) and see how they power a real-world, beautifully designed full-stack app called [**Conduit**](https://demo.realworld.io).\n\n_Read the [full blog post announcing RealWorld on Medium.](https://medium.com/@ericsimons/introducing-realworld-6016654d36b5)_\n\nJoin us on [GitHub Discussions!](https://github.com/gothinkster/realworld/discussions) 🎉\n\n# Implementations\n\nOver 100 implementations have been created using various languages, libraries, and frameworks.\n\nExplore them on [**CodebaseShow**](https://codebase.show/projects/realworld).\n\n# Create a new implementation\n\n[**Create a new implementation >>>**](https://realworld-docs.netlify.app/docs/implementation-creation/introduction)\n\nOr you can [view upcoming implementations (WIPs)](https://github.com/gothinkster/realworld/discussions/categories/wip-implementations).\n\n# Learn more\n\n- [\"Introducing RealWorld 🙌\"](https://medium.com/@ericsimons/introducing-realworld-6016654d36b5) by Eric Simons\n- Every tutorial is built against the same [API spec](api/) to ensure modularity of every frontend & backend\n- Every frontend utilizes the same handcrafted [Bootstrap 4 theme](https://github.com/gothinkster/conduit-bootstrap-template) for identical UI/UX\n- There is a hosted version of the backend API available for public usage, no API keys are required\n- Interested in creating a new RealWorld stack? View our [starter guide & spec](https://realworld-docs.netlify.app/docs/implementation-creation/introduction)\n\n# Active Maintainers\n\n#### [Gérôme Grignon](https://github.com/geromegrignon) - Maintainer\n\n<img align=\"left\" width=\"40\" height=\"40\" src=\"https://avatars.githubusercontent.com/u/32737308?v=4\">\n\nGérôme is a Software Engineer at Sfeir. He's an open-source enthusiast.<br /><br />\n\n#### [Manuel Vila](https://github.com/mvila) - Maintainer\n\n<img align=\"left\" width=\"40\" height=\"40\" src=\"https://avatars.githubusercontent.com/u/381671?v=40\">\n\nManuel is an independent Software Engineer, creator of the [Layr framework](https://layrjs.com) and the [CodebaseShow website](https://codebase.show/).<br /><br />\n\n[![Brought to you by Thinkster](media/end.png)](https://thinkster.io)\n","url":"https://github.com/toluwalase09/realworld","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:16.023Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:16.023Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"cloudboosta-intern-tesr","title":"cloudboosta-intern-tesr","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/cloudboosta-intern-tesr","language":"HCL","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.788Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.788Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"aws-ec2-workflow","title":"aws-ec2-workflow","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/aws-ec2-workflow","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.925Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.925Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"udacity_proj4","title":"udacity_proj4","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# udacity_proj4","url":"https://github.com/toluwalase09/udacity_proj4","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:16.205Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:16.205Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"python-CI-CD-with-Jenkins-and-ArgoCD","title":"python-CI-CD-with-Jenkins-and-ArgoCD","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# A  ci/cd project with git, jenkins, ArgoCD, kubernetes\n\n\n\n## Tools I Used\n\n-  **Github** as repo source\n- **Jenkins** for continous Integration\n- **python flask** the framework\n- **Docker** inorder to containerize the app\n-  **Kubernetes** inorder to orchestrate the containerized app\n-  **GitOps argoCD** inorder to monitors your running infrastructure (the actual state) to compare it to declaratively-defined coded app (the desired state or target state) to determine whether they are out of sync, which helps to remediate configuration drift.\n","url":"https://github.com/toluwalase09/python-CI-CD-with-Jenkins-and-ArgoCD","language":"Python","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.848Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.848Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"SUCCESS","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":true},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Silver"}},"scorecardsStats":66.667,"scorecardsRuleCount":3},{"identifier":"aws-serverless-webapp-workshop","title":"aws-serverless-webapp-workshop","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# Serverless web application\n\nThis workshop shows you how to build a dynamic, serverless web application. You'll learn how to host static web resources with Amazon S3, how to use Amazon Cognito to manage users and authentication, and how to build a RESTful API for backend processing using Amazon API Gateway, AWS Lambda and Amazon DynamoDB.\n\n## Completing the workshop\n\nThe simplest way to complete the workshop is by visiting the hosted version at [webapp.serverlessworkshops.io](https://webapp.serverlessworkshops.io).\n\n## What's Included\n\nThis repository includes the following folders:\n\n* `deck`: PDF copies of the presentation materials for this workshop.\n* `resources`: Any required sample code, IAM policies, or Cloudformation templates needed to complete the workshop.\n* `workshop`: A [Hugo](https://gohugo.io) site with instructions for completing the workshop.\n\n## Running locally\n\n1. [Clone this repository](https://help.github.com/articles/fork-a-repo/).\n2. [Install Hugo locally](https://gohugo.io/overview/quickstart/).\n3. Navigate to the `workshop` directory\n    ```bash\n    cd aws-serverless-webapp-workshop/workshop\n    ```\n4. Launch the website locally with the following command:\n    ```bash\n    hugo serve\n    ```\n5. Visit `http://localhost:1313` in your browser and complete the workshop\n\nCopyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\nSPDX-License-Identifier: MIT-0\n","url":"https://github.com/toluwalase09/aws-serverless-webapp-workshop","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.887Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.887Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"microservices-demo","title":"microservices-demo","icon":null,"blueprint":"service","team":[],"properties":{"readme":"<p align=\"center\">\n<img src=\"src/frontend/static/icons/Hipster_HeroLogoCyan.svg\" width=\"300\" alt=\"Online Boutique\" />\n</p>\n\n\n![Continuous Integration](https://github.com/GoogleCloudPlatform/microservices-demo/workflows/Continuous%20Integration%20-%20Master/Release/badge.svg)\n\n\n**Online Boutique** is a cloud-native microservices demo application.\nOnline Boutique consists of a 10-tier microservices application. The application is a\nweb-based e-commerce app where users can browse items,\nadd them to the cart, and purchase them.\n\n**Google uses this application to demonstrate use of technologies like\nKubernetes/GKE, Istio, Stackdriver, gRPC and OpenCensus**. This application\nworks on any Kubernetes cluster, as well as Google\nKubernetes Engine. It’s **easy to deploy with little to no configuration**.\n\nIf you’re using this demo, please **★Star** this repository to show your interest!\n\n> 👓**Note to Googlers:** Please fill out the form at\n> [go/microservices-demo](http://go/microservices-demo) if you are using this\n> application.\n\nLooking for the old Hipster Shop frontend interface? Use the [manifests](https://github.com/GoogleCloudPlatform/microservices-demo/tree/v0.1.5/kubernetes-manifests) in release [v0.1.5](https://github.com/GoogleCloudPlatform/microservices-demo/releases/v0.1.5).\n\n## Screenshots\n\n| Home Page                                                                                                         | Checkout Screen                                                                                                    |\n| ----------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |\n| [![Screenshot of store homepage](./docs/img/online-boutique-frontend-1.png)](./docs/img/online-boutique-frontend-1.png) | [![Screenshot of checkout screen](./docs/img/online-boutique-frontend-2.png)](./docs/img/online-boutique-frontend-2.png) |\n\n\n## Quickstart (GKE)\n\n[![Open in Cloud Shell](https://gstatic.com/cloudssh/images/open-btn.svg)](https://ssh.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https://github.com/GoogleCloudPlatform/microservices-demo&cloudshell_tutorial=README.md)\n\n1. **[Create a Google Cloud Platform project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#creating_a_project)** or use an existing project. Set the `PROJECT_ID` environment variable and ensure the Google Kubernetes Engine and Cloud Operations APIs are enabled.\n\n```\nPROJECT_ID=\"<your-project-id>\"\ngcloud services enable container.googleapis.com --project ${PROJECT_ID}\ngcloud services enable monitoring.googleapis.com \\\n    cloudtrace.googleapis.com \\\n    clouddebugger.googleapis.com \\\n    cloudprofiler.googleapis.com \\\n    --project ${PROJECT_ID}\n```\n\n2. **Clone this repository.**\n\n```\ngit clone https://github.com/GoogleCloudPlatform/microservices-demo.git\ncd microservices-demo\n```\n\n3. **Create a GKE cluster.**\n\n```\nZONE=us-central1-b\ngcloud container clusters create onlineboutique \\\n    --project=${PROJECT_ID} --zone=${ZONE} \\\n    --machine-type=e2-standard-2 --num-nodes=4\n```\n\n4. **Deploy the sample app to the cluster.**\n\n```\nkubectl apply -f ./release/kubernetes-manifests.yaml\n```\n\n5. **Wait for the Pods to be ready.**\n\n```\nkubectl get pods\n```\n\nAfter a few minutes, you should see:\n\n```\nNAME                                     READY   STATUS    RESTARTS   AGE\nadservice-76bdd69666-ckc5j               1/1     Running   0          2m58s\ncartservice-66d497c6b7-dp5jr             1/1     Running   0          2m59s\ncheckoutservice-666c784bd6-4jd22         1/1     Running   0          3m1s\ncurrencyservice-5d5d496984-4jmd7         1/1     Running   0          2m59s\nemailservice-667457d9d6-75jcq            1/1     Running   0          3m2s\nfrontend-6b8d69b9fb-wjqdg                1/1     Running   0          3m1s\nloadgenerator-665b5cd444-gwqdq           1/1     Running   0          3m\npaymentservice-68596d6dd6-bf6bv          1/1     Running   0          3m\nproductcatalogservice-557d474574-888kr   1/1     Running   0          3m\nrecommendationservice-69c56b74d4-7z8r5   1/1     Running   0          3m1s\nredis-cart-5f59546cdd-5jnqf              1/1     Running   0          2m58s\nshippingservice-6ccc89f8fd-v686r         1/1     Running   0          2m58s\n```\n\n7. **Access the web frontend in a browser** using the frontend's `EXTERNAL_IP`.\n\n```\nkubectl get service frontend-external | awk '{print $4}'\n```\n\n*Example output - do not copy*\n\n```\nEXTERNAL-IP\n<your-ip>\n```\n\n**Note**- you may see `<pending>` while GCP provisions the load balancer. If this happens, wait a few minutes and re-run the command.\n\n8. [Optional] **Clean up**:\n\n```\ngcloud container clusters delete onlineboutique \\\n    --project=${PROJECT_ID} --zone=${ZONE}\n```\n\n## Other Deployment Options\n\n- **Workload Identity**: [See these instructions.](docs/workload-identity.md)\n- **Istio**: [See these instructions.](docs/service-mesh.md)\n- **Anthos Service Mesh**: ASM requires Workload Identity to be enabled in your GKE cluster. [See the workload identity instructions](docs/workload-identity.md) to configure and deploy the app. Then, use the [service mesh guide](/docs/service-mesh.md).\n- **non-GKE clusters (Minikube, Kind)**: see the [Development Guide](/docs/development-guide.md)\n- **Memorystore**: [See these instructions](/docs/memorystore.md) to replace the in-cluster `redis` database with hosted Google Cloud Memorystore (redis).\n\n\n## Architecture\n\n**Online Boutique** is composed of 11 microservices written in different\nlanguages that talk to each other over gRPC. See the [Development Principles](/docs/development-principles.md) doc for more information.\n\n[![Architecture of\nmicroservices](./docs/img/architecture-diagram.png)](./docs/img/architecture-diagram.png)\n\nFind **Protocol Buffers Descriptions** at the [`./pb` directory](./pb).\n\n| Service                                              | Language      | Description                                                                                                                       |\n| ---------------------------------------------------- | ------------- | --------------------------------------------------------------------------------------------------------------------------------- |\n| [frontend](./src/frontend)                           | Go            | Exposes an HTTP server to serve the website. Does not require signup/login and generates session IDs for all users automatically. |\n| [cartservice](./src/cartservice)                     | C#            | Stores the items in the user's shopping cart in Redis and retrieves it.                                                           |\n| [productcatalogservice](./src/productcatalogservice) | Go            | Provides the list of products from a JSON file and ability to search products and get individual products.                        |\n| [currencyservice](./src/currencyservice)             | Node.js       | Converts one money amount to another currency. Uses real values fetched from European Central Bank. It's the highest QPS service. |\n| [paymentservice](./src/paymentservice)               | Node.js       | Charges the given credit card info (mock) with the given amount and returns a transaction ID.                                     |\n| [shippingservice](./src/shippingservice)             | Go            | Gives shipping cost estimates based on the shopping cart. Ships items to the given address (mock)                                 |\n| [emailservice](./src/emailservice)                   | Python        | Sends users an order confirmation email (mock).                                                                                   |\n| [checkoutservice](./src/checkoutservice)             | Go            | Retrieves user cart, prepares order and orchestrates the payment, shipping and the email notification.                            |\n| [recommendationservice](./src/recommendationservice) | Python        | Recommends other products based on what's given in the cart.                                                                      |\n| [adservice](./src/adservice)                         | Java          | Provides text ads based on given context words.                                                                                   |\n| [loadgenerator](./src/loadgenerator)                 | Python/Locust | Continuously sends requests imitating realistic user shopping flows to the frontend.                                              |\n\n## Features\n\n- **[Kubernetes](https://kubernetes.io)/[GKE](https://cloud.google.com/kubernetes-engine/):**\n  The app is designed to run on Kubernetes (both locally on \"Docker for\n  Desktop\", as well as on the cloud with GKE).\n- **[gRPC](https://grpc.io):** Microservices use a high volume of gRPC calls to\n  communicate to each other.\n- **[Istio](https://istio.io):** Application works on Istio service mesh.\n- **[OpenCensus](https://opencensus.io/) Tracing:** Most services are\n  instrumented using OpenCensus trace interceptors for gRPC/HTTP.\n- **[Cloud Operations (Stackdriver)](https://cloud.google.com/products/operations):** Many services\n  are instrumented with **Profiling**, **Tracing** and **Debugging**. In\n  addition to these, using Istio enables features like Request/Response\n  **Metrics** and **Context Graph** out of the box. When it is running out of\n  Google Cloud, this code path remains inactive.\n- **[Skaffold](https://skaffold.dev):** Application\n  is deployed to Kubernetes with a single command using Skaffold.\n- **Synthetic Load Generation:** The application demo comes with a background\n  job that creates realistic usage patterns on the website using\n  [Locust](https://locust.io/) load generator.\n\n## Local Development\n\nIf you would like to contribute features or fixes to this app, see the [Development Guide](/docs/development-guide.md) on how to build this demo locally.\n\n## Demos featuring Online Boutique\n\n- [Take the first step toward SRE with Cloud Operations Sandbox](https://cloud.google.com/blog/products/operations/on-the-road-to-sre-with-cloud-operations-sandbox)\n- [Deploying the Online Boutique sample application on Anthos Service Mesh](https://cloud.google.com/service-mesh/docs/onlineboutique-install-kpt)\n- [Anthos Service Mesh Workshop: Lab Guide](https://codelabs.developers.google.com/codelabs/anthos-service-mesh-workshop)\n- [KubeCon EU 2019 - Reinventing Networking: A Deep Dive into Istio's Multicluster Gateways - Steve Dake, Independent](https://youtu.be/-t2BfT59zJA?t=982)\n- Google Cloud Next'18 SF\n  - [Day 1 Keynote](https://youtu.be/vJ9OaAqfxo4?t=2416) showing GKE On-Prem\n  - [Day 3 Keynote](https://youtu.be/JQPOPV_VH5w?t=815) showing Stackdriver\n    APM (Tracing, Code Search, Profiler, Google Cloud Build)\n  - [Introduction to Service Management with Istio](https://www.youtube.com/watch?v=wCJrdKdD6UM&feature=youtu.be&t=586)\n- [Google Cloud Next'18 London – Keynote](https://youtu.be/nIq2pkNcfEI?t=3071)\n  showing Stackdriver Incident Response Management\n\n---\n\nThis is not an official Google project.","url":"https://github.com/toluwalase09/microservices-demo","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.957Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.957Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"rps-ant","title":"rps-ant","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# rps-ant","url":"https://github.com/toluwalase09/rps-ant","language":"HTML","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.970Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.970Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"k8s-microservice","title":"k8s-microservice","icon":null,"blueprint":"service","team":[],"properties":{"readme":"\"# k8s-microservice\" \n","url":"https://github.com/toluwalase09/k8s-microservice","language":"Shell","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:15.980Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:15.980Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"ci-demo","title":"ci-demo","icon":null,"blueprint":"service","team":[],"properties":{"readme":"--------------------------------------\nRepo for CI process demo \n\n- builds a maven project\n- jenkinsfile\n--------------------------------------","url":"https://github.com/toluwalase09/ci-demo","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:16.030Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:16.030Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"docker-k8s-training","title":"docker-k8s-training","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# Docker and Kubernetes Training Exercise\nThis contains a list of exercises that takes you from containerizing a simple application into a Docker container to running it as in a local Kubernetes cluster.\nIt aims to teach and demonstrate key concepts with Docker and Kubernetes and is suitable for beginners\n\n## Pre-requisites\n- Docker should be installed. Details on installing can be found [here](https://docs.docker.com/get-docker/)\n- Kubectl and Minikube should be installed. Details on installing both are available [here](https://kubernetes.io/docs/tasks/tools/)\n\n## Content\n- [Docker: Containerizing a Simple Flask App](01-docker-flask-app/README.md)\n- [Kubernetes: Deploying and Configuring Pods](02-kubernetes-pod/README.md)\n- [Kubernetes: Working with ConfigMaps and Secrets](03-kubernetes-config/README.md)\n- [Kubernetes: Working with Deployments and Services](04-kubernetes-deployment-and-services/README.md)\n- [Further Reading](05-further-reading/README.md)","url":"https://github.com/toluwalase09/docker-k8s-training","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:16.154Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:16.154Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"test-amplify","title":"test-amplify","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# Website\n\nThis website is built using [Docusaurus](https://docusaurus.io/), a modern static website generator.\n\n### Installation\n\n```\n$ yarn\n```\n\n### Local Development\n\n```\n$ yarn start\n```\n\nThis command starts a local development server and opens up a browser window. Most changes are reflected live without having to restart the server.\n\n### Build\n\n```\n$ yarn build\n```\n\nThis command generates static content into the `build` directory and can be served using any static contents hosting service.\n\n### Deployment\n\nUsing SSH:\n\n```\n$ USE_SSH=true yarn deploy\n```\n\nNot using SSH:\n\n```\n$ GIT_USER=<Your GitHub username> yarn deploy\n```\n\nIf you are using GitHub pages for hosting, this command is a convenient way to build the website and push to the `gh-pages` branch.\n","url":"https://github.com/toluwalase09/test-amplify","language":"JavaScript","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:16.036Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:16.036Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"SUCCESS","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":true},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Silver"}},"scorecardsStats":66.667,"scorecardsRuleCount":3},{"identifier":"getmida.github.io","title":"getmida.github.io","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/getmida.github.io","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:16.251Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:16.251Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":0,"scorecardsRuleCount":3},{"identifier":"aws-sap-code","title":"aws-sap-code","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# AWS Certified Solutions Architect Professional Course Code\n*By [Digital Cloud Training](https://digitalcloud.training/) - Course Author Neal Davis*\n\n## How to Use the Course Code\n\nThe code used throughout the course has been zipped up and is available for download from this repo. Please download the code to your computer and unzip the contents. When course updates are made the file may be updated and you will need to ensure you download the latest version.\n\n## Course Overview\n\nThis course is packed with 19 hours of comprehensive video lessons, practical exercises and high-quality visuals to help you understand the concepts.\n\nYou’ll learn everything you need to know to ace your AWS Certified Solutions Architect Professional exam.\n\nUse the practical exercises to learn how to architect and build applications on Amazon Web Services.\n\nWith our mixture of in-depth theory, logical diagrams and hands-on training, you'll learn how to create real-world solution architectures on Amazon Web Services - fully preparing you for the AWS Solutions Architect PRO Certification exam.\n\n***What you will learn:***\n\n- AWS Accounts and Organizations including Service Control Policies (SCPs)\n- Identity Management and Permissions including RBAC, ABAC and permissions boundaries\n- AWS Directory Services and Federation including Identity Federation, AWS SSO, and Cognito\n- Advanced Amazon VPC including a routing deep dive and multi-account VPC configurations\n- Hybrid Connectivity including S2S VPN, Direct Connect, and AWS Transit Gateway\n- Compute, Auto Scaling, and Load Balancing including ALB, NLB, EC2, and NAT\n- AWS Storage Services including EBS, EFS, and Amazon S3\n- DNS, Caching, and Performance Optimization including Route 53, CloudFront, and AWS Global Accelerator\n- AWS Database Services including Amazon RDS, Aurora, ElastiCache and DynamoDB\n- Serverless Applications including AWS Lambda, EventBridge, SQS, SNS, and API Gateway\n- Docker Containers and PaaS including Amazon ECS, Fargate, and Elastic Beanstalk\n- Deployment and Management including AWS CodeCommit, CodePipeline, Service Catalog, Systems Manager and more\n- Migration and Transfer Service including AWS DMS, SMS, DataSync, and Snowball\n- Analytics Services including Amazon Athena, AWS Glue, RedShift, EMR, and Kinesis\n- Monitoring, Logging and Auditing including CloudWatch, CloudTrail and AWS X-Ray\n- Security: Defense in Depth including how to build a secure application with ACM, KMS, Config, Inspector and WAF/Shield\n- Cost Management including how AWS services are priced, consolidated billing, and AWS Budgets\n\nLearn more and [enroll in this course](https://digitalcloud.training/aws-solutions-architect-professional/) now to become an AWS Certified Solutions Architect Professional\n","url":"https://github.com/toluwalase09/aws-sap-code","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:16.304Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:16.304Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"kubernetes-bootcamp","title":"kubernetes-bootcamp","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# Kubernetes Bootcamp (CKAD)\n\nHi, I'm Pius Lawal, and this course is part of my cloud application developer bootcamp series. Star [this repo](https://github.com/piouson/kubernetes-bootcamp) to say thank you!\n\n<a href=\"https://github.com/sponsors/piouson\" target=\"_blank\"><img src=\"https://img.shields.io/static/v1?message=buy%20me%20coffee&logo=buymeacoffee&labelColor=2E0050&color=4B0083&logoColor=pink&label=%20&style=for-the-badge\" alt=\"buy me coffee to sponsor this project\"></a>\n\n<div style=\"page-break-after: always;\"></div>\n\n## Learning Outcomes\n\nThis bootcamp covers the [Certified Kubernetes Application Developer (CKAD)](https://training.linuxfoundation.org/certification/certified-kubernetes-application-developer-ckad/) exam curriculum plus more. In summary, you will be learning cloud application development, which is a modern approach to building and running software applications that exploits the flexibility, scalability, and resilience of cloud computing. Some highlights include:\n\n- proficiency working on the command-line\n- proficiency working with containers\n- proficiency working with infrastructure as code\n- microservices architecture\n- devops with kubernetes\n\n## Ace the CKAD Exam\n\nPassing the CKAD exam with confidence should be a simple 4-stage process, all of which is covered in this bootcamp:\n\n1. Learn the CKAD exam curriculum content by your preferred method\n2. Learn how to troubleshoot all the resources covered in the curriculum\n3. Familiarity with the exam-language and common exam tips\n4. Proficiency with `kubectl` and related CLI tools\n\n<div style=\"page-break-after: always;\"></div>\n\n## FAQs\n\n<details>\n<summary>How will this work?</summary>\n<br/>\n\nFollow the **_Labs_**, that's all! <br/>\nNo prior experience required and its okay if you're not confident on the command-line, yet!\n\nEach chapter contains several **_Labs_** to help you slowly build confidence and proficiency around the concepts covered. There are _command snippet blocks_ provided to help you through the _Labs_ - use them if you're stuck on any _Lab_ and aren't yet confident using `help` on the terminal.\n\nThere are **_Tasks_** provided at the end of most chapters with content designed to challenge your critical understanding and troubleshooting strategy of the core concepts in that chapter. These _Tasks_ are longer and require more time to solve than standard exam questions, which makes them more difficult. Therefore, you know you are exam-ready if you can complete all 16 _Tasks_ under 2 hours.\n</details>\n\n<details>\n<summary>What else do I need to pass CKAD?</summary>\n<br/>\n\nNothing else, this bootcamp is an **All-In-One-Guide**! Simply working through this bootcamp will make you proficient with Kubernetes as well as prepare you for the CKAD exam!\n\nThe _Exam Readiness Mode_, where you simulate the exam by completing all 16 _Tasks_ under 2 hours, will help you identify your weak areas. Then you simply repeat those chapters/sections, and make sure to review all links to resources from the official Kubernetes documentation, until you are confident.\n</details>\n\n<details>\n<summary>I know Kubernetes already?</summary>\n<br/>\n\nIf you have completed [step [1] above](#ace-the-ckad-exam), for example, you have completed a CKAD course prior or use Kubernetes day-to-day, etc, and just wish to dive into _Exam Readiness Mode_, skip to [Ch15 - Exam tips](#15-exam).\n</details>\n\n<details>\n<summary>I know Docker already?</summary>\n<br/>\n\nGreat! Then you can skip to [Chapter 2: Task - Docker image](#task---docker-image)\n</details>\n\n<details>\n<summary>I only want Kubernetes not CKAD?</summary>\n<br/>\n\nHey! CKAD is entry-level Kubernetes and covers the basic features and core components of Kubernetes. This bootcamp covers everything you need from NOOB setup to mastery. Preparing for the CKAD exam is a structured approach to learning Kubernetes. When you finish this bootcamp, you may choose not to pay for and sit the exam, but you will have acquired the ability to pass regardless.\n</details>\n\n<details>\n<summary>CKAD exam curriculum?</summary>\n<br/>\n\nIn the CKAD exam, [you will have 2 hours to complete 15-20 performance-based questions](https://docs.linuxfoundation.org/tc-docs/certification/tips-cka-and-ckad) around the areas below. \n\n<a target=\"_blank\" width=\"100%\" align=\"center\" href=\"https://github.com/cncf/curriculum\">![CKAD exam curriculum](https://user-images.githubusercontent.com/17856665/186679939-ea79ce57-f277-45c8-8d02-6595d02d9f85.png)</a>\n\n</details>\n\n<div style=\"page-break-after: always;\"></div>\n\n## Requirements\n\nA Unix-based environment running docker (Docker Engine or Docker Desktop).\n\n<details>\n<summary>macOS users</summary>\n\n```sh\n# 1. install xcode tools\nsudo xcode-select --install\n# 2. install homebrew\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n# 3. install docker\nbrew install --cask docker\n```\n</details>\n\n<details>\n  <summary>Windows users</summary>\n\n```sh\n# powershell as administrator\n# 1. install wsl2\nwsl --install\n# 2. install terminal\nwinget install Microsoft.WindowsTerminal\n# 3. install docker\nwinget install Docker.DockerDesktop\n# restart device\n```\n\nAfter device restart:\n\n- Complete Ubuntu user setup - Ubuntu terminal should auto-open\n- [enable Docker Desktop integration with WSL2 Ubuntu](https://docs.microsoft.com/en-us/windows/wsl/media/docker-dashboard.png)\n- [open Terminal and switch to Ubuntu](https://user-images.githubusercontent.com/17856665/192830999-f8f9c5af-8b4e-41c4-8f5e-c9c159fcf9ca.png)\n- [make Ubuntu your default Terminal profile](https://user-images.githubusercontent.com/17856665/192833271-5a3170a0-caf6-45bf-b378-ac6eb1f2dfbc.png)\n- perform Internet connection test in WSL2 by running `curl google.com`\n- if connection fails with `Could not resolve host`, and you have a VPN program installed, see _WSL2 VPN fix_ below\n\n<details>\n  <summary>WSL2 VPN fix</summary>\n\n```sh\n# powershell as administrator\n# 1. download vpnkit\nwget -o wsl-vpnkit.tar.gz https://github.com/sakai135/wsl-vpnkit/releases/latest/download/wsl-vpnkit.tar.gz\n# 2. add vpnkit as linux distro\nwsl --import wsl-vpnkit $env:USERPROFILE\\wsl-vpnkit wsl-vpnkit.tar.gz --version 2\nwsl -d wsl-vpnkit\n# 3. switch to wsl2 ubuntu terminal\nwsl\n# 4. create an alias `vpnkit`\nprintf '# vpnkit - fix vpn network issues\\nalias vpnkit=\"wsl.exe -d wsl-vpnkit service wsl-vpnkit\"' >> ~/.bashrc\n# 5. load the new alias\nexec bash\n# 6. start the vpnkit\nvpnkit start\n# 7. test internet connection again\ncurl google.com\n# note that you can stop the fix with `vpnkit stop`, see https://github.com/sakai135/wsl-vpnkit\n```\n\n</details>\n\n</details>\n\n<details>\n<summary>Ubuntu users</summary>\n<br />\n\nInstall Docker Engine on Ubuntu. This is also an alternative for Windows users running WSL2.\n\n> if using Windows/WSL2, be sure to [disable Docker Desktop integration with WSL2 Ubuntu](https://docs.microsoft.com/en-us/windows/wsl/media/docker-dashboard.png)\n\n```sh\n# Windows/WSL2 prerequisites - enable `systemd` on WSL2\ngit clone https://github.com/DamionGans/ubuntu-wsl2-systemd-script.git\ncd ubuntu-wsl2-systemd-script/\nsudo bash ubuntu-wsl2-systemd-script.sh --force\ncd ../ && rm -rf ubuntu-wsl2-systemd-script/\nexec bash\nsystemctl # long output confirms systemd up and running\n# 1. uninstall old docker versions\nsudo apt-get remove docker docker-engine docker.io containerd runc\n# 2. setup docker repository\nsudo apt-get update\nsudo apt-get -y install ca-certificates curl gnupg lsb-release\nsudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n# 3. install docker engine\nsudo apt-get update\nsudo apt-get -y install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n# 4. manage docker as non-root user\nsudo groupadd docker\nsudo usermod -aG docker $USER\n# 5. start a new terminal to update group membership\ndocker run hello-world\n```\n\n</details>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 1. Understanding and Using Containers\n\nA [container](https://www.docker.com/resources/what-container/) is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. A **container-runtime**, which relies on the host kernel, is required to run a container.\n\n[Docker](https://www.docker.com/) is the most popular container-runtime and container-solution, but there are other runtimes like [runc](https://github.com/opencontainers/runc#runc), [cri-o](https://cri-o.io/), [containerd](https://containerd.io/), etc, However, the only significant container-solutions today are Docker and [Podman](https://podman.io/)\n\nA container image is a lightweight, standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries and settings. Container images become containers at runtime.\n\nThe [Open Container Initiative (OCI)](https://opencontainers.org/) creates open industry standards around container formats and runtimes.\n\nA container registry is a repository, or collection of repositories, used to store and access container images. Container registries are a big player in cloud application development, often as part of [GitOps](https://www.redhat.com/en/topics/devops/what-is-gitops) processes.\n\n### Basic docker commands\n\n```sh\n# run busybox container, see `docker run --help`\ndocker run busybox\n# run in interactive mode\ndocker run -it busybox\n# run in interactive mode and delete container when stopped\ndocker run -it --rm busybox\n# run in detached mode\ndocker run -d busybox\n# list running containers\ndocker ps\n# list all containers\ndocker ps -a\n# start a stopped container, see `docker container start --help`\ndocker container start $CONTAINER_NAME_OR_ID\n# stop a running container, see `docker container stop --help`\ndocker container stop $CONTAINER_NAME_OR_ID\n# restart a running container, see `docker container restart --help`\ndocker container restart $CONTAINER_NAME_OR_ID\n# delete a stopped container, see `docker container rm --help`\ndocker container rm $CONTAINER_NAME_OR_ID\n# exit running container - container is stopped if connected to entrypoint\nexit\n# exit running container without stopping it\nctrl-p ctrl-q\n```\n\n> See [possible container statuses](https://www.baeldung.com/ops/docker-container-states#possible-states-of-a-docker-container) to understand more about container states\n\n<div id=\"lab1-1\">\n\n### Lab 1.1. Hello docker\n\n1. Run `docker info` to confirm docker client and server statuses\n2. Run `docker run hello-world`\n\n</div>\n\n<div id=\"lab1-2\">\n\n### Lab 1.2. First container interaction\n\n```sh\n## view kernel details\nuname -r # or `cat /proc/version` or `hostnamectl`\n# view os version\ncat /etc/*-release # or redhat `/etc/redhat-release`, other unix-based os `/etc/os-release`\n# view running processes, see `ps --help`\nps aux\n# view processes, alternative to `ps`\nls /proc # to find PID, then\ncat /proc/$PID/cmdline\n```\n\n1. Run `ps aux` to review running processes on your host device\n2. Run a `busybox` container in interactive mode `docker run -it busybox`\n3. Review the container kernel details\n4. Review the running processes in the container and note PID\n5. Exit the container\n6. List running containers\n7. List all containers\n8. Repeat [2] and exit the container without stopping it\n9. List running containers\n10. List all containers\n11. Delete the containers\n\n</div>\n\n<div id=\"soln-lab1-2\">\n\n<details>\n  <summary>lab1.2 solution</summary>\n  \n```sh\n# host terminal\nps aux\ndocker run --name box1 -it busybox\n# container terminal\nps aux\nuname -r\ncat /proc/version\nhostnamectl # not found\ncat /etc/*-release # not found\nbusybox | head\nexit\n# host terminal\ndocker ps\ndocker ps -a\ndocker run --name box2 -it busybox\n# container terminal\nctrl+p ctrl+q\n# host terminal\ndocker ps\ndocker ps -a\ndocker stop box2\ndocker rm box1 box2\n```\n</details>\n\n> `docker ps` showing STATUS of `Exited (0)` means exit OK, but an Exit STATUS that's not 0 should be investigated `docker logs`\n>\n> `CTRL+P, CTRL+Q` only works when running a container in interactive mode, see [how to attach/detach containers](https://stackoverflow.com/a/19689048/1235675) for more details\n\n</div>\n\n<div id=\"lab1-3\">\n\n### Lab 1.3. Entering and exiting containers\n\n```sh\n# run container with specified name\ndocker run -d --name webserver httpd\n# run command `date` in a new container\ndocker run busybox date\n# get a \"dash\" shell to a running container, see `docker exec --help`\ndocker exec -it $CONTAINER_NAME_OR_ID sh\n# get a \"bash\" shell to a running container\ndocker exec -it $CONTAINER_NAME_OR_ID bash\n# view open ports, the commands below only work if installed in the container\nnetstat -tupln # see `netstat --help` - t tcp, u udp, p program-names, l listening, n port-numbers-only\nss -tulpn # see `ss --help`, alternative to netstat\n```\n\n1. Run a `nginx` container\n2. List running containers (use another terminal if stuck)\n3. Exit the container\n4. List running containers\n5. Run another `nginx` container in interactive mode\n6. Review container kernel details\n7. Review running processes in the container\n8. Exit container\n9. Run another `nginx` container in detached mode\n10. List running containers\n11. Connect a shell to the new container interactively\n12. View open ports in the container\n13. Exit the container\n14. List running containers\n15. Delete all containers\n\n</div>\n\n<div id=\"soln-lab1-3\">\n\n<details>\n<summary>lab1.3 solution</summary>\n\n```sh\n# host terminal\ndocker run --name webserver1 nginx\n# host second terminal\ndocker ps\n# host terminal\nctrl+c\ndocker ps\ndocker run --name webserver2 -it --rm nginx bash\n# container terminal\ncat /etc/*-release\nps aux # not found\nls /proc\nls /proc/1 # list processes running on PID 1\ncat /proc/1/$PROCESS_NAME\nexit\n# host terminal\ndocker run --name webserver3 -d nginx\ndocker ps\ndocker exec -it webserver3 bash\n# container terminal\nnetstat -tupln\nss -tulpn\nexit\n# host terminal\ndocker ps\ndocker stop webserver3\ndocker rm webserver1 webserver2 webserver3\n```\n\n</details>\n\n> Containers may not always have `bash` shell, but will usually have the dash shell `sh`\n\n</div>\n\n<div id=\"lab1-4\">\n\n### Lab 1.4. Container arguments\n\n1. Run a `busybox` container with command `sleep 30` as argument, see `sleep --help`\n2. List running containers (use another terminal if stuck)\n3. Exit container (note that container will auto exit after 30s)\n4. Run another `busybox` container in detached mode with command `sleep 300` as argument\n5. List running containers\n6. Connect to the container to execute commands\n7. Exit container\n8. List running containers\n9. Run another `busybox` container in detached mode, no commands\n10. List running containers\n11. List all containers\n12. Delete all containers\n\n</div>\n\n<div id=\"soln-lab1-4\">\n\n<details>\n<summary>lab1.4 solution</summary>\n\n```sh\n# host terminal\ndocker run --name box1 busybox sleep 30\n# host second terminal\ndocker ps\ndocker stop box1\n# host terminal\ndocker run --name box2 -d busybox sleep 300\ndocker ps\ndocker exec -it box2 sh\n# container terminal\nexit\n# host terminal\ndocker ps\ndocker run --name box3 -d busybox\ndocker ps\ndocker ps -a\ndocker stop box2\ndocker rm box1 box2 box3\n```\n\n</details>\n\n> The `Entrypoint` of a container is [the init process](https://en.wikipedia.org/wiki/Init) and allows the container to run as an executable. Commands passed to a container are passed to the container's entrypoint process.\n>\n> Note that `docker` commands after `$IMAGE_NAME` are passed to the container's entrypoint as arguments. \\\n> ❌ `docker run -it mysql -e MYSQL_PASSWORD=hello` will pass `-e MYSQL_PASSWORD=hello` to the container \\\n> ✔️ `docker run -it -e MYSQL_PASSWORD=hello mysql`\n\n</div>\n\n### Managing containers and images\n\n```sh\n# run container with port, see `docker run --help`\ndocker run -d -p 8080:80 httpd # visit localhost:8080\n# run container with mounted volume\ndocker run -d -p 8080:80 -v ~/html:/usr/local/apache2/htdocs httpd\n# run container with environment variable\ndocker run -e MONGO_INITDB_ROOT_USERNAME=admin -e MONGO_INITDB_ROOT_PASSWORD=secret mongo\n# inspect container, see `docker container inspect --help | docker inspect --help`\ndocker inspect $CONTAINER_NAME_OR_ID | less # press Q key to quit from less\ndocker container inspect $CONTAINER_NAME_OR_ID\n# format inspect output to view container network information\ndocker inspect --format=\"{{.NetworkSettings.IPAddress}}\" $CONTAINER_NAME_OR_ID\n# format inspect output to view container status information\ndocker inspect --format=\"{{.State.Pid}}\" $CONTAINER_NAME_OR_ID\n# view container logs, see `docker logs --help`\ndocker logs $CONTAINER_NAME_OR_ID\n# remove all unused data (including dangling images)\ndocker system prune\n# remove all unused data (including unused images, dangling or not, and volumes)\ndocker system prune --all --volumes\n# manage images, see `docker image --help`\ndocker image ls # or `docker images`\ndocker image inspect $IMAGE_ID\ndocker image rm $IMAGE_ID\n# see `docker --help` for complete resources\n```\n\n<div id=\"lab1-5\">\n\n### Lab 1.5. Container ports and IP\n\n1. Run a `nginx` container with name `webserver`\n2. Inspect the container (use `| less` to avoid console clutter) and review the `State` and `NetworkSettings` fields, quit with `q`\n3. Visit `http://$CONTAINER_IP_ADDRESS` in your browser (this may not work depending on your envrionment network settings)\n4. Run another `nginx` container with name `webserver` and exposed on port 80\n5. Visit http://localhost in your browser\n6. Delete the containers\n\n</div>\n\n<div id=\"soln-lab1-5\">\n\n<details>\n<summary>lab1.5 solution</summary>\n\n```sh\n# host terminal\ndocker run -d --name webserver nginx\ndocker inspect webserver | grep -A 13 '\"State\"' | less\ndocker inspect webserver | grep -A 50 '\"NetworkSettings\"' | less\ncurl http://$(docker inspect webserver --format \"{{.NetworkSettings.IPAddress}}\") | less\ndocker stop webserver\ndocker rm webserver\ndocker run -d --name webserver -p 80:80 nginx\ncurl localhost | less\ndocker ps\ndocker ps -a\ndocker stop webserver\ndocker rm webserver\n```\n\n</details>\n\n> Always run containers in detached mode to avoid getting stuck in the container `STDOUT`\n\n</div>\n\n<div id=\"lab1-6\">\n\n### Lab 1.6. Container volumes\n\n1. Create an `html/index.html` file with some content\n2. Run any webserver containers on port 8080 and mount the `html` folder to the [DocumentRoot](https://serverfault.com/a/588388)\n   - option `nginx` DocumentRoot - `/usr/share/nginx/html`\n   - option `httpd` DocumentRoot - `/usr/local/apache2/htdocs`\n3. Visit http://localhost:8080\n4. List running containers\n5. List all containers\n6. Delete containers\n\n</div>\n\n<div id=\"soln-lab1-6\">\n\n<details>\n<summary>lab1.6 solution</summary>\n\n```sh\n# host terminal\ncd ~\nmkdir html\necho \"Welcome to Lab 1.6 Container volumes\" >> html/index.html\n# with nginx\ndocker run -d --name webserver -v ~/html:/usr/share/nginx/html -p 8080:80 nginx\n# with httpd\n# docker run -d --name webserver -v ~/html:/usr/local/apache2/htdocs -p 8080:80 httpd\ncurl localhost:8080\ndocker ps\ndocker ps -a\ndocker stop webserver\ndocker rm webserver\n```\n\n</details>\n\n</div>\n\n<div id=\"lab1-7\">\n\n### Lab 1.7. Container environment variables\n\n1. Run a `mysql` container in detached mode\n2. Connect to the container\n3. Review the container logs and resolve the output message regarding environment variable\n4. Confirm issue resolved by connecting to the container\n5. Exit the container\n6. List running containers\n7. List all containers\n8. List all images\n9. List all volumes\n10. Clean up with [`docker system prune`](https://docs.docker.com/engine/reference/commandline/system_prune/)\n11. Check all resources are deleted, containers, images and volumes.\n\n</div>\n\n<div id=\"soln-lab1-7\">\n\n<details>\n<summary>lab1.7 solution</summary>\n\n```sh\n# host terminal\ndocker run -d --name db mysql\ndocker exec -it db bash # error not running\ndocker logs db\ndocker rm db\ndocker run -d --name db -e MYSQL_ROOT_PASSWORD=secret mysql\ndocker ps\ndocker ps -a\ndocker image ls\ndocker volume ls\ndocker stop db\ndocker ps # no containers running\ndocker system prune --all --volumes\ndocker image ls\ndocker volume ls\n```\n\n</details>\n\n> You don't always have to run a new container, we have had to do this to apply new configuration. You can restart an existing container `docker ps -a`, if it meets your needs, with `docker start $CONTAINER`\n\n</div>\n\n<div id=\"lab1-8\">\n\n### Lab 1.8. Container registries\n\nExplore [Docker Hub](https://hub.docker.com/) and search for images you've used so far or images/applications you use day-to-day, like databases, environment tools, etc.\n\n> Container images are created with instructions that determine the default container behaviour at runtime. A familiarity with specific images/applications may be required to understand their default behaviours\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 2. Managing Container Images\n\nA docker image consist of layers, and each [image layer](https://vsupalov.com/docker-image-layers/) is its own image. An image layer is a change on an image - every command (FROM, RUN, COPY, etc.) in your Dockerfile (aka Containerfile by OCI) causes a change, thus creating a new layer. It is recommended reduce your image layers as best possible, e.g. replace multiple `RUN` commands with \"command chaining\" `apt update && apt upgrade -y`.\n\n> A name can be assigned to an image by \"tagging\" the image. This is often used to identify the image version and/or registry.\n\n```sh\n# to view image layers/history, see `docker image history --help`\ndocker image history $IMAGE_ID\n# tagging images, see `docker tag --help`\ndocker tag $IMAGE_NAME $NEW_NAME:$TAG # if tag is omitted, `latest` is used\ndocker tag nginx nginx:1.1\n# tags can also be used to add repository location\ndocker tag nginx domain.com/nginx:1.1\n```\n\n<div id=\"lab2-1\">\n\n### Lab 2.1. Working with images\n\n1. List all images (if you've just finished [lab1.7](#lab-17-container-environment-variables), run new container to download an image)\n2. Inspect one of the images with `| less` and review the `ContainerConfig` and `Config`\n3. View the image history\n4. Tag the image with the repository `localhost` and a version\n5. List all images\n6. View the tagged image history\n7. Delete tagged image by ID\n8. Lets try that again, delete tagged image by tag\n\n</div>\n\n<div id=\"soln-lab2-1\">\n\n<details>\n<summary>lab2.1 solution</summary>\n\n```sh\n# host terminal\ndocker image ls\n# using nginx image\ndocker image inspect nginx | grep -A 40 ContainerConfig | less\ndocker image inspect nginx | grep -A 40 '\"Config\"' | less\ndocker image history nginx\ndocker tag nginx localhost/nginx:1.1\ndocker image ls\ndocker image history localhost/nginx:1.1 # tagging isn't a change\ndocker image rm $IMAGE_ID # error conflict\ndocker image rm localhost/nginx:1.1 # deleting removes tag\n```\n\n</details>\n\n</div>\n\n<div id=\"lab2-2\">\n\n### Lab 2.2. Custom images\n\nAlthough, we can also [create an image from a running container using `docker commit`](https://docs.docker.com/engine/reference/commandline/commit/), we will only focus on using a Dockerfile, which is the recommended method.\n\nBuild the below Dockerfile with `docker build -t $IMAGE_NAME:$TAG /path/to/Dockerfile/directory`, see `docker build --help\n\n```Dockerfile\n# Example Dockerfile\nFROM ubuntu\nMAINTAINER Piouson\nRUN apt-get update && \\\n    apt-get install -y nmap iproute2 && \\\n    apt-get clean\nENTRYPOINT [\"/usr/bin/nmap\"]\nCMD [\"-sn\", \"172.17.0.0/16\"] # nmap will scan docker network subnet `172.17.0.0/16` for running containers\n```\n\n</div>\n\n### Dockerfile overview\n\n```sh\nFROM # specify base image\nRUN # execute commands\nENV # specify environment variables used by container\nADD # copy files from project directory to the image\nCOPY # copy files from local project directory to the image - ADD is recommended\nADD /path/to/local/file /path/to/container/directory # specify commands in shell form - space separated\nADD [\"/path/to/local/file\", \"/path/to/container/directory\"] # specify commands in exec form - as array (recommended)\nUSER # specify username (or UID) for RUN, CMD and ENTRYPOINT commands\nENTRYPOINT [\"command\"] # specify default command, `/bin/sh -c` is used if not specified - cannot be overwritten, so CMD is recommended for flexibility\nCMD [\"arg1\", \"arg2\"] # specfify arguments to the ENTRYPOINT - if ENTRYPOINT is not specified, args will be passed to `/bin/sh -c`\nEXPOSE $PORT # specify container should listen on port $PORT\n```\n\n<div id=\"lab2-3\">\n\n### Lab 2.3. Create image from Dockerfile\n\nSee [best practices for writing Dockerfile](https://docs.docker.com/develop/develop-images/dockerfile_best-practices).\n\n```sh\n# find a package containing an app (debian-based)\napt-file search --regex <filepath-pattern> # requires `apt-file` installation, see `apt-file --help`\napt-file search --regex \".*/sshd$\"\n# find a package containing an app, if app already installed (debian-based)\ndpkg -S /path/to/file/or/pattern # see `dpkg --help`\ndpkg -S */$APP_NAME\n# find a package containing an app (rpm-based)\ndnf provides /path/to/file/or/pattern\ndnf provides */sshd\n```\n\n1. Create a Dockerfile based on the following:\n   - Base image should be debian-based or rpm-based\n   - Should include packages containing `ps` application and network utilities like `ip`, `ss` and `arp`\n   - Should run the `nmap` process as the `ENTRYPOINT` with arguments `-sn 172.17.0.0/16`\n2. Build the Dockerfile with repository `local` and version `1.0`\n3. List images\n4. Run separate containers from the image as follows and review behaviour\n   - do not specify any modes\n   - in interactive mode with a shell\n   - in detached mode, then check the logs\n5. Edit the Dockerfile to run the same process and arguments but **not** as `ENTRYPOINT`\n6. Repeat all three options in [4] and compare the behaviour\n7. Clean up\n\n</div>\n\n<div id=\"soln-lab2-3\">\n\n<details>\n<summary>lab2.3 solution</summary>\n\n```sh\n# run ubuntu container to find debian-based packages\ndocker run -it --rm ubuntu\n# container terminal\napt update\napt install -y apt-file\napt-file update\napt-file search --regex \"bin/ip$\"\napt-file search --regex \"bin/ss$\"\napt-file search --regex \"bin/arp$\"\n# found `iproute2` and `net-tools`\nexit\n```\n\n```sh\n# alternatively, run fedora container to find rpm-based packages\ndocker run -it --rm fedora\n# container terminal\ndnf provides *bin/ip\ndnf provides *bin/ss\ndnf provides *bin/arp\n# found `iproute` and `net-tools`\nexit\n```\n\n```sh\n# host terminal\nmkdir test\nnano test/Dockerfile\n```\n\n```Dockerfile\n# Dockerfile\nFROM alpine\nRUN apk add --no-cache nmap iproute2 net-tools\nENTRYPOINT [\"/usr/bin/nmap\"]\nCMD [\"-sn\", \"172.17.0.0/16\"]\n```\n\n```sh\n# host terminal\ndocker build -t local/alpine:1.0 ./test\ndocker run --name alps1 local/alpine:1.0\ndocker run --name alps2 -it local/alpine:1.0 sh\ndocker run --name alps3 -d local/alpine:1.0\ndocker log alps3\nnano test/Dockerfile\n```\n\n```Dockerfile\n# Dockerfile\nFROM alpine\nRUN apk add --no-cache nmap iproute2 net-tools\nCMD [\"/usr/bin/nmap\", \"-sn\", \"172.17.0.0/16\"]\n```\n\n```sh\n# host terminal\ndocker build -t local/alpine:1.1 ./test\ndocker run --name alps4 local/alpine:1.0\ndocker run --name alps5 -it local/alpine:1.0 sh\n# container terminal\nexit\n# host terminal\ndocker run --name alps6 -d local/alpine:1.0\ndocker log alps6\ndocker stop alps3 alps5 alps6\ndocker rm alps1 alps2 alps3 alps4 alps5 alps6\ndocker image rm local/alpine:1.0 local/alpine:1.1\n```\n\n</details>\n\n> In most cases, building an image goes beyond a successful build. Some installed packages require additional steps to run containers successfully\n\n</div>\n\n<div id=\"lab2-4\">\n\n### Lab 2.4. Containerise your application\n\nSee the [official language-specific getting started guides](https://docs.docker.com/language/) which includes NodeJS, Python, Java and Go examples.\n\n1. Bootstrap a frontend/backend application project, your choice of language\n2. Install all dependencies and test the app works\n3. Create a Dockerfile to containerise the project\n4. Build the Dockerfile\n5. Run a container from the image exposed on port 8080\n6. Confirm you can access the app on http://localhost:8080\n\n</div>\n\n<div id=\"soln-lab2-4\">\n\n<details>\n<summary>lab2.4 nodejs solution</summary>\n\n```sh\n# host terminal\nnpx express-generator --no-view test-app\ncd test-app\nyarn\nyarn start # visit localhost:3000 if OK, ctrl+c to exit\necho node_modules > .dockerignore\nnano Dockerfile\n```\n\n```Dockerfile\n# Dockerfile\nFROM node:alpine\nENV NODE_ENV=production\nWORKDIR /app\nCOPY [\"package.json\", \"yarn.lock\", \"./\"]\nRUN yarn --frozen-lockfile --prod\nCOPY . .\nCMD [\"node\", \"bin/www\"]\nEXPOSE 3000\n```\n\n```sh\n# host terminal\ndocker build -t local/app:1.0 .\ndocker run -d --name app -p 8080:3000 local/app:1.0\ncurl localhost:8080\ndocker stop app\ndocker rm app\ndocker image rm local/app:1.0\ncd ..\nrm -rf test-app\n```\n\n</details>\n\n</div>\n\n### Docker container access control\n\nBefore we finally go into Kubernetes, it would be advantageous to have a basic understanding of unix-based systems file permissions and access control.\n\n#### UID and GID\n\nA _user identifier (UID)_ is a unique number assigned to each user. This is how the system identifies each user. The root user has UID of 0, UID 1-500 are often reserved for system users and UID for new users commonly start at 1000. UIDs are stored in the plain-text `/etc/passwd` file: each line represents a user account, and has seven fields delimited by colons `account:password:UID:GID:GECOS:directory:shell`.\n\nA _group identifier (GID)_ is similar to UIDs - used by the system to identify _groups_. A _group_ consists of several users and the root group has GID of 0. GIDs are stored in the plain-text `/etc/group` file: each line represents a group, and has four fields delimited by colons `group:password:GID:comma-separated-list-of-members`. An example of creating and assigning a group was covered in [step 4 - docker engine installation](#docker-engine-installation) where we created and assigned the `docker` group.\n\nUIDs and GIDs are used to implement _Discretionary Access Control (DAC)_ in unix-based systems by assigning them to files and processes to denote ownership - _left at owner's discretion_. This can be seen by running `ls -l` or `ls -ln`: the output has seven fields delimited by spaces `file_permisions number_of_links user group size date_time_created file_or_folder_name`. See [unix file permissions](https://www.guru99.com/file-permissions.html) for more details.\n\n<details>\n<summary><code>ls -l</code> in detail</summary>\n\n![output of commandline list](https://user-images.githubusercontent.com/17856665/187016629-e6c4f17f-f06a-4aeb-98c4-0cfc4d371be2.png)\n\n</details>\n\n```sh\n# show current user\nwhoami\n# view my UID and GID, and my group memberships\nid\n# view the local user database on system\ncat /etc/passwd\n# output - `account:password:UID:GID:GECOS:directory:shell`\nroot:x:0:0:root:/root:/bin/bash\npiouson:x:1000:1000:,,,:/home/dev:/bin/bash\n# view the local group database on system\ncat /etc/group\n# output - `group:password:GID:comma-separated-list-of-member`\nroot:x:0:\npiouson:x:1000:\ndocker:x:1001:piouson\n# list folder contents and their owner (user/group) names\nls -l\n# show ownership by ids, output - `permision number_of_links user group size date_time_created file_or_folder_name`\nls -ln\n```\n\n#### Capabilities\n\nIn the context of permission checks, processes running on unix-based systems are traditionally categorised as:\n\n- _privileged_ processes: effective UID is 0 (root) - bypass all kernel permission checks\n- _unprivileged_ processes: effective UID is nonzero - subject to permission checks\n\nStarting with kernel 2.2, Linux further divides traditional root privileges into distinct units known as _capabilities_ as a way to control root user powers. Each root _capability_ can be independently enabled and disabled. \\\nSee the [overview of Linux _capabilities_](https://man7.org/linux/man-pages/man7/capabilities.7.html) for more details, including a comprehensive list of capabilities.\n\n> `CAP_SYS_ADMIN` is an overloaded capability that grants privileges similar to traditional root privileges \\\n> By default, Docker containers are **_unprivileged_** and root in a docker container uses [_restricted capabilities_](https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities) \\\n> ❌ `docker run --privileged` gives all capabilities to the container, allowing nearly all the same access to the host as processes running on the host\n\n#### Running containers as non-root\n\nFor practical reasons, most containers run as root by default. However, in a security context, this is bad practice:\n\n- it voilates the [_principle of least privilege_](https://en.wikipedia.org/wiki/Principle_of_least_privilege)\n- an attacker might take advantage of an application vulnerability to gain root access to the container\n- an attacker might take advantage of a container-runtime, or kernel, vulnerability to gain root access to the host after gaining access to the container\n\nWe can control the users containers run with by:\n\n- omitting the `USER` command in Dockerfile assigns root\n- specify a user in the `Dockerfile` with the `USER` command\n- override the UID at runtime with `docker run --user $UID`\n\n```Dockerfile\n# Dockerfile\nFROM ubuntu\n# create group `piouson`, and create user `piouson` as member of group `piouson`, see `groupadd -h` and `useradd -h`\nRUN groupadd piouson && useradd piouson --gid piouson\n# specify GID/UID when creating/assigning a group/user\nRUN groupadd --gid 1004 piouson && useradd --uid 1004 piouson --gid piouson\n# assign user `piouson` for subsequent commands\nUSER piouson\n# create system-group `myapp`, and create system-user `myapp` as member of group `myapp`\nRUN groupadd --system myapp && useradd --system --no-log-init myapp --gid myapp\n# assign system-user `myapp` for subsequent commands\nUSER myapp\n```\n\n<div id=\"lab2-5\">\n\n### Lab 2.5. Container privileges\n\n1. Display your system's current user\n2. Display the current user's UID, GID and group memberships\n3. Run a `ubuntu` container interactively, and in the container shell:\n   - display the current user\n   - display the current user's UID, GID and group memberships\n   - list existing user accounts\n   - list existing groups\n   - create a file called `test-file` and display the file ownership info\n   - exit the container\n4. Run a new `ubuntu` container interactively with UID 1004, and in the container shell:\n   - display the current user\n   - display the current user's UID, GID and group memberships\n   - exit the container\n5. Create a docker image based on `ubuntu` with a non-root user as default user\n6. Run a container interactively using the image, and in the container shell:\n   - display the current user\n   - display the current user's UID, GID and group memberships\n   - exit the container\n7. Delete created resources\n\n</div>\n\n<div id=\"lab2-5\">\n\n<details>\n<summary>lab2.5 solution</summary>\n\n```sh\n# host terminal\nwhoami\nid\ndocker run -it --rm ubuntu\n# container terminal\nwhoami\nid\ncat /etc/passwd\ncat /etc/group\ntouch test-file\nls -l\nls -ln\nexit\n# host terminal\ndocker run -it --rm --user 1004 ubuntu\n# container terminal\nwhoami\nid\nexit\n```\n\n```Dockerfile\n# test/Dockerfile\nFROM ubuntu\nRUN groupadd --gid 1000 piouson && useradd --uid 1000 piouson --gid 1000\nUSER piouson\n```\n\n```sh\n# host terminal\ndocker build -t test-image test/\ndocker run -it --rm test-image\n# container terminal\nwhoami\nid\nexit\n# host terminal\ndocker image rm test-image\n```\n\n</details>\n\n> If a containerized application can run without privileges, change to a non-root user \\\n> It is recommended to explicitly specify GID/UID when creating a group/user\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n<div id=\"task2-1\">\n\n### Task - Docker image\n\n```Dockerfile\nFROM nginx:1.22-alpine\nEXPOSE 80\n```\n\nUsing docker and the Dockerfile above, build an image with tag `bootcamp/nginx:v1` and tag `ckad/nginx:latest`. Once complete, export a tar file of the image to `/home/$USER/ckad-tasks/docker/nginx.tar`. \\\nRun a container named `web-test` from the image `bootcamp/nginx:v1` accessible on port 2000, and another container named `web-test2` from image `ckad/nginx:latest` accessible on port 2001. Leave both containers running.\n\nWhat commands would you use to perform the above operations using `podman`? Specify these commands on separate lines in file `/home/$USER/ckad-tasks/docker/podman-commands`\n\n</div>\n\n<div id=\"hint-task2-1\">\n\n<details>\n  <summary>hints</summary>\n\n  <details>\n  <summary>hint 1</summary>\n\n  You can specify multiple tags when building an image `docker build -t tag1 -t tag2 /path//to/dockerfile-directory`\n  </details>\n\n  <details>\n  <summary>hint 2</summary>\n\n  Try to find the command for exporting a docker image with `docker image --help`\n  </details>\n\n  <details>\n  <summary>hint 2</summary>\n\n  Did you run the containers in detached mode?\n  </details>\n\n  <details>\n  <summary>hint 3</summary>\n\n  You can export a docker image to a tar file with `docker image save -o /path/to/output/file $IMAGE_NAME`\n  </details>\n\n  <details>\n  <summary>hint 4</summary>\n\n  Did you expose the required ports when creating the containers? You can use `docker run -p $HOST_PORT:$CONTAINER_PORT`\n  </details>\n\n  <details>\n  <summary>hint 5</summary>\n\n  Did you verify the containers running at exposed ports `curl localhost:2000` and `curl localhost:2001`?\n  </details>\n\n  <details>\n  <summary>hint 6</summary>\n\n  Docker and Podman have interchangeable commands, therefore, the only change is `docker -> podman`, For example, `docker run -> podman run`, `docker build -> podman build`, etc.\n  </details>\n</details>\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 3. Understanding Kubernetes\n\n[K8s](kubernetes.io) is an open-source system for automating deployment, scaling and containerized applications management, currently owned by the [Cloud Native Computing Foundation (CNCF)](https://www.cncf.io/). \\\nK8s **release cycle is 3 months** and deprecated features are supported for a minimum of 2 release cycles (6 months).\n\n> You can watch [kubernetes in 1 minute](https://www.youtube.com/watch?v=BzvLp-lH5_Q&list=PLBBog2r6uMCSplEmHu-1n7VixRn9RTZP5&index=6) for a quick overview \\\n> When you've got more time, watch/listen to **Kubernetes: The Documentary ([PART 1](https://www.youtube.com/watch?v=BE77h7dmoQU) & [PART 2](https://www.youtube.com/watch?v=318elIq37PE))**\n\n<div id=\"lab3-1\">\n\n### Lab 3.1. Kubernetes in Google Cloud\n\n> A local lab setup is covered in [chapter 4 with minikube](#4-kubernetes-lab-environment) \\\n> Skip this lab if you do not currently have a Google Cloud account with Billing enabled\n\n- Signup and Login to [console.cloud.google.com](https://console.cloud.google.com)\n- Use the \"Cluster setup guide\" to create \"My first cluster\"\n- Connect to the cluster using the \"Cloud Shell\"\n- View existing Kubernetes resources by running `kubectl get all`\n\n</div>\n\n### Basic Kubernetes API resources\n\nEntities in Kubernetes are recorded in the Kubernetes system as _Objects_, and they represent the state of your cluster. [_Kubernetes objects_](https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects) can describe:\n\n- what containerized applications are running (and on which nodes)\n- resources available to those applications\n- policies around applications behaviour - restarts, upgrades, fault-tolerance, etc\n\nSome common _Kubernetes objects_ include:\n\n- Deployment: represents the application and provides services\n- ReplicaSet: manages scalability - array of pods\n- Pods: manages containers (**note that one container per pod is the standard**)\n\n<details>\n  <summary>Kubernetes architecture</summary>\n  \n![kubernetes-architecture from https://platform9.com/blog/kubernetes-enterprise-chapter-2-kubernetes-architecture-concepts/](https://user-images.githubusercontent.com/17856665/185714430-afe68ed2-9593-47c1-b032-b9ad9630f9fa.png)\n</details>\n\n<details>\n  <summary>Pods architecture</summary>\n  \n![pods-architecture from https://platform9.com/blog/kubernetes-enterprise-chapter-2-kubernetes-architecture-concepts/](https://user-images.githubusercontent.com/17856665/185716058-b9b273ab-295b-4a5a-9d63-31b6f0d25e2c.jpg)\n</details>\n\n```sh\n# help\nkubectl --help | less\n# view available resources\nkubectl get all, see `kubectl get --help`\n# create a deployment, see `kubectl create deploy -h`\nkubectl create deploy myapp --image=nginx\n# create a deployment with six replicas\nkubectl create deploy myapp --image=nginx --replicas=6\n# view complete list of supported API resources, shows api-versions and their resource types\nkubectl api-resources\n# view api-versions only\nkubectl api-versions\n# delete a deployment, see `kubectl delete --help`\nkubectl delete deploy myapp\n```\n\n<div id=\"lab3-2\">\n\n### Lab 3.2. Explore Kubernetes API resources via Google Cloud\n\n> This lab is repeated in [chapter 4 with minikube](#4-kubernetes-lab-environment) \\\n> Skip this lab if you do not currently have a Google Cloud account with Billing enabled\n\n1. Create an `nginx` application with three replicas\n2. View available resources\n3. Delete a pod create\n4. View available resources, how many pods left, can you find the deleted pod?\n5. List supported API resources\n6. Delete the application\n7. view available resource\n8. Delete the Kubernetes service\n9. view available resources\n10. If nothing found, allow 5s and try [9] again\n\n</div>\n\n<div id=\"soln-lab3-2\">\n\n<details>\n<summary>lab3.2 solution</summary>\n\n```sh\nkubectl create deploy webserver --image=nginx --replicas=3\nkubectl get all\nkubectl delete pod $POD_NAME\nkubectl get all # new pod auto created to replace deleted\nkubectl api-resources\nkubectl delete deploy webserver\nkubectl get all\nkubectl delete svc kubernetes\nkubectl get all # new kubernetes service is auto created to replace deleted\n```\n\n</details>\n\n> Remember to delete Google cloud cluster to avoid charges if you wish to use a local environment detailed in the next chapter\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 4. Kubernetes Lab Environment\n\n```sh\n# check kubernetes version\nkubectl version\n# list kubernetes context (available kubernetes clusters - docker-desktop, minikube, etc)\nkubectl config get-contexts\n# switch kubernetes context\nkubectl config use-context docker-desktop\n```\n\n### Use Docker Desktop\n\n<details>\n  <summary>Enable Kubernetes in Docker Desktop settings, then apply and restart</summary>\n  \n  ![image](https://user-images.githubusercontent.com/17856665/178120815-357cea98-ecf1-4536-81af-a614b7b4cf5e.png)\n</details>\n\n> See Docker's [Deploy on Kubernetes](https://docs.docker.com/desktop/kubernetes/) for more details \\\n> Note that using Docker Desktop will have network limitations when exposing your applications publicly, see alternative Minikube option below\n\n### Use Minikube\n\nMinikube is the recommended Kubernetes solution for this course on a local lab environment. See the [official minikube installation docs](https://minikube.sigs.k8s.io/docs/start/).\n\n> [Kubernetes v1.24+ has deprecated docker as a container-runtime and now uses cri-o](https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/). Therefore, we use Kubernetes v1.23 to avoid installing cri-o and its dependencies.\n\n#### Install Minikube on macOS\n\n```sh\n# 1. install minikube\ncurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64\nsudo install minikube-darwin-amd64 /usr/local/bin/minikube\nrm minikube-darwin-amd64\n# 2. start a minikube cluster\nminikube start --kubernetes-version=1.23.9\n```\n\n#### Install Minikube on Windows WSL2\n\n```sh\n# 1. install minikube\ncurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\nchmod +x ./minikube-linux-amd64\nsudo install minikube-linux-amd64 /usr/local/bin/minikube\nrm minikube-linux-amd64\n# 2. install minikube prereqs - conntrack\nsudo apt install conntrack\nsudo sysctl fs.protected_regular=0\n# 3. start a minikube cluster\nminikube start --driver=docker --kubernetes-version=1.23.9\n# if [3] doesn't work, e.g. vpn issue, etc, try `--driver=none`\n# sudo minikube start --driver=none --kubernetes-version=1.23.9\n# 4. change the owner of the .kube and .minikube directories\nsudo chown -R $USER $HOME/.kube $HOME/.minikube\n```\n\n#### Minikube commands\n\n```sh\n# show current status, see `minikube --help`\nminikube status\n# open K8s dashboard in local browser\nminikube dashboard\n# start a minikube cluster with latest k8s version and default driver, see `minikube --help`\nminikube start\n# start minikube with a specified driver and specified kubernetes version\nminikube start --driver=docker --kubernetes-version=1.23.9\n# show current IP address\nminikube ip\n# show current version\nminikube version\n# connect to minikube cluster\nminikube ssh\n# list addons\nminikube addons list\n# enable addons\nminikube addons enable $ADDON_NAME\n# stop running minikube cluster\nminikube stop\n# delete stopped minikube cluster\nminikube delete\n```\n\n<div id=\"lab4-1\">\n\n### Lab 4.1. Setup minikube and kubectl\n\n1. Confirm minikube running `minikube status`\n2. Create `kubectl` alias in `.bashrc`\n   ```sh\n   printf \"\n   # minikube kubectl\n   alias kubectl='minikube kubectl --'\n   \" >> ~/.bashrc\n   exec bash\n   ```\n3. Start using the alias\n   ```sh\n   kubectl version\n   kubectl get all\n   ```\n4. Enable kubectl autocompletion, see `kubectl completion --help`\n   ```sh\n   echo \"source <(kubectl completion bash)\" >> ~/.bashrc # macos replace bash with zsh\n   exec bash\n   ```\n5. The default `kubectl edit` text editor is `vi`. To change this:\n   ```sh\n   export KUBE_EDITOR=\"nano\" # use nano\n   export KUBE_EDITOR=\"vim\" # use vim\n   ```\n6. Open the kubernetes dashboard with `minikube dashboard`\n7. Use the Kubernetes Dashboard to deploy a webserver with three replicas\n   - visit url provided in browser\n   - click on top right plus \"+\" icon\n   - select `Create from form`\n   - enter App name: `app`, Container image: `nginx`, Number of pods: `3`\n   - click `Deploy`\n8. Return to the terminal and delete created resources\n   ```sh\n   ctrl+c # to terminate dashboard\n   kubectl get all\n   kubectl delete deploy app\n   ```\n9. List Kubernetes clusters with `kubectl config get-contexts`\n10. If you have Kubernetes cluster from both Minikube and Docker Desktop, you can switch between them:\n   - Set Docker Desktop cluster as current cluster: `kubectl config set-context docker-desktop`\n   - Set Minikube cluster as current cluster: `kubectl config set-context minikube`\n\n</div>\n\n<div id=\"lab4-2\">\n\n### Lab 4.2. Explore Kubernetes API resources via Minikube\n\n1. Run an `nginx` Pod\n2. View resources\n3. Delete the Pod\n4. View resources\n5. Repeat [Lab 3.2](#lab-32-explore-kubernetes-api-resources-via-gcloud) in Minikube\n\n</div>\n\n<div id=\"soln-lab4-2\">\n\n<details>\n<summary>lab4.2 solution</summary>\n\n```sh\nkubectl run webserver --image=nginx\nkubectl get all\nkubectl delete pod webserver\nkubectl get all # pod gone\n# see `lab3.2 solution` for remaining steps\n```\n\n</details>\n\n> Pods started without a deployment are called _Naked Pods_ - these are not managed by a replicaset, therefore, are not rescheduled on failure, not eligible for rolling updates, cannot be scaled, cannot be replaced automatically. \\\n> Although, _Naked Pods_ are not recommended in live environments, they are crucial for learning how to manage Pods, which is a big part of [CKAD](https://www.cncf.io/certification/ckad/).\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 5. Pods\n\n[Pods](https://kubernetes.io/docs/concepts/workloads/pods/) are the smallest deployable units of computing that you can create and manage in Kubernetes.\n\n### Managing Pods\n\n```sh\n# run a pod, see `kubectl run --help`\nkubectl run $POD_NAME $IMAGE_NAME\n# run a nginx pod with custom args, args are passed to the pod's container's `ENTRYPOINT`\nkubectl run mypod --image=nginx -- <arg1> <arg2> ... <argN>\n# run a command in an nginx pod\nkubectl run mypod --image=nginx --command -- <command>\n# run a busybox pod interactively and delete after task completion\nkubectl run -it mypod --image=busybox --rm --restart=Never -- date\n# to specify the port exposed by the image is 8080\nkubectl run mypod --port=8080 --image=image-that-uses-port-8080\n# connect a shell to a running pod `mypod`\nkubectl exec mypod -it -- sh\n# list pods, see `kubectl get --help`\nkubectl get pods # using `pod` or `pods` will work\n# only show resource names when listing pods\nkubectl get pods -o name | less\n# display full details of pod in YAML form\nkubectl get pods $POD_NAME -o yaml | less\n# show details of pod in readable form, see `kubectl describe --help`\nkubectl describe pods $POD_NAME | less\n# view the pod spec\nkubectl explain pod.spec | less\n```\n\n> With `kubectl`, everything after the `--` flag is passed to the Pod \\\n> 💡 `-- <args>` corresponds to Dockerfile `CMD` while `--command -- <args>` corresponds to `ENTRYPOINT` \\\n> See [answer to `kubectl run --command vs -- arguments`](https://stackoverflow.com/a/66078726) for more details\n\n<div id=\"lab5-1\">\n\n### Lab 5.1. Creating Pods\n\n1. Create a Pod with `nginx:alpine` image and confirm creation\n2. Review full details of the Pod in YAML form\n3. Display details of the Pod in readable form and review the Node, IP, container start date/time and Events\n4. List pods but only show resource names\n5. Connect a shell to the Pod and confirm an application is exposed\n   - By default, Nginx exposes applications on port 80\n   - confirm exposed ports\n5. Delete the Pod\n6. Review the Pod spec\n7. Have a look at the Kubernetes API to determine when pods were introduced\n\n> Not all images expose their applications on port 80. Kubernetes doesn't have a native way to check ports exposed on running container, however, you can connect a shell to a Pod with `kubectl exec` and try one of `netstat -tulpn` or `ss -tulpn` in the container, if installed, to show open ports.\n\n</div>\n\n<div id=\"soln-lab5-1\">\n\n<details>\n<summary>lab5.1 solution</summary>\n\n```sh\n# host terminal\nkubectl run mypod --image=nginx:alpine\nkubectl get pods\nkubectl describe pods mypod | less\nkubectl get pods -o name\nkubectl exec -it mypod -- sh\n# container terminal\ncurl localhost # or curl localhost:80, can omit since 80 is the default\nnetstat -tulpn\nss -tulpn\nexit\n# host terminal\nkubectl delete pods mypod\nkubectl explain pod.spec\nkubectl api-resources # pods were introduced in v1 - the first version of kubernetes\n```\n\n</details>\n\n</div>\n\n### Pod manifest file\n\nExample of a Pod manifest file with a `busybox` image and mounted _empty-directory_ volume.\n\n```yaml\napiVersion: v1 # api version\nkind: Pod # type of resource, pod, deployment, configmap, etc\nmetadata:\n  name: box # metadata information, including labels, namespace, etc\nspec:\n  volumes: # create an empty-directory volume\n  - name: varlog\n    emptyDir: {}\n  containers:\n  - name: box\n    image: busybox:1.28\n    volumeMounts: # mount created volume\n    - name: varlog\n      mountPath: /var/log\n```\n\n> Volumes are covered in more detail in [Chapter 10 - Storage](#10-storage). For now it will suffice to know how to create and mount an _empty-directory_ volume\n\n```sh\n# view description of a Kubernetes Object with `kubectl explain <object>[.field]`, see `kubectl explain --help`\nkubectl explain pod\nkubectl explain pod.metadata # or `pod.spec`, `pod.status` etc\n# include nested fields with `--recursive`\nkubectl explain --recursive pod.spec | less\n# perform actions on a resource with a YAML file\nkubectl {create|apply|replace|delete} -f pod.yaml\n# generate YAML file of a specific command with `--dry-run`\nkubectl run mynginx --image=nginx -o yaml --dry-run=client > pod.yaml\n```\n\n> Object fields are **case sensitive**, **always generate** manifest files to avoid typos \\\n> `kubectl apply` creates a new resource, or updates existing if previously created by `kubectl apply`\n\n### Valid reasons for multi-container Pods\n\n**Always create single container Pods!** However, some special scenarios require a [multi-container Pod pattern](https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns/):\n\n- To initialise primary container ([Init Container](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/#understanding-init-containers))\n- To enhance primary container, e.g. for logging, monitoring, etc. ([Sidecar Container](https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns/#example-1-sidecar-containers))\n- To prevent direct access to primary container, e.g. proxy ([Ambassador Container](https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns/#example-2-ambassador-containers))\n- To match the traffic/data pattern in other applications in the cluster ([Adapter Container](https://kubernetes.io/blog/2015/06/the-distributed-system-toolkit-patterns/#example-3-adapter-containers))\n\n<div id=\"lab5-2\">\n\n### Lab 5.2. Managing Pods with YAML file\n\n> In the official k8s docs, you will often find example code with a URL, e.g. `pods/commands.yaml`. The file can be downloaded by appending `https://k8s.io/examples` to the URL, thus: `https://k8s.io/examples/pods/commands.yaml`\n\n```sh\n# download file `pods/commands.yaml`\nwget https://k8s.io/examples/pods/commands.yaml\n# save downloaded file with a new name `comm.yaml`\nwget https://k8s.io/examples/pods/commands.yaml -O comm.yaml\n# hide output while downloading\nwget -q https://k8s.io/examples/pods/commands.yaml\n# view contents of a downloaded file without saving\nwget -O- https://k8s.io/examples/pods/commands.yaml\n# view contents quietly without saving\nwget -qO- https://k8s.io/examples/pods/commands.yaml\n```\n\n1. Generate a YAML file of a `busybox` Pod that runs the command `sleep 60`, see [create Pod with command and args docs](https://kubernetes.io/docs/tasks/inject-data-application/define-command-argument-container/#define-a-command-and-arguments-when-you-create-a-pod)\n2. Apply the YAML file.\n3. List created resources\n4. View details of the Pod\n5. Delete the Pod\n\n</div>\n\n<div id=\"soln-lab5-2\">\n\n<details>\n<summary>lab5.2 solution</summary>\n\n```sh\nkubectl run mypod --image=busybox --dry-run=client -o yaml --command -- sleep 60 > lab5-2.yaml\nkubectl apply -f lab5-2.yaml\nkubectl get pods\nkubectl describe pods mypod | less\nkubectl delete -f lab5-2.yaml\n```\n\n</details>\n\n> Some images, like busybox, do not remain in running state by default. An extra command is required, e.g. `sleep 60`, to keep containers using these images in running state for as long as you need. In the CKAD exam, make sure your Pods remain in running states unless stated otherwise\n\n</div>\n\n<div id=\"lab5-3\">\n\n### Lab 5.3. Init Containers\n\nNote that the main container will only be started after the _init container_ enters `STATUS=completed`\n\n```sh\n# view logs of pod `mypod`\nkubectl logs mypod\n# view logs of specific container `mypod-container-1` in pod `mypod`\nkubectl logs mypod -c mypod-container-1\n```\n\n1. Create a Pod that logs `App is running!` to STDOUT\n   - use `busybox:1.28` image\n   - the application should `Never` restart\n   - the application should use a _Init Container_ to wait for 60secs before starting\n   - the _Init Container_ should log `App is initialising...` to STDOUT\n   - see [init container docs](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/#init-containers-in-use).\n2. List created resources and note Pod `STATUS`\n3. View the logs of the main container\n4. View the logs of the _init container_\n5. View more details of the Pod and note the `State` of both containers.\n6. List created resources and confirm Pod `STATUS`\n7. Delete Pod\n\n</div>\n\n<div id=\"soln-lab5-3\">\n\n<details>\n<summary>lab5.3 solution</summary>\n\n```sh\n# partially generate pod manifest\nkubectl run myapp --image=busybox:1.28 --restart=Never --dry-run=client -o yaml --command -- sh -c \"echo App is running!\" > lab5-3.yaml\n```\n\n```yaml\n# edit lab5-3.yaml to add init container spec\napiVersion: v1\nkind: Pod\nmetadata:\n  labels:\n    run: myapp\n  name: myapp\nspec:\n  containers:\n    - name: myapp\n      image: busybox:1.28\n      command: [\"sh\", \"-c\", \"echo App is running!\"]\n  initContainers:\n    - name: myapp-init\n      image: busybox:1.28\n      command: [\"sh\", \"-c\", 'echo \"App is initialising...\" && sleep 60']\n  restartPolicy: Never\n```\n\n```sh\nkubectl apply -f lab5-3.yaml\nkubectl get pods\nkubectl logs myapp # not created until after 60secs\nkubectl logs myapp -c myapp-init\nkubectl describe -f lab5-3.yaml | less\nkubectl get pods\nkubectl delete -f lab5-3.yaml\n```\n\n</details>\n\n</div>\n\n<div id=\"lab5-4\">\n\n### Lab 5.4. Multi-container Pod\n\n1. Create a Pod with 2 containers and a volumne shared by both containers, see [multi-container docs](https://kubernetes.io/docs/tasks/access-application-cluster/communicate-containers-same-pod-shared-volume/#creating-a-pod-that-runs-two-containers).\n2. List created resources\n3. View details of the Pod\n4. Delete the Pod\n\n<details>\n<summary>lab5.4 solution</summary>\n\n```yaml\n# lab5-4.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp\nspec:\n  containers:\n    - name: myapp-1\n      image: busybox:1.28\n      volumeMounts:\n        - name: logs\n          mountPath: /var/log\n    - name: myapp-2\n      image: busybox:1.28\n      volumeMounts:\n        - name: logs\n          mountPath: /var/log\n  volumes:\n    - name: logs\n      emptyDir: {}\n```\n\n```sh\nkubectl apply -f lab5-4.yaml\nkubectl get pods\nkubectl describe pods myapp | less\nkubectl logs myapp -c myapp-1\nkubectl logs myapp -c myapp-2\nkubectl delete -f lab5-4.yaml\n```\n\n</details>\n\n> Always create single container Pods!\n\n</div>\n\n<div id=\"lab5-5\">\n\n### Lab 5.5. Sidecar Containers\n\n> Remember you can prepend [`https://k8s.io/examples/`](https://kubernetes.io/docs/concepts/workloads/pods/#using-pods) to any example manifest names from the official docs for direct download of the YAML file\n\n1. Create a `busybox` Pod that logs `date` to a file every second\n   - expose the logs with a _sidecar container_'s STDOUT to prevent direct access to the main application\n   - see example _sidecar container_ manifest `https://k8s.io/examples/admin/logging/two-files-counter-pod-streaming-sidecar.yaml`\n2. List created resources\n3. View details of the Pod\n4. View the logs of the main container\n5. View the logs of the _sidecar container_\n6. Delete created resources\n\n</div>\n\n<div id=\"soln-lab5-5\">\n\n<details>\n<summary>lab5.5 solution</summary>\n\n```yaml\n# lab5-5.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: myapp\nspec:\n  containers:\n    - name: myapp\n      image: busybox:1.28\n      args:\n        - /bin/sh\n        - -c\n        - >\n          while true;\n          do\n            echo $(date) >> /var/log/date.log;\n            sleep 1;\n          done\n      volumeMounts:\n        - name: logs\n          mountPath: /var/log\n    - name: myapp-logs\n      image: busybox:1.28\n      args: [/bin/sh, -c, \"tail -F /var/log/date.log\"]\n      volumeMounts:\n        - name: logs\n          mountPath: /var/log\n  volumes:\n    - name: logs\n      emptyDir: {}\n```\n\n```sh\nkubectl apply -f lab5-5.yaml\nkubectl get pods\nkubectl describe pods myapp | less\nkubectl logs myapp -c myapp\nkubectl logs myapp -c myapp-logs\nkubectl delete -f lab5-5.yaml\n```\n\n</details>\n\n</div>\n\n### Using namespaces\n\n[Namespaces](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/) are a way to divide/isolate cluster resources between multiple users. Names of resources need to be unique within a Namespace, but not across namespaces. \\\nNot all Kubernetes resources are in a Namespace and Namespace-based scoping is only applicable for namespaced objects.\n\n> Namespaces should be used sensibly, you can read more about [understanding the motivation for using namespaces](https://kubernetes.io/docs/tasks/administer-cluster/namespaces/#understanding-the-motivation-for-using-namespaces)\n\n```sh\n# create namespace called `myns`, see `kubectl create namespace -h`\nkubectl create namespace myns\n# run a pod in the `myns` namespace with `-n myns`\nkubectl run mypod --image=imageName -n myns\n# view pods in the `myns` namespaces\nkubectl get pods -n myns\n# list pods in all namespaces with `--all-namespaces` or `-A`\nkubectl get pods --all-namespaces\n# list all resources in all namespaces\nkubectl get all --all-namespaces\n# view the current namespace in use for commands\nkubectl config view --minify | grep namespace:\n# set `myns` namespace to be the namespace used for subsequent commands\nkubectl config set-context --current --namespace=myns\n# view kubernetes api resources in a namespace\nkubectl api-resources --namespaced=true\n# view kubernetes api resources not in a namespace\nkubectl api-resources --namespaced=false\n# view the namespace object\nkubectl explain namespace | less\n# view the namespace object recursively\nkubectl explain namespace --recursive | less\n```\n\n<div id=\"lab5-6\">\n\n### Lab 5.6 Namespaces\n\nYou can also follow the [admin guide doc for namespaces](https://kubernetes.io/docs/tasks/administer-cluster/namespaces/)\n\n> Remember you can connect a shell to a Pod with `kubectl exec` and try one of `netstat -tulpn` or `ss -tulpn` in the container, if installed, to show open ports.\n\n1. Create a Namespace `myns`\n2. Create a webserver Pod in the `myns` Namespace\n3. Review created resources and confirm `myns` Namespace is assigned to the Pod\n4. Delete resources created\n5. Review the `NAMESPACED` column of the Kubernetes API resources\n6. Review the Namespace object and the Namespace spec\n\n</div>\n\n<div id=\"soln-lab5-6\">\n\n<details>\n<summary>lab5.6 solution</summary>\n\n```sh\nkubectl create ns myns --dry-run=client -o yaml > lab5-6.yaml\necho --- >> lab5-6.yaml\nkubectl run mypod --image=httpd:alpine -n myns --dry-run=client -o yaml >> lab5-6.yaml\nkubectl apply -f lab5-6.yaml\nkubectl get pods\nkubectl describe -f lab5-6.yaml | less\nkubectl delete -f lab5-6.yaml\nkubectl api-resources | less\nkubectl explain namespace | less\nkubectl explain namespace --recursive | less\nkubectl explain namespace.spec | less\n```\n\n</details>\n\n> Remember that namespaced resources are not visible by default unless the namespace is specified \\\n> 💡 `kubectl get pods` - only shows resources in the `default` namespace \\\n> 💡 `kubectl get pods -n mynamespace` - shows resources in the `mynamespace` namespace\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n<div id=\"task5-1\">\n\n### Task - Pods\n\nImagine a student in the CKAD Bootcamp training reached out to you for assistance to finish their homework. Their task was to create a `webserver` with a sidecar container for logging in the `cow` namespace. Find this Pod, which could be located in one of the Namespaces `ape`, `cow` or `fox`, and ensure it is configured as required.\n\nAt the end of your task, copy the log file used by the logging container to directory `/home/$USER/ckad-tasks/pods/`\n\n- Command to setup environment:\n  ```sh\n  printf '\\nlab: environment setup in progress...\\n'; echo '{\"apiVersion\":\"v1\",\"items\":[{\"kind\":\"Namespace\",\"apiVersion\":\"v1\",\"metadata\":{\"name\":\"fox\"}},{\"kind\":\"Namespace\",\"apiVersion\":\"v1\",\"metadata\":{\"name\":\"ape\"}},{\"kind\":\"Namespace\",\"apiVersion\":\"v1\",\"metadata\":{\"name\":\"cow\"}},{\"apiVersion\":\"v1\",\"kind\":\"Pod\",\"metadata\":{\"labels\":{\"run\":\"box\"},\"name\":\"box\",\"namespace\":\"ape\"},\"spec\":{\"containers\":[{\"args\":[\"sleep\",\"3600\"],\"image\":\"busybox\",\"name\":\"box\"}],\"dnsPolicy\":\"ClusterFirst\",\"restartPolicy\":\"Always\"}},{\"apiVersion\":\"v1\",\"kind\":\"Pod\",\"metadata\":{\"labels\":{\"run\":\"for-testing\"},\"name\":\"for-testing\",\"namespace\":\"fox\"},\"spec\":{\"containers\":[{\"args\":[\"sleep\",\"3600\"],\"image\":\"busybox\",\"name\":\"for-testing\"}],\"dnsPolicy\":\"ClusterFirst\",\"restartPolicy\":\"Always\"}},{\"apiVersion\":\"v1\",\"kind\":\"Pod\",\"metadata\":{\"labels\":{\"run\":\"webserver\"},\"name\":\"webserver\",\"namespace\":\"fox\"},\"spec\":{\"containers\":[{\"name\":\"server\",\"image\":\"ngnx:1.20-alpine\",\"volumeMounts\":[{\"name\":\"serverlog\",\"mountPath\":\"/usr/share/nginx/html\"}]},{\"name\":\"logger\",\"image\":\"busybox:1.28\",\"args\":[\"/bin/sh\",\"-c\",\"while true; do  echo $(date) >> /usr/share/nginx/html/1.log;\\n  sleep 30;\\ndone\\n\"],\"volumeMounts\":[{\"name\":\"serverlog\",\"mountPath\":\"/usr/share/nginx/html\"}]}],\"volumes\":[{\"name\":\"serverlog\",\"emptyDir\":{}}]}}],\"metadata\":{\"resourceVersion\":\"\"},\"kind\":\"List\"}' | kubectl apply -f - >/dev/null; echo 'lab: environment setup complete!'\n  ```\n- Command to destroy environment:\n  ```sh\n  kubectl delete ns ape cow fox\n  ```\n\n</div>\n\n<div id=\"hint-task5-1\">\n\n<details>\n  <summary>hints</summary>\n\n  <details>\n  <summary>hint 1</summary>\n\n  Did you search for Pods in specific namespaces, e.g. `kubectl get pod -n ape`?\n  </details>\n\n  <details>\n  <summary>hint 2</summary>\n\n  Did you review the Pod error message under _STATUS_ column of `kubectl get po` command? You can reveal more information with `kubectl get -owide`.\n  </details>\n\n  <details>\n  <summary>hint 3</summary>\n\n  Did you review more details of the Pod, especially details under _Containers_ section of `kubectl describe po` command?\n  </details>\n\n  <details>\n  <summary>hint 4</summary>\n\n  Is the `webserver` Pod up and running in the `cow` Namespace? Remember this is the requirement, so migrate the Pod if not in correct Namespace. No other resources should be migrated.\n  </details>\n\n  <details>\n  <summary>hint 5</summary>\n\n  Did you delete the `webserver` Pod in wrong Namespace `fox`?\n  </details>\n\n  <details>\n  <summary>hint 6</summary>\n\n  You can use `kubectl cp --help` to copy files and directories to and from containers. See [_kubectl_ cheatsheet](https://kubernetes.io/docs/reference/kubectl/cheatsheet/#copy-files-and-directories-to-and-from-containers) for more details.\n  </details>\n</details>\n\n</div>\n\n<div id=\"task5-2\">\n\n### Task - Pods II\n\nIn the `rat` Namespace (create if required), create a Pod named `webapp` that runs `nginx:1.22-alpine` image and has env-var `NGINX_PORT=3005` which determines the port exposed by the container. The Pod container should be named `web` and should mount an `emptyDir` volume to `/etc/nginx/templates`. \\\nThe Pod should have an _Init Container_ named `web-init`, running `busybox:1.28` image, that creates a file in the same `emptyDir` volume, mounted to `/tempdir`, with below command:\n\n```sh\necho \"server {\\n\\tlisten\\t${NGINX_PORT};\\n\\n\\tlocation / {\\n\\t\\troot\\t/usr/share/nginx/html;\\n\\t}\\n}\" > /tempdir/default.conf.template\n```\n\n</div>\n\n<div id=\"hint-task5-2\">\n\n<details>\n  <summary>hints</summary>\n\n  <details>\n  <summary>hint 1</summary>\n\n  Did you create the Pod in Namespace `rat`?\n  </details>\n\n  <details>\n  <summary>hint 2</summary>\n\n  Did you set environment variable `NGINX_PORT=3005` in container `web`? See `kubectl run --help` for how to set an environment variable in a container. \n  </details>\n\n  <details>\n  <summary>hint 3</summary>\n\n  Did you set Pod's `containerPort` parameter to be same value as env-var `NGINX_PORT`? Since the env-var `NGINX_PORT` determines the container port, you must change set the `containerPort` parameter to this value. See `kubectl run --help` for how to set port exposed by container.\n  </details>\n\n  <details>\n  <summary>hint 4</summary>\n\n  Did you specify an `emptyDir` volume and mounted it to `/etc/nginx/templates` in Pod container `web`? See [example pod manifest](#pod-manifest-file).\n  </details>\n\n  <details>\n  <summary>hint 5</summary>\n\n  Did you create `web-init` as an _Init Container_ under `pod.spec.initContainers`? See [_lab 5.3 - init containers_](#lab-53-init-containers).\n  </details>\n\n  <details>\n  <summary>hint 6</summary>\n\n  Did you run appropriate command in _Init Container_? You can use _list-form_, or _array-form_ with single quotes.\n\n  ```yaml\n  # list form\n  command:\n  - /bin/sh\n  - -c\n  - echo \"...\" > /temp...\n  # array form with single quotes\n  command: [\"/bin/sh\", \"-c\", \"echo '...' > /temp...\"]\n  ```\n  </details>\n\n  <details>\n  <summary>hint 7</summary>\n\n  Did you specify an `emptyDir` volume, mounted to `/tempdir` in _Init Container_ `web-init`? See [example pod manifest](#pod-manifest-file).\n  </details>\n\n  <details>\n  <summary>hint 8</summary>\n\n  Did you confirm that a webpage is being served by container `web` on specified port? Connect a shell to the container and run `curl localhost:3005`.\n  </details>\n</details>\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 6. Exploring Pods\n\nWhilst a Pod is running, the _kubelet_ is able to restart containers to handle some faults. Within a Pod, Kubernetes tracks different container states and determines what action to take to make the Pod healthy again.\n\nKubernetes tracks the _phase_ of a Pod\n\n- Pending - Pod starts here and waits to be scheduled, image download, etc\n- Running - at least one container running\n- Succeeded - all containers terminated successfully\n- Failed - all containers have terminated, at least one terminated in failure\n- Unknown - pod state cannot be obtained, either node communication breakdown or other\n\nKubernetes also tracks the _state_ of containers running in a Pod\n\n- Waiting - startup not complete\n- Running - executing without issues\n- Terminated - ran into issues whilst executing\n\n### Debugging Pods\n\nThe first step in debugging a Pod is taking a look at it. Check the current state of the Pod and recent events with:\n\n```sh\nkubectl describe pods $POD_NAME\n```\n\nWhen running commands locally in a Terminal, you can immediately see the output `STDOUT`. However, applications running in a cloud environment have their own way of showing their outputs - for Kubernetes, you can view a Pod `STDOUT` with:\n\n```sh\nkubectl logs $POD_NAME\n# to view only events\nkubectl get events --field-selector=involvedObject.name=$POD_NAME\n```\n\n> A Pod `STATUS=CrashLoopBackOff` means the Pod is in a cool off period following container failure. The container will be restarted after cool off \\\n> You will usually find more clues in the logs when a Pod shows a _none-zero_ `Exit Code` \\\n> See the [official _debug running pods_ tutorial](https://kubernetes.io/docs/tasks/debug/debug-application/debug-pods/) for more details\n\n<div id=\"lab6-1\">\n\n### Lab 6.1 Troubleshoot failing Pod\n\n1. Create a Pod with mysql image and confirm Pod state\n2. Get detailed information on the Pod and review Events (any multiple attempts?), 'State', 'Last State' and their Exit codes.\n   - Note that Pod `STATES` might continue to change for containers in error due to default `restartPolicy=Always`\n3. Review cluster logs for the Pod\n4. Apply relevant fixes until you have a mysql Pod in 'Running' state\n5. Delete created resources\n\n</div>\n\n<div id=\"soln-lab6-1\">\n\n<details>\n<summary>lab6.1 solution</summary>\n\n```sh\nkubectl run mydb --image=mysql --dry-run=client -o yaml > lab6-1.yaml\nkubectl apply -f lab6-1.yaml\nkubectl get pods\nkubectl describe -f lab6-1.yaml | less\nkubectl get pods --watch # watch pods for changes\nctrl+c\nkubectl delete -f lab6-1.yaml\nkubectl run mydb --image=mysql --env=\"MYSQL_ROOT_PASSWORD=secret\" --dry-run=client -o yaml > lab6-1.yaml\nkubectl apply -f lab6-1.yaml\nkubectl get pods\nkubectl describe -f lab6-1.yaml | less\nkubectl delete -f lab6-1.yaml\n```\n\n</details>\n\n</div>\n\n### Ephemeral containers\n\n[Ephemeral containers](https://kubernetes.io/docs/concepts/workloads/pods/ephemeral-containers/) are useful for interactive troubleshooting when `kubectl exec` is insufficient because a container has crashed or a container image doesn't include debugging utilities, such as with [distroless images](https://github.com/GoogleContainerTools/distroless).\n\n```sh\n# create a `mysql` Pod called `mypod` (assume the pod fails to start)\nkubectl run mydb --image=mysql\n# add ephemeral container to Pod `mypod`\nkubectl debug -it ephemeral-pod --image=busybox:1.28 --target=ephemeral-demo\n```\n\n> The `EphemeralContainers` feature must be enabled in the cluster and the `--target` parameter must be supported by the _container runtime_ \\\n> When not supported, the _Ephemeral Container_ may not be started, or started without revealing processes\n\n### Port forwarding\n\nPort forwarding in Kubernetes should only be used for testing purposes.\n\n```sh\n# get a list of pods with extra information, including IP Address\nkubectl get pods -o wide\n# view port forwarding help\nkubectl port-forward --help\n# forward host port 8080 to container `mypod` port 80, requires `ctrl+c` to terminate\nkubectl port-forward mypod 8080:80\n```\n\n> When a program runs in a unix-based environment, it starts a process. A _foreground process_ prevents further execution of commands, e.g. `sleep`\n\n```sh\n# run any foreground command in the background by adding an ampersand &\nsleep 60 &\n# view running background processes and their ids\njobs\n# bring a background process to the foreground\nfg $ID\n# run the `kubectl port-forward` command in the background\nkubectl port-forward mypod 8080:80 &\n```\n\n<div id=\"lab6-2\">\n\n### Lab 6.2. Use port forwarding to access applications\n\n1. Create a webserver Pod\n2. List created resources and determine Pod IP address\n3. Access the webserver with the IP address (you can use `curl`)\n4. Use port forwarding to access the webserver on http://localhost:5000\n5. Terminate port forwarding and delete created resources\n\n</div>\n\n<div id=\"soln-lab6-2\">\n\n<details>\n<summary>lab6.2 solution</summary>\n\n```sh\nkubectl run webserver --image=httpd\nkubectl get pods -o wide\ncurl $POD_IP_ADDRESS\nkubectl port-forward webserver 5000:80 &\ncurl localhost:5000\nfg 1\nctrl+c\nkubectl delete pods webserver\n```\n\n</details>\n\n</div>\n\n### Security context\n\n> This section requires a basic understanding of unix-based systems file permissions and access control covered in [ch2 - container access control](#docker-container-access-control)\n\nA [security context](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/) defines privilege and access control settings for a Pod or Container. Security context can be controlled at Pod-level `pod.spec.securityContext` as well as at container-level `pod.spec.containers.securityContext`. A detailed explanation of security context is provided in the linked docs, however, for [CKAD](https://www.cncf.io/certification/ckad/), we will only focus on the following:\n\n- `runAsGroup: $GID` - specifies the GID of logged-in user in pod containers (pod and container level)\n- `runAsNonRoot: $boolean` - specifies whether the containers run as a non-root user at image level - containers will not start if set to `true` while image uses root (pod and container)\n- `runAsUser: $UID` - specifies the UID of logged-in user in pod containers (pod and container)\n- `fsGroup: $GID` - specifies additional GID used for filesystem (mounted volumes) in pod containers (pod level)\n- `privileged: $boolean` - controls whether containers will run as privileged or unprivileged (container level)\n- `allowPrivilegeEscalation: $boolean` - controls whether a process can gain more privileges than its parent process - always `true` when the container is run as privileged, or has `CAP_SYS_ADMIN` (container level)\n- `readOnlyRootFilesystem: $boolean` - controls whether the container has a read-only root filesystem (container level)\n\n>\n\n```sh\n# show pod-level security context options\nkubectl explain pod.spec.securityContext | less\n# show container-level security context options\nkubectl explain pod.spec.containers.securityContext | less\n# view pod details for `mypod`\nkubectl get pods mypod -o yaml\n```\n\n<div id=\"lab6-3\">\n\n### Lab 6.3. Set Pod security context\n\nUsing the official docs manifest example `pods/security/security-context.yaml` as base to:\n\n1. Use the official manifest example `pods/security/security-context.yaml` as base to create a Pod manifest with these security context options:\n   - all containers have a logged-in user of `UID: 1010, GID: 1020`\n   - all containers set to run as non-root user\n   - mounted volumes for all containers in the pod have group `GID: 1110`\n   - escalating to root privileges is disabled ([more on privilege escalation](https://blog.g0tmi1k.com/2011/08/basic-linux-privilege-escalation/))\n2. Apply the manifest file and review details of created pod\n3. Review pod details and confirm security context applied at pod-level and container-level\n4. Connect an interactive shell to a container in the pod and confirm the following:\n   - current user\n   - group membership of current user\n   - ownership of entrypoint process\n   - ownership of the mounted volume `/data/demo`\n   - create a new file `/data/demo/new-file` and confirm file ownership\n   - escalate to a shell with root privileges `sudo su`\n5. Edit the pod manifest file to the following:\n   - do not set logged-in user UID/GID\n   - do not set root privilege escalation\n   - all containers set to run as non-root user\n6. Create a new pod with updated manifest\n7. Review pod details and confirm events and behaviour\n   - what were your findings?\n8. Delete created resources\n9. Explore the Pod spec and compare the `securityContext` options available at pod-level vs container-level\n\n</div>\n\n<div id=\"soln-lab6-3\">\n\n<details>\n<summary>lab6.3 solution</summary>\n\n```sh\n# host terminal\nkubectl explain pod.spec.securityContext | less\nkubectl explain pod.spec.containers.securityContext | less\nwget -qO lab6-3.yaml https://k8s.io/examples/pods/security/security-context.yaml\nnano lab6-3.yaml\n```\n\n```yaml\n# lab6-3.yaml\nspec:\n  securityContext:\n    runAsUser: 1010\n    runAsGroup: 1020\n    fsGroup: 1110\n  containers:\n    - name: sec-ctx-demo\n      securityContext:\n        allowPrivilegeEscalation: false\n# etc\n```\n\n```sh\n# host terminal\nkubectl apply -f lab6-3.yaml\nkubectl describe pods security-context-demo | less\nkubectl get pods security-context-demo -o yaml | grep -A 4 -E \"spec:|securityContext:\" | less\nkubectl exec -it security-context-demo -- sh\n# container terminal\nwhoami\nid # uid=1010 gid=1020 groups=1110\nps\nls -l /data # root 1110\ntouch /data/demo/new-file\nls -l /data/demo # 1010 1110\nsudo su # sudo not found - an attacker might try other ways to gain root privileges\nexit\n# host terminal\nnano lab6-3.yaml\n```\n\n```yaml\n# lab6-3.yaml\nspec:\n  securityContext:\n    runAsNonRoot: true\n    fsGroup: 1110\n  containers:\n    - name: sec-ctx-demo\n      securityContext:\n        allowPrivilegeEscalation: false\n# etc\n```\n\n```sh\n# host terminal\nkubectl delete -f lab6-3.yaml\nkubectl apply -f lab6-3.yaml\nkubectl get pods security-context-demo\nkubectl describe pods security-context-demo | less\n# found error creating container - avoid conflicting rules, enforcing non-root user `runAsNonRoot: true` requires a non-root user specified `runAsUser: $UID`\n```\n\n</details>\n\n</div>\n\n### Jobs\n\nA [Job](https://kubernetes.io/docs/concepts/workloads/controllers/job/) creates one or more Pods and will continue to retry execution of the Pods until a specified number of them successfully terminate - a _Completed_ status. Deleting a Job will clean up the Pods it created. Suspending a Job will delete its active Pods until the Job is resumed again. The default `restartPolicy` for Pods is _Always_, while the default `restartPolicy` for Jobs is _Never_.\n\nA Job type is determined by the values of the `completions` and `parallelism` fields - you can view all Job fields with `kubectl explain job.spec`:\n\n- `completions=1; parallelism=1` - one pod started per job, unless failure\n- `completions=1; parallelism=x` - multiple pods started, until one successfully completes task\n- `completions=n; parallelism=x` - multiple pods started, until `n` successful task completions\n- `ttlSecondsAfterFinished=x` - automatically delete a job after `x` seconds\n\n```sh\n# view resource types you can create in kubernetes\nkubectl create -h\n# create a job `myjob` that runs `date` command, see `kubectl create job -h`\nkubectl create job myjob --image=busybox -- date\n# generate a job manifest\nkubectl create job myjob --image=busybox --dry-run=client -o yaml -- date\n# list jobs\nkubectl get jobs\n# list jobs and pods\nkubectl get jobs,pods\n# view the manifest of an existing job `myjob`\nkubectl get jobs myjob -o yaml\n# view details of a job `myjob`\nkubectl describe job myjob\n# view the job spec\nkubectl explain job.spec | less\n```\n\n<div id=\"lab6-4\">\n\n### Lab 6.4. Working with Jobs\n\n1. Create a Job `myjob1` with a suitable image that runs the command `echo Lab 6.4. Jobs!`\n2. List jobs and pods\n3. Review the details of `myjob1`\n4. Review the yaml form of `myjob1`\n5. Create another Job `myjob2` with a suitable image that runs the command `date`\n6. List jobs and pods\n7. Repeat [4] using a manifest file with name `myjob3`\n8. List jobs and pods\n9. Delete all jobs created\n10. List jobs and pods\n11. Edit the manifest file and add the following:\n   - 5 pods successfully run the command\n   - pods are auto deleted after 30secs\n12. Apply the new manifest and:\n   - confirm the new changes work as expected\n   - note the total number of resources created\n   - note the behaviour after 30secs\n13. Delete created resources\n14. Review the Job spec to understand fields related to working with jobs\n15. Review the Kubernetes API Resources to determine when jobs was introduced\n\n</div>\n\n<div id=\"soln-lab6-4\">\n\n<details>\n<summary>lab6.4 solution</summary>\n\n```sh\nkubectl explain job.spec | less\nkubectl create job myjob1 --image=busybox -- echo Lab 6.4. Jobs!\nkubectl get jobs,pods\nkubectl describe job myjob1\nkubectl get jobs myjob1 -o yaml\nkubectl create job myjob2 --image=busybox -- date\nkubectl get jobs,pods\nkubectl create job myjob3 --image=busybox --dry-run=client -o yaml -- date >> lab6-4.yaml\nkubectl apply -f lab6-4.yaml\nkubectl get jobs,pods # so many pods!\nkubectl delete jobs myjob1 myjob2 myjob3\nkubectl get jobs,pods # pods auto deleted!\nnano lab6-4.yaml\n```\n\n```yaml\n# lab6-4.yaml\nkind: Job\nspec:\n  template:\n    spec:\n      completions: 5\n      ttlSecondsAfterFinished: 30\n      containers:\n# etc\n```\n\n```sh\nkubectl apply -f lab6-4.yaml\nkubectl get jobs,pods\nkubectl get pods --watch # watch pods for 30secs\n```\n\n</details>\n\n</div>\n\n### CronJobs\n\nA [CronJob](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/) creates Jobs on a repeating schedule. It runs a job periodically on a given schedule, written in Cron format. This isn't very different from the Linux/Unix crontab (cron table).\n\n> Note that 1 minute is the lowest you can set a crontab schedule. Anything lower will require additional logic or hack\n> If you are not familiar with Linux/Unix crontab, have a look at [this beginner guide](https://ostechnix.com/a-beginners-guide-to-cron-jobs/) or [this beginner tutorial](https://linuxhint.com/cron_jobs_complete_beginners_tutorial/)\n\n```sh\n# cronjob time syntax: * * * * * - minute hour day_of_month month day_of_week\nkubectl create cronjob -h\n# create a cronjob `cj` that run a job every minute\nkubectl create cronjob cj --image=busybox --schedule=\"* * * * *\" -- date\n# view the cronjob spec\nkubectl explain cronjob.spec | less\n# view the job spec of cronjobs\nkubectl explain cronjobs.spec.jobTemplate.spec\nkubectl api-resources # jobs was introduced in batch/v1\n```\n\n<div id=\"lab6-5\">\n\n### Lab 6.5. Working with CronJobs\n\n1. Create a job with a suitable image that runs the `date` command every minute\n2. Review details of the created CronJob\n3. Review the YAML form of the created CronJob\n4. List created resources and compare results before and after 1 minute\n5. Delete created resources\n6. Review the CronJob spec to understand fields related to working with cronjobs\n7. Review the Job spec of a CronJob and compare this to a standard Job spec\n8. Review the Kubernetes API Resources to determine when jobs was introduced\n\n</div>\n\n<div id=\"soln-lab6-5\">\n\n<details>\n<summary>lab6.5 solution</summary>\n\n```sh\nkubectl explain cronjob.spec | less\nkubectl explain cronjob.spec.jobTemplate.spec | less\nkubectl create cronjob mycj --image=busybox --schedule=\"* * * * *\" -- date\nkubectl describe cj mycj | less\nkubectl get cj mycj -o yaml | less\nkubectl get all\nkubectl get pods --watch # watch pods for 60s to see changes\nkubectl delete cj mycj # deletes associated jobs and pods!\nkubectl api-resources # cronjobs was introduced in batch/v1\n```\n\n</details>\n\n> All CronJob `schedule` times are based on the timezone of the [_kube-controller-manager_](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-controller-manager/) \\\n> Since a CronJob runs a Job periodically, the Job spec auto delete feature `ttlSecondsAfterFinished` is quite handy\n\n</div>\n\n### Requests and Limits\n\nBy default, Linux will not limit resources available to processes - containers are processes running on Linux. However, when creating Pod, you can optionally specify how much of each resource a container needs. The most common resources to specify are CPU and RAM, but there are others.\n\n_Request_ is the initial/minimum amount of a particular resource provided to a container, while _Limit_ is the maximum amount of the resource available - the container cannot exceed this value. See [resource management for pods and containers](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/) for more details.\n\n> A Pod resource request/limit is the sum of the resource requests/limits of containers in the Pod\n> A Pod remains in \"Pending\" status until a Node with sufficient resources becomes available \\\n> Note that _Requests and Limits_ management at the Namespace-level is not for CKAD but covered in [CKA](https://www.cncf.io/certification/cka/)\n\n#### Resource requests and limits of Pod and container\n\n- `spec.containers[].resources.limits.cpu` - in cores and millicores, 500m = 0.5 CPU\n- `spec.containers[].resources.limits.memory` - Ki (1024) / k (1000) | Mi/M | Gi/G | Ti/T | Pi/P | Ei/E\n- `spec.containers[].resources.limits.hugepages-<size>`\n- `spec.containers[].resources.requests.cpu`\n- `spec.containers[].resources.requests.memory`\n- `spec.containers[].resources.requests.hugepages-<size>`\n\n```sh\n# view container resources object within the pod spec\nkubectl explain pod.spec.containers.resources\n# pod resource update is forbidden, but you can generate YAML, see `kubectl set -h`\nkubectl set resources pod --help\n# generate YAML for pod `mypod` that requests 0.2 CPU and 128Mi memory\nkubectl set resources pod mypod --requests=cpu=200m,memory=128Mi --dry-run=client -oyaml|less\n# generate YAML for requests 0.2 CPU, 128Mi memory, and limits 0.5 CPU, 256Mi memory\nkubectl set resources pod mypod --requests=cpu=200m,memory=128Mi --limits=cpu=500m,memory=256Mi --dry-run=client -oyaml|less\n```\n\n<div id=\"lab6-6\">\n\n### Lab 6.6. Resource limitation\n\nYou may use the [official container resource example manifest](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#example-1) or generate a manifest file with `kubectl set resources`.\n\n1. Create a Pod with the following spec:\n   - runs in `dev` namespace\n   - runs two containers, MongoDB database and webserver frontend\n   - restart only on failure, see `pod.spec.restartPolicy`\n   - both containers starts with 0.25 CPU, 64 mebibytes RAM\n   - both containers does not exceed 1 CPU, 256 mebibytes RAM\n2. List created pods\n3. Review pod details and confirm the specified resource quotas are applied\n4. Edit the Pod manifest as follows:\n   - both containers starts with an insufficient amount RAM, e.g 4 mebibytes\n   - both containers does not exceed 8 mebibytes RAM\n5. Apply the manifest and review behaviour\n6. Review logs for both containers\n7. Compare the logs output in [6] to details from `kubectl describe`\n8. Edit the Pod manifest as follows:\n   - both containers starts with an amount of RAM equal to host RAM (run `cat /proc/meminfo` or `free -h`)\n   - both containers starts with an amount CPU equal to host CPU (run `cat /proc/cpuinfo` or `lscpu`)\n   - both containers does not exceed x2 the amount of host RAM\n9. Apply the manifest and review behaviour\n10. Delete created resources\n11. Review the Pod spec fields related to limits and requests\n\n</div>\n\n<div id=\"soln-lab6-6\">\n\n<details>\n<summary>lab6.6 solution</summary>\n\n```sh\nkubectl create ns dev --dry-run=client -o yaml >> lab6-6.yaml\necho --- >> lab6-6.yaml\n# add the contents of the example manifest to lab6-6.yaml and modify accordingly\nnano lab6-6.yaml\n```\n\n```yaml\n# lab6-6.yaml\nkind: Namespace\nmetadata:\n  name: dev\n# etc\n---\nkind: Pod\nmetadata:\n  name: webapp\n  namespace: dev\nspec:\n  restartPolicy: OnFailure\n  containers:\n    - image: mongo\n      name: database\n      resources:\n        requests:\n          memory: \"64Mi\"\n          cpu: \"250m\"\n        limits:\n          memory: \"256Mi\"\n          cpu: 1\n    - image: nginx\n      name: frontend\n      resources: # same as above\n# etc\n```\n\n```sh\nkubectl apply -f lab6-6.yaml\nkubectl get pods -n dev\nkubectl describe pods webapp -n dev | less\nkubectl describe pods webapp -n dev | grep -A 4 -E \"Containers:|State:|Limits:|Requests:\" | less\nnano lab6-6.yaml\n```\n\n```yaml\n# lab6-6.yaml\nkind: Pod\nspec:\n  containers:\n    - resources:\n        requests:\n          memory: \"4Mi\"\n          cpu: \"250m\"\n        limits:\n          memory: \"8Mi\"\n          cpu: 1\n# etc - use above resources for both containers\n```\n\n```sh\nkubectl delete -f lab6-6.yaml\nkubectl apply -f lab6-6.yaml\nkubectl get pods -n dev --watch # watch for OOMKilled | CrashLoopBackOff\nkubectl get logs webapp -n dev -c database # not very helpful logs\nkubectl get logs webapp -n dev -c frontend\nkubectl describe pods webapp -n dev | less # helpful logs - Last State: Terminated, Reason: OutOfMemory (OOMKilled)\nkubectl describe pods webapp -n dev | grep -A 4 -E \"Containers:|State:|Limits:|Requests:\" | less\ncat /proc/cpuinfo # check for host memory\ncat /proc/meminfo # check for host ram\nnano lab6-6.yaml\n```\n\n```yaml\n# lab6-6.yaml\nkind: Pod\nspec:\n  containers:\n    - resources:\n        requests:\n          memory: \"8Gi\" # use value from `cat /proc/meminfo`\n          cpu: 2 # use value from `cat /proc/cpuinfo`\n        limits:\n          memory: \"16Gi\"\n          cpu: 4\n# etc - use above resources for both containers\n```\n\n```sh\nkubectl delete -f lab6-6.yaml\nkubectl apply -f lab6-6.yaml\nkubectl get pods -n dev --watch # remains in Pending until enough resources available\nkubectl describe pods webapp\nkubectl delete -f lab6-6.yaml\nkubectl explain pod.spec.containers.resources | less\n```\n\n</details>\n\n> Remember a multi-container Pod is not recommended in live environments but only used here for learning purposes\n\n</div>\n\n<div id=\"lab6-7\">\n\n### Lab 6.7. Resource allocation and usage\n\nThis lab requires a Metrics Server running in your cluster, please run `minikube addons enable metrics-server` to enable Metrics calculation.\n\n```sh\n# enable metrics-server on minikube\nminikube addons enable metrics-server\n# list available nodes\nkubectl get nodes\n# view allocated resources for node and % resource usage for running (non-terminated) pods\nkubectl describe node $NODE_NAME\n# view nodes resource usage\nkubectl top node\n# view pods resource uage\nkubectl top pod\n```\n\n<details>\n<summary>output from <code>kubectl describe node</code></summary>\n\n![image](https://user-images.githubusercontent.com/17856665/191446804-8bbf8678-70ef-4f1c-a88c-bcbe01f8b232.png)\n</details>\n\n1. Enable Metrics Server in your cluster\n2. What is the cluster Node's minimum required CPU and memory?\n3. Create a Pod as follows:\n   - image `nginx:alpine`\n   - does not restart, see `kubectl explain pod.spec`\n   - only pulls a new image if not present locally, see `kubectl explain pod.spec.containers`\n   - requires 0.2 CPU to start but does not exceed half of the cluster Node's CPU\n   - requires 64Mi memory to start but does not exceed half of the cluster Node's memory\n4. Review the running Pod and confirm resources configured as expected\n5. Delete created resources\n\n</div>\n\n<div id=\"soln-lab6-7\">\n\n<details>\n<summary>lab 6.7 solution</code></summary>\n\n```sh\nminikube addons enable metrics-server\nkubectl get node # show node name\nkubectl describe node $NODE_NAME | grep -iA10 \"allocated resources:\" # cpu 0.95, memory 460Mi\nkubectl run mypod --image=nginx:alpine --restart=Never --image-pull-policy=IfNotPresent --dry-run=client -oyaml>lab6-7.yml\nkubectl apply -f lab6-7.yml # cannot use `kubectl set` if pod don't exist\nkubectl set resources pod mypod --requests=cpu=200m,memory=64Mi --limits=cpu=475m,memory=230Mi --dry-run=client -oyaml|less\nnano lab6-7.yml # copy resources section of above output to pod yaml\n```\n\n```yaml\nkind: Pod\nspec:\n  containers:\n  - name: mypod\n    imagePullPolicy: IfNotPresent\n    resources:\n      limits:\n        cpu: 475m\n        memory: 230Mi\n      requests:\n        cpu: 200m\n        memory: 64Mi\n```\n\n```sh\nkubectl delete -f lab6-7.yml\nkubectl apply -f lab6-7.yml\nkubectl describe -f lab6-7.yml | grep -iA6 limits:\nkubectl delete -f lab6-7.yml\n```\n</details>\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n<div id=\"task6-1\">\n\n### Task - CronJobs\n\nIn the `boa` Namespace, create a Pod that runs the shell command `date`, in a busybox container, once every hour, regardless success or failure. Job should terminate after 20s even if command still running. Jobs should be automatically deleted after 12 hours. A record of 5 successful Jobs and 5 failed Jobs should be kept. All resources should be named `bootcamp`, including the container. You may create a new Namespace if required.\n\nAt the end of your task, to avoid waiting an hour to confirm all works, manually run the Job from the Cronjob and verify expected outcome.\n\n</div>\n\n<div id=\"hint-task6-1\">\n\n<details>\n  <summary>hints</summary>\n\n  <details>\n  <summary>hint 1</summary>\n\n  Did you create the Cronjob in the `boa` Namespace? You can generate YAML with Namespace specified, see [lab 5.6](#lab-56-namespaces)\n  </details>\n\n  <details>\n  <summary>hint 2</summary>\n\n  You can generate YAML for Cronjob schedule and command, see [_lab 6.5 - working with cronjobs_](#lab-65-working-with-cronjobs)\n  </details>\n\n  <details>\n  <summary>hint 3</summary>\n\n  See `kubectl explain job.spec` for terminating and auto-deleting Jobs after specified time.\n  </details>\n\n  <details>\n  <summary>hint 4</summary>\n\n  See `kubectl explain cronjob.spec` for keeping successful/failed Jobs.\n  </details>\n\n  <details>\n  <summary>hint 5</summary>\n\n  You can create a Job to manually run a Cronjob, see `kubectl create job --help`\n  </details>\n\n  <details>\n  <summary>hint 6</summary>\n\n  Did you create the Job in the `boa` Namespace?\n  </details>\n\n  <details>\n  <summary>hint 7</summary>\n\n  Did you specify `cronjob.spec.jobTemplate.spec.activeDeadlineSeconds` and `cronjob.spec.jobTemplate.spec.ttlSecondsAfterFinished`?\n  </details>\n\n  <details>\n  <summary>hint 8</summary>\n\n  Did you specify `cronjob.spec.failedJobsHistoryLimit` and `cronjob.spec.successfulJobsHistoryLimit`?\n  </details>\n\n  <details>\n  <summary>hint 9</summary>\n\n  After Cronjob creation, did you verify configured parameters in `kubectl describe`?\n  </details>\n\n  <details>\n  <summary>hint 10</summary>\n\n  After manual Job creation, did you verify Job successfully triggered?\n  </details>\n</details>\n\n</div>\n\n<div id=\"task6-2\">\n\n### Task - Resources and Security Context\n\nA client requires a Pod running the `nginx:1.21-alpine` image with name `webapp` in the `dog` Namespace. The Pod should start with 0.25 CPU and 128Mi memory, but shouldn't exceed 0.5 CPU and half of the Node's memory. All processes in Pod containers should run with user ID 1002 and group ID 1003. Containers mustn't run in `privileged` mode and privilege escalation should be disabled. You may create a new Namespace if required.\n\nWhen you are finished with the task, the client would also like to know the Pod with the highest memory consumption in the `default` Namespace. Save the name the Pod in the format `<namespace>/<pod-name>` to a file `/home/$USER/ckad-tasks/resources/pod-with-highest-memory`\n\n</div>\n\n<div id=\"hint-task6-2\">\n\n<details>\n  <summary>hints</summary>\n\n  <details>\n  <summary>hint 1</summary>\n\n  Did you create the resource in the `dog` Namespace? You can generate YAML with Namespace specified, see [lab 5.6](#lab-56-namespaces)\n  </details>\n\n  <details>\n  <summary>hint 2</summary>\n\n  You can separately generate YAML for the `pod.spec.containers.resources` section, see [_lab 6.7 - resource allocation and usage_](#lab-67-resource-allocation-and-usage)\n  </details>\n\n  <details>\n  <summary>hint 3</summary>\n\n  See [lab 6.3](#lab-63-set-pod-security-context) for security context. You will need to add four separate rules for user ID, group ID, privileged and privilege escalation.\n  </details>\n\n  <details>\n  <summary>hint 4</summary>\n\n  You can use a combination of the output-name and sorting format `kubectl -oname --sort-by=json-path-to-field`. The JSON path can be derived from viewing the resource with output-json `-ojson`. See [_kubectl_ cheatsheet](https://kubernetes.io/docs/reference/kubectl/cheatsheet/#viewing-finding-resources) for more details\n  </details>\n</details>\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 7. Deployments\n\n[Deployments](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/) manages Pods with scalability and reliability. This is the standard way to manage Pods and ReplicaSets in live environments.\n\n```sh\n# create a deployment `myapp` with 1 pod, see `kubectl create deploy --help`\nkubectl create deployment myapp --image=nginx\n# create a deployment `myapp` with 3 pods\nkubectl create deploy myapp --image=nginx --replicas=3\n# list existing resources in `default` namespace\nkubectl get all\n# list existing resources filtered by selector `app=myapp`\nkubectl get all --selector=\"app=myapp\" # or `--selector app=myapp`\n# show details of deployment `myapp`, see `kubectl describe deploy --help`\nkubectl describe deploy myapp\n# scale deployment `myapp`, see `kubectl scale deploy --help`\nkubectl scale deploy myapp --replicas=4\n# edit deployment `myapp` (not all fields are edittable), see `kubectl edit deploy --help`\nkubectl edit deploy myapp\n# edit deployment `myapp` with specified editor\nKUBE_EDITOR=nano kubectl edit deploy myapp\n# set deployment image for `webserver` container to `nginx:1.8`, see `kubectl set --help` for editable fields\nkubectl set image deployment/myapp webserver=nginx:1.8\n# set deployment image for all containers to `nginx:1.8`, see `kubectl set image --help`\nkubectl set image deployment/myapp *=nginx:1.8\n# view the deployment spec\nkubectl explain deploy.spec\n```\n\n<div id=\"lab7-1\">\n\n### Lab 7.1. Deploy an app with a replicaset\n\nDeployments can be used to rollout a ReplicaSet which manages the number of Pods. In [CKAD](https://www.cncf.io/certification/ckad/) you will only work with ReplicaSets via Deployments\n\n1. Create a deployment with three replicas using a suitable image\n2. Show more details of the deployment and review available fields:\n   - namespace, labels, selector, replicas, update strategy type, pod template, conditions, replicaset and events\n3. List all created resources\n4. Delete a Pod and monitor results\n5. Compare results to using _naked_ Pods (run a pod and delete it)\n6. Delete the ReplicaSet with `kubectl delete rs $rsName` and monitor results\n7. Delete created resources\n8. Explore the deployment spec\n9. Explore the Kubernetes API Resources to determine when deployments and replicasets was introduced\n\n</div>\n\n<div id=\"soln-lab7-1\">\n\n<details>\n<summary>lab7.1 solution</summary>\n  \n```sh\nkubectl create deploy myapp --image=httpd --replicas=3\nkubectl describe deploy myapp | less\nkubectl get all\nkubectl delete pod $POD_NAME\nkubectl get all\nkubectl get pods --watch # watch replicaset create new pod to replace deleted\nkubectl run mypod --image=httpd\nkubectl get all\nkubectl delete pod mypod\nkubectl get all # naked pod not recreated\nkubectl delete replicaset $REPLICASET_NAME # pods and replicaset deleted\nkubectl get all\nkubectl get pods --watch # deployment creates new replicaset, and replicaset creates new pods\nkubectl delete deploy myapp nginx-deployment\nkubectl explain deploy.spec\nkubectl api-resources # deployments & replicasets were introduced in apps/v1\n# replicasets replaced v1 replicationcontrollers\n```\n</details>\n\n</div>\n\n<div id=\"lab7-2\">\n\n### Lab 7.2. Scale deployment\n\nA deployment creates a ReplicaSet that manages scalability. Do not manage replicasets outside of deployments.\n\n1. Create a deployment using the official deployment manifest example `controllers/nginx-deployment.yaml`\n2. List created resources\n3. Edit the deployment with `kubectl edit` and change the `namespace` to dev\n4. Save the editor and confirm behaviour\n5. Edit the deployment again using a different editor, change the replicas to 12 and upgrade the image version\n6. Save the editor and confirm behaviour, then immediately list all resources and review:\n   - deployment status for `READY`, `UP-TO-DATE` and `AVAILABLE`\n   - replicaset status for `DESIRED`, `CURRENT` and `READY`\n   - pod status for `NAME`, `READY` and `STATUS`\n   - compare the _ID-suffix_ in the Pods name to the ReplicaSets name\n7. View details of deployment to confirm edit applied, including image change\n8. Scale down the deployment back to 3 replicas using `kubectl scale` and review same in [6]\n9. List all resources and confirm scaling applied\n10. Delete created resources\n11. Edit the `apiVersion` of the manifest example file to `apps/v0`\n12. Apply the edited manifest and confirm behaviour\n\n</div>\n\n<div id=\"soln-lab7-2\">\n\n<details>\n<summary>lab7.2 solution</summary>\n  \n```sh\nwget -O lab7-2.yaml https://k8s.io/examples/controllers/nginx-deployment.yaml\nkubectl apply -f lab7-2.yaml\nkubectl get all\nkubectl edit -f lab7-2.yaml\n```\n\n```yaml\nkind: Deployment\nmetadata:\n  name: nginx-deployment\n  namespace: dev\n# etc (save failed: not all fields are editable - cancel edit)\n```\n\n```sh\nKUBE_EDITOR=nano kubectl edit -f lab7-2.yaml\n```\n\n```yaml\nkind: Deployment\nspec:\n  replicas: 12\n  template:\n    spec:\n      containers:\n        - image: nginx:1.3\n# etc - save successful\n```\n\n```sh\nkubectl get all\nkubectl describe -f lab7-2.yaml | less\nkubectl scale deploy myapp --replicas=3\nkubectl get all\nkubectl delete -f lab7-2.yaml\nnano lab7-2.yaml\n```\n\n```yaml\napiVersion: apps/v0\nkind: Deployment\n# etc\n```\n\n```sh\nkubectl apply -f lab7-2.yaml # recognise errors related to incorrect manifest fields\n```\n\n</details>\n\n</div>\n\n### Labels, selectors and annotations\n\nLabels are used for groupings, filtering and providing metadata. Selectors are used to group related resources. Annotations are used to provide additional metadata but are not used in queries. \\\nWhen a deployment is created, a default Label `app=$appName` is assigned, and a similar Selector is also created. When a pod is created, a default Label `run=$podName` is assigned\n\n> Labels added after creating a deployment are not inherited by the resources\n\n```sh\n# add new label `state: test` to deployment `myapp`, see `kubectl label --help`\nkubectl label deployment myapp state=test\n# list deployments and their labels, see `kubectl get deploy --help`\nkubectl get deployments --show-labels\n# list all resources and their labels\nkubectl get all --show-labels\n# list deployments filtered by specific label\nkubectl get deployments --selector=\"state=test\"\n# list all resources filtered by specific label\nkubectl get all --selector=\"app=myapp\"\n# remove the `app` label from deployment `myapp`\nkubectl label deploy myapp app-\n# remove the `run` label from pod `mypod`\nkubectl label pod mypod run-\n```\n\n<div id=\"lab7-3\">\n\n### Lab 7.3. Working with labels\n\n1. Create a deployment `myapp` with three replicas using a suitable image\n2. List all deployments and their labels to confirm default labels assigned\n3. Add a new label `pipeline: test` to the deployment\n4. List all deployments and their labels\n5. View more details of the deployment and review labels/selectors\n6. View the YAML form of the deployment to see how labels are added in the manifest\n7. Verify the default label/selector assigned when you created a new Pod\n8. List all resources and their labels filtered by default label of the deployment\n9. List all resources and their labels, filtered by new label added, compare with above\n10. Remove the default label from one of the pods in the deployment and review behaviour\n11. List all pods and their labels\n12. List all pods filtered by the default label\n13. Delete the deployment\n14. Delete the _naked_ Pod from [10]\n\n</div>\n\n<div id=\"soln-lab7-3\">\n\n<details>\n<summary>lab7.3 solution</summary>\n  \n```sh\nkubectl create deploy myapp --image=httpd --dry-run=client -o yaml >> lab7-3.yaml\nkubectl apply -f lab7-3.yaml\nkubectl get deploy --show-labels\nkubectl label deploy myapp pipeline=test\nkubectl get deploy --show-labels\nkubectl describe -f lab7-3.yaml\nkubectl get -o yaml -f lab7-3.yaml | less\nkubectl run mypod --image=nginx --dry-run=client -o yaml | less\nkubectl get all --selector=\"app=myapp\"\nkubectl get all --selector=\"pipeline=test\"\nkubectl label pod $POD_NAME app- # pod becomes naked/dangling and unmanaged by deployment\nkubectl get pods --show-labels # new pod created to replace one with label removed\nkubectl get pods --selector=\"app=myapp\" # shows 3 pods\nkubectl delete -f lab7-3.yaml # $POD_NAME not deleted! `deploy.spec.selector` is how a deployment find pods to manage!\n```\n</details>\n\n</div>\n\n### Update strategy\n\n[Rolling updates](https://kubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/) is the default update strategy, triggered when a field in the deployment's Pod template `deployment.spec.template` is changed. A new ReplicaSet is created that creates updated Pods one after the other, and the old ReplicaSet is scaled to 0 after successful update. At some point during the update, both old version and new version of the app will be live. By default, ten old ReplicaSets will be kept, see [`deployment.spec.revisionHistoryLimit`](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#revision-history-limit)\n\nThe other type of update strategy is [Recreate](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#recreate-deployment), where all Pods are killed before new Pods are created. This is useful when you cannot have different versions of an app running simultaneously, e.g database.\n\n- [`deploy.spec.strategy.rollingUpdate.maxUnavailable`](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#max-unavailable): control number of Pods upgraded simultaneously\n- [`deploy.spec.strategy.rollingUpdate.maxSurge`](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#max-surge): controls the number of additional Pods, more than the specified replicas, created during update. Aim to have a higher `maxSurge` than `maxUnavailable`.\n\n> A Deployment's rollout is only triggered if a field within the Pod template `deploy.spec.template` is changed \\\n> Scaling down a Deployment to 0 is another way to delete all resources, saving costs, while keeping the config for a quick scale up when required\n\n```sh\n# view the update strategy field under deployment spec\nkubectl explain deployment.spec.strategy\n# view update strategy field recursively\nkubectl explain deployment.spec.strategy --recursive\n# edit the image of deployment `myapp` by setting directly, see `kubectl set -h`\nkubectl set image deployment myapp nginx=nginx:1.24\n# edit the environment variable of deployment `myapp` by setting directly\nkubectl set env deployment myapp dept=MAN\n# show recent update history - entries added when fields under `deploy.spec.template` change\nkubectl rollout history deployment myapp -h\n# show update events\nkubectl describe deployment myapp\n# view rolling update options\nkubectl get deploy myapp -o yaml\n# view all deployments history, see `kubectl rollout -h`\nkubectl rollout history deployment\n# view `myapp` deployment history\nkubectl rollout history deployment myapp\n# view specific change revision/log for `myapp` deployment (note this shows fields that affect rollout)\nkubectl rollout history deployment myapp --revision=n\n# revert `myapp` deployment to previous version/revision, see `kubectl rollout undo -h`\nkubectl rollout undo deployment myapp --to-revision=n\n```\n\n<div id=\"lab7-4\">\n\n### Lab 7.4. Rolling updates\n\n1. Review the update strategy field under the deployment spec\n2. Create a deployment with a suitable image\n3. View more details of the deployment\n   - by default, how many pods can be upgraded simultaneously during update?\n   - by default, how many pods can be created in addition to the number of replicas during update?\n4. Create a new deployment with the following parameters:\n   - 5 replicas\n   - image `nginx:1.18`\n   - additional deployment label `update: feature`\n   - maximum of 2 Pods can be updated simultaneously\n   - no more than 3 additional Pod created during updates\n5. List all resources filtered by the default label\n6. List all resources filtered by the additional label\n7. List rollout history for all deployments - how many revisions does the new deployment have?\n8. Upgrade/downgrade the image version\n9. List all resources specific to the new deployment\n10. List rollout history specific to the new deployment - how many revisions?\n11. View more details of the deployment and note the image and _Events messages_\n12. Compare the latest change revision of the new deployment's rollout history to the previous revision\n13. Revert the new deployment to its previous revision\n14. List all resources specific to the new deployment twice or more to track changes\n15. List rollout history specific to the new deployment - any new revisions?\n16. Scale the new deployment to 0 Pods\n17. List rollout history specific to the new deployment - any new revisions?\n18. List all resources specific to the new deployment\n19. Delete created resources\n\n</div>\n\n<div id=\"soln-lab7-4\">\n\n<details>\n<summary>lab7.4 solution</summary>\n  \n```sh\nkubectl explain deploy.spec.strategy | less\nkubectl create deploy myapp --image=nginx --dry-run=client -o yaml > lab7-4.yaml\nkubectl apply -f lab7-4.yaml\nkubectl describe -f lab7-4.yaml\nkubectl get deploy myapp -o yaml | less # for manifest example to use in next step\nnano lab7-4.yaml # edit to new parameters\n```\n\n```yaml\nkind: Deployment\nmetadata:\n  labels: # labels is `map` not `array` so no `-` like containers\n    app: myapp\n    updates: feature\n  name: myapp\nspec:\n  replicas: 5\n  strategy:\n    rollingUpdate:\n      maxSurge: 3\n      maxUnavailable: 2\n  template:\n    spec:\n      containers:\n        - image: nginx:1.18\n          name: webserver\n# etc\n```\n\n```sh\nkubectl get all --selector=\"app=myapp\"\nkubectl get all --selector=\"updates=feature\" # extra deployment label not applied on pods\nkubectl rollout history deploy\nkubectl set image deploy myapp nginx=n -f lab7-4.yaml\nkubectl set image deploy myapp webserver=nginx:1.23\nkubectl get all --selector=\"app=myapp\"\nkubectl rollout history deploy myapp # 2 revisions\nkubectl describe deploy myapp\nkubectl rollout history deploy myapp --revision=2\nkubectl rollout history deploy myapp --revision=1\nkubectl rollout undo deploy myapp --to-revision=1\nkubectl get all --selector=\"app=myapp\"\nkubectl rollout history deploy myapp # 2 revisions, but revision count incremented\nkubectl scale deploy myapp --replicas=0\nkubectl rollout history deploy myapp # replicas change does not trigger rollout, only `deploy.spec.template` fields\nkubectl get all --selector=\"app=myapp\"\nkubectl delete -f lab7-4.yaml\n```\n\n</details>\n\n</div>\n\n### DaemonSets\n\nA [_DaemonSet_](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/) is a kind of deployment that ensures that all (or some) Nodes run a copy of a particular Pod. This is useful in a multi-node cluster where specific application is required on all nodes, e.g. running a - cluster storage, logs collection, node monitoring, network agent - daemon on every node. As nodes are added to the cluster, Pods are added to them. As nodes are removed from the cluster, those Pods are garbage collected. Deleting a DaemonSet will clean up the Pods it created.\n\n```sh\n# create daemonset via yaml file\nkubectl create -f daemonset.yaml\n# view daemonsets pods\nkubectl get ds,pods\n# view daemonset in kube system namespace\nkubectl get ds,pods -n kube-system\n# view the daemonset spec\nkubectl explain daemontset.spec | less\n# view the daemonset spec recursively\nkubectl explain daemontset.spec --recursive | less\n```\n\n<div id=\"lab7-5\">\n\n### Lab 7.5. Exploring DaemonSets\n\nDaemonSets can only be created by YAML file, see an official example manifest `controllers/daemonset.yaml`.\n\n1. Compare the DaemonSet manifest to a Deployment manifest - differences/similarities?\n2. Apply the example manifest\n3. List all resources and note resources created by the DaemonSet\n4. View more details of the DaemonSet\n5. Delete created resources\n6. Review the Kubernetes API Resources to determine when DaemonSets was introduced\n7. List existing DaemonSets in the _kube-system_ namespace and their labels\n   - what does Kubernetes use a DaemonSet for?\n8. List all resources in the _kube-system_ namespace matching the DaemonSet label\n9. Review the DaemonSet spec\n\n</div>\n\n<div id=\"soln-lab7-5\">\n\n<details>\n<summary>lab7.5 solution</summary>\n  \n```sh\nkubectl create deploy myapp --image=nginx --dry-run=client -o yaml | less # view fields required\nwget -qO- https://k8s.io/examples/controllers/daemonset.yaml | less # similar to deployment, except Kind and replicas\nkubectl apply -f https://k8s.io/examples/controllers/daemonset.yaml\nkubectl get all # note daemonset and related pod\nkubectl describe -f https://k8s.io/examples/controllers/daemonset.yaml\nkubectl delete -f https://k8s.io/examples/controllers/daemonset.yaml\nkubectl api-resources # introduced in version apps/v1\nkubectl get ds -n=kube-system --show-labels # used to add network agent `kube-proxy` to all cluster nodes\nkubectl get all -n=kube-system --selector=\"k8s-app=kube-proxy\"\nkubectl explain daemonset.spec | less\nkubectl explain daemonset.spec --recursive | less\n```\n</details>\n\n</div>\n\n<div id=\"lab7-6\">\n\n### Lab 7.6. Resource usage and Autoscaling\n\nAutoscaling is very important in live environments but not covered in [CKAD](https://www.cncf.io/certification/ckad/). Visit [HorizontalPodAutoscaler Walkthrough](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/#run-and-expose-php-apache-server) for a complete lab on autoscaling.\n\n> The lab requires a _metrics-server_ so install one via Minikube if you plan to complete the lab\n\n```sh\n# list minikube addons\nminikube addons list\n# enable minikube metrics-server\nminikube addons enable metrics-server\n# disable minikube metrics-server\nminikube addons disable metrics-server\n```\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n<div id=\"task7-1\">\n\n### Task - Deployment\n\nSome bootcamp students have been messing with the `webapp` Deployment for the test environment's webpage in the `default` Namespace, leaving it broken. Please rollback the Deployment to the last fully functional version. Once on the fully functional version, update the Deployment to have a total of 10 Pods, and ensure that the total number of old and new Pods, during a rolling update, do not exceed 13 or go below 7.\n\nUpdate the Deployment to `nginx:1.22-alpine` to confirm the Pod count stays within these thresholds. Then rollback the Deployment to the fully functional version. Before you leave, set the Replicas to 4, and just to be safe, Annotate all the Pods with `description=\"Bootcamp Test Env - Please Do Not Change Image!\"`.\n\n- Command to setup environment:\n  ```sh\n  printf '\\nlab: environment setup in progress...\\n'; echo '{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"metadata\":{\"labels\":{\"appid\":\"webapp\"},\"name\":\"webapp\"},\"spec\":{\"replicas\":2,\"revisionHistoryLimit\":15,\"selector\":{\"matchLabels\":{\"appid\":\"webapp\"}},\"template\":{\"metadata\":{\"labels\":{\"appid\":\"webapp\"}},\"spec\":{\"volumes\":[{\"name\":\"varlog\",\"emptyDir\":{}}],\"containers\":[{\"image\":\"nginx:1.12-alpine\",\"name\":\"nginx\",\"volumeMounts\":[{\"name\":\"varlog\",\"mountPath\":\"/var/logs\"}]}]}}}}' > k8s-task-6.yml; kubectl apply -f k8s-task-6.yml >/dev/null; cp k8s-task-6.yml k8s-task-6-bak.yml; sed -i -e 's/nginx:1.12-alpine/nginx:1.13alpine/g' k8s-task-6.yml 2>/dev/null; sed -i '' 's/nginx:1.12-alpine/nginx:1.13alpine/g' k8s-task-6.yml 2>/dev/null; kubectl apply -f k8s-task-6.yml >/dev/null; sleep 1; sed -i -e 's/nginx:1.13alpine/nginx:1.14-alpine/g' k8s-task-6.yml 2>/dev/null; sed -i '' 's/nginx:1.13alpine/nginx:1.14-alpine/g' k8s-task-6.yml 2>/dev/null; kubectl apply -f k8s-task-6.yml >/dev/null; sleep 4; sed -i -e 's/nginx:1.14-alpine/nginx:1.15-alpine/g' k8s-task-6.yml 2>/dev/null; sed -i -e 's/\\/var\\/logs/\\/usr\\/share\\/nginx\\/html/g' k8s-task-6.yml 2>/dev/null; sed -i '' 's/nginx:1.14-alpine/nginx:1.15-alpine/g' k8s-task-6.yml 2>/dev/null; sed -i '' 's/\\/var\\/logs/\\/usr\\/share\\/nginx\\/html/g' k8s-task-6.yml 2>/dev/null; kubectl apply -f k8s-task-6.yml >/dev/null; sleep 2; sed -i -e 's/nginx:1.15-alpine/ngnx:1.16-alpine/g' k8s-task-6.yml 2>/dev/null; sed -i -e 's/\\/var\\/logs/\\/usr\\/share\\/nginx\\/html/g' k8s-task-6.yml 2>/dev/null; sed -i '' 's/nginx:1.15-alpine/ngnx:1.16-alpine/g' k8s-task-6.yml 2>/dev/null; sed -i '' 's/\\/var\\/logs/\\/usr\\/share\\/nginx\\/html/g' k8s-task-6.yml 2>/dev/null; kubectl apply -f k8s-task-6.yml >/dev/null; sleep 4; kubectl apply -f k8s-task-6-bak.yml >/dev/null; sleep 4; kubectl rollout undo deploy webapp --to-revision=5 >/dev/null; kubectl delete $(kubectl get rs --sort-by=\".spec.replicas\" -oname | tail -n1) >/dev/null; rm k8s-task-6.yml k8s-task-6-bak.yml; echo 'lab: environment setup complete!'\n  ```\n- Command to destroy environment:\n  ```sh\n  kubectl delete deploy webapp\n  ```\n\n</div>\n\n<div id=\"hint-task7-1\">\n\n<details>\n  <summary>hints</summary>\n\n  <details>\n  <summary>hint 1</summary>\n\n  ReplicaSets store the Pod configuration used by a Deployment.\n  </details>\n\n  <details>\n  <summary>hint 2</summary>\n\n  You can reveal more resource details with `kubectl get -owide`. You might be able to find defective Pods/ReplicaSets quicker this way. \n  </details>\n\n  <details>\n  <summary>hint 3</summary>\n\n  You will need to review the Deployment's rollout history, see [lab 7.4 - rolling updates](https://github.com/piouson/ckad-bootcamp#lab-74-rolling-updates)\n  </details>\n\n  <details>\n  <summary>hint 4</summary>\n\n  You can view more details of a rollout revision with `kubectl rollout history --revision=$REVISION_NUMBER`\n  </details>\n\n  <details>\n  <summary>hint 5</summary>\n\n  Did you test that the Pods are serving an actual webpage? This task isn't complete without testing the webpage - Pods in _Running_ state doesn't mean _fully functional_ version.\n  </details>\n\n  <details>\n  <summary>hint 6</summary>\n\n  You can test a Pod with `kubectl port-forward`, by creating a temporary Pod `kubectl run --rm -it --image=nginx:alpine -- sh` and running `curl $POD_IP`, etc.\n  </details>\n\n  <details>\n  <summary>hint 7</summary>\n\n  Always remember `kubectl explain` when you encounter new requirements. Use this to figure out what rolling update parameters are required.  \n  </details>\n\n  <details>\n  <summary>hint 8</summary>\n\n  You can update a Deployment's image quickly with `kubectl set image --help`. You're not required to count Pods during rolling update, all should be fine long as you have `maxSurge` and `maxUnavailable` set correctly. \n  </details>\n\n  <details>\n  <summary>hint 9</summary>\n\n  Any change that triggers a rollout (changing anything under `deploy.spec.template`) will create a new ReplicaSet which becomes visible with `kubectl rollout history`. \\\n  Be sure to perform updates one after the other, without batching, as an exam question dictates, especially if the changes trigger a rollout. For example, apply replicas and update strategy changes before applying image changes.\n  </details>\n\n  <details>\n  <summary>hint 10</summary>\n\n  You can set replicas quickly with `kubectl scale --help`.  \n  </details>\n\n  <details>\n  <summary>hint 11</summary>\n\n  You can Annotate all 4 Pods in a single command, see `kubectl annotate --help`.\n  </details>\n</details>\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 8. Networking\n\n### Service\n\nA [Service](https://kubernetes.io/docs/concepts/services-networking/service/) provides access to applications running on a set of Pods. A Deployment creates and destroys Pods dynamically, so you cannot rely on Pod IP. This is where _Services_ come in, to provide access and load balancing to the Pods.\n\nLike Deployments, Services targets Pods by _selector_ but exists independent from a Deployment - not deleted during Deployment deletion and can provide access to Pods in different Deployments.\n\n#### Service Types\n\n- ClusterIP: this is a service inside a cluster responsible for routing traffic between apps running in the cluster - no external access\n- [NodePort](https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport): as the name implies, a specific port is opened on each _Worker Node_'s IP to allow external access to the cluster at `$NodeIP:$NodePort` - useful for testing purposes\n- [LoadBalancer](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer): Exposes the Service using a cloud provider (not for [CKAD](https://www.cncf.io/certification/ckad/))\n- [ExternalName](https://kubernetes.io/docs/concepts/services-networking/service/#externalname): Uses DNS records (not for CKAD)\n\n<details>\n<summary><i>ClusterIP</i> and <i>NodePort</i> example</summary>\n\n![ClusterIP and NodePort topology](https://user-images.githubusercontent.com/17856665/187857434-f07e0289-699e-4868-b84e-bd196bdfb4d7.png)\n\n</details>\n\n#### Discovering services\n\nKubernetes supports two primary modes of finding a Service - environment variables and DNS.\n\nIn the env-vars mode, the [_kubelet_](https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/) adds a set of env-vars (`{SVCNAME}_SERVICE_HOST` and `{SVCNAME}_SERVICE_PORT`) to each Pod for each active Service. Services must be created before Pods to auto-populate the env-vars. You can disable this mode by setting the `pod.spec` field `enableServiceLinks: false`.\n\nThe DNS mode is the recommended discovery method. A cluster-aware DNS server, such as [_CoreDNS_](https://kubernetes.io/docs/tasks/administer-cluster/coredns/#about-coredns), watches the Kubernetes API for new Services and creates a set of DNS records for each one. If DNS has been enabled throughout your cluster, then for a Service called `my-service` in a Kubernetes namespace `my-ns`, Pods in the `my-ns` namespace can find the service by a name lookup for `my-service`, while Pods in other namespaces must qualify the name `my-service.my-ns`.\n\n> Always remember that a Service will only target Pods that have Labels matching the Service's Label Selector \\\n> Not all images expose their applications on port 80. When unsure, try one of `netstat -tulpn` or `ss -tulpn` in the container.\n\n```yaml\n# service\nkind: Service\nmetadata:\n  name: webapp\nspec:\n  selector:\n    appid: webapp # this must match the label of a pod to be targeted by a Service\n  ports:\n  - nodePort: 32500 # node port\n    port: 80 # service port\n    targetPort: 8080 # container port - do not assume port 80, always check container\n---\n# pod targeted\nkind: Pod\nmetadata:\n  labels:\n    appid: webapp # matches label selector of service\n  name: mypod\n---\n# pod not targeted\nkind: Pod\nmetadata:\n  labels:\n    app: webapp # does not match label selector of service\n  name: mypod\n```\n\n```sh\n# view the service spec\nkubectl explain svc.spec | less\n# create a ClusterIP service by exposing a deployment `myapp` on port 80, see `kubectl expose -h`\nkubectl expose deploy myapp --port=80\n# specify a different service name, the deployment name is used if not specified\nkubectl expose deploy myapp --port=80 --name=myappsvc\n# specify container port 8000\nkubectl expose deploy myapp --port=80 --target-port=8000\n# create a NodePort service\nkubectl expose deploy myapp --type=NodePort --port=80\n# print a pod's service environment variables\nkubectl exec $POD_NAME -- printenv | grep SERVICE\n# view more details of the service exposing deployment `myapp`\nkubectl describe svc myapp\n# view the yaml form of service in yaml\nkubectl get svc myapp -o yaml | less\n# edit service\nkubectl edit svc myapp\n# list all endpoints\nkubectl get endpoints\n# list pods and their IPs\nkubectl get pods -o wide\n```\n\n<div id=\"lab8-1\">\n\n### Lab 8.1. Connecting applications with services\n\n1. Create a simple deployment with name `webserver`\n2. List created resources\n3. List endpoints, and pods with their IPs\n   - Can you spot the relationship between the Service, Endpoints and Pods?\n4. Create a Service for the deployment, exposed on port 80\n5. List created resources and note services fields `TYPE`, `CLUSTER-IP`, `EXTERNAL-IP` and `PORT(S)`\n6. View more details of the Service and note fields `IPs`, `Port`, `TargetPort` and `Endpoints`\n7. View the YAML form of the Service and compare info shown with output in [6]\n8. Print the Service env-vars from one of the pods\n9. Scale the deployment down to 0 replicas first, then scale up to 2 replicas\n10. List all pods and their IPs\n11. Print the Service env-vars from one of the pods and compare to results in [3]\n12. List endpoints, and pods with their IPs\n13. Access the app by the Service: `curl $ClusterIP:$Port`\n14. Access the app by the Service from the container host: `minikube ssh` then `curl $ClusterIP:$Port`\n15. Run a `busybox` Pod with a shell connected interactively and perform the following commands:\n   - run `cat /etc/resolv.conf` and review the output\n   - run `nslookup webserver` (service name) and review the output\n   - what IPs and/or qualified names do these match?\n16. Run a temporary `nginx:alpine` Pod to query the Service by name:\n   - first run `kubectl run mypod --rm -it --image=nginx:alpine -- sh`\n   - then once in container, run `curl $SERVICE_NAME:$PORT`\n   - you should run `curl $SERVICE_NAME.$SERVICE_NAMESPACE:$PORT` if the Service and the temporary Pod are in separate Namespaces\n17. Delete created resources\n18. Explore the Service object and the Service spec\n\n</div>\n\n<div id=\"soln-lab8-1\">\n\n<details>\n<summary>lab 8.1 solution</summary>\n\n```sh\n# host terminal\nkubectl create deploy webserver --image=httpd --dry-run=client -o yaml > lab8-1.yaml\nkubectl apply -f lab8-1.yaml\nkubectl get all\nkubectl get svc,ep,po -o wide # endpoints have <ip_address:port> of pods targeted by service\necho --- >> lab8-1.yaml\nkubectl expose deploy webserver --port=80 --dry-run=client -o yaml >> lab8-1.yaml\nkubectl apply -f lab8-1.yaml\nkubectl get svc,pods\nkubectl describe svc webserver | less\nkubectl get svc webserver -o yaml | less # missing endpoints IPs\nkubectl exec $POD_NAME -- printenv | grep SERVICE # no service env-vars\nkubectl scale deploy webserver --replicas=0; kubectl scale deploy webserver --replicas=2\nkubectl get pods -o wide # service env-vars applied to pods created after service\nkubectl exec $POD_NAME -- printenv | grep SERVICE\nkubectl get endpoints,pods -o wide\ncurl $CLUSTER_IP # docker-desktop connection error, docker-engine success\nminikube ssh\n# cluster node terminal\ncurl $CLUSTER_IP # success with both docker-desktop and docker-engine\nexit\n# host terminal\nkubectl run mypod --rm -it --image=busybox\n# container terminal\ncat /etc/resolv.conf # shows service ip as dns server\nnslookup webserver # shows dns search results, read more at https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#namespaces-of-services\nexit\n# host terminal\nkubectl run mypod --rm -it --image=nginx:alpine -- sh\n# container terminal\ncurl webserver # no need to add port cos default is 80\ncurl webserver.default # this uses the namespace of the service\nexit\n# host terminal\nkubectl delete -f lab8-1.yaml\nkubectl explain service | less\nkubectl explain service.spec | less\n```\n\n</details>\n\n</div>\n\n<div id=\"lab8-2\">\n\n### Lab 8.2. Connect a frontend to a backend using services\n\nIn this lab, we will implement a naive example of a _backend-frontend_ microservices architecture - expose frontend to external traffic with `NodePort` Service while keeping backend hidden with `ClusterIP` Service.\n\n> Note that live environments typically use [_Ingress_](#9-ingress) (covered in the next chapter) to expose applications to external traffic\n\n<details>\n<summary><i>Backend-Frontend</i> microservices architecture example</summary>\n\n![backend-frontend microservice architecture](https://user-images.githubusercontent.com/17856665/187857523-8d0fd28f-d540-4453-bae9-ff5481d63e07.png)\n\n</details>\n\n1. Create a simple Deployment, as our `backend` app, with the following spec:\n   - image `httpd` (for simplicity)\n   - name `backend`\n   - has Labels `app: backend` and `tier: webapp`\n   - has Selectors `app: backend` and `tier: webapp`\n2. Create a Service for the backend app with the following spec:\n   - type `ClusterIP`\n   - port 80\n   - same name, Labels and Selectors as backend Deployment\n3. Confirm you can access the app by `$CLUSTER-IP` or `$SERVICE_NAME`\n4. Create an [nginx _server block_ config file `nginx/default.conf`]() to redirect traffic for the `/` route to the backend service\n\n   ```sh\n   # nginx/default.conf\n   upstream backend-server {\n       server backend; # dns service discovery within the same namespace use service name\n   }\n\n   server {\n       listen 80;\n\n       location / {\n           proxy_pass http://backend-server;\n       }\n   }\n   ```\n\n5. Create a simple Deployment, as our `frontend` app, with the following spec:\n   - image `nginx`\n   - name `frontend`\n   - has Labels `app: webapp` and `tier: frontend`\n   - has Selectors `app: webapp` and `tier: frontend`\n   - Remember that Services target Pods by Selector (the Label Selector of the Service must match the Label of the Pod)\n   - mounts the nginx config file to `/etc/nginx/conf.d/default.conf` (use fullpath `$(pwd)/nginx/default.conf`)\n   - see example [_hostPath volume mount manifest_](https://kubernetes.io/docs/concepts/storage/volumes/#hostpath-configuration-example)\n6. Create a Service for the frontend app with the following spec:\n   - type `NodePort`\n   - port 80\n   - same name, Labels and Selectors as frontend Deployment\n   - Remember that Services target Pods by Selector\n7. Confirm you can access the backend app from the Minikube Node `$(minikube ip):NodePort`\n8. Delete created resources\n\n</div>\n\n<div id=\"soln-lab8-2\">\n\n<details>\n<summary>lab 8.2 solution</summary>\n\n```sh\nkubectl create deploy backend --image=httpd --dry-run=client -o yaml > lab8-2.yaml\necho --- >> lab8-2.yaml\nkubectl expose deploy backend --port=80 --dry-run=client -o yaml >> lab8-2.yaml\nnano lab8-2.yaml\n```\n\n```yaml\n# backend deploymemt\nkind: Deployment\nmetadata:\n  labels:\n    app: backend\n    tier: webapp\n  name: backend\nspec:\n  selector:\n    matchLabels:\n      app: backend\n      tier: webapp\n  template:\n    metadata:\n      labels:\n        app: backend\n        tier: webapp\n# backend service\nkind: Service\nmetadata:\n  labels:\n    app: backend\n    tier: webapp\n  name: backend\nspec:\n  selector:\n    app: backend\n    tier: webapp\n```\n\n```sh\nkubectl apply -f lab8-2.yaml\ncurl $CLUSTER_IP # or run in node terminal `minikube ssh`\nmkdir nginx\nnano nginx/default.conf # use snippet from step [4]\necho --- >> lab8-2.yaml\nkubectl create deploy frontend --image=nginx --dry-run=client -o yaml >> lab8-2.yaml\necho --- >> lab8-2.yaml\nkubectl expose deploy frontend --port=80 --dry-run=client -o yaml >> lab8-2.yaml\nnano lab8-2.yaml\n```\n\n```yaml\n# frontend deploymemt\nkind: Deployment\nmetadata:\n  labels:\n    app: frontend\n    tier: webapp\n  name: frontend\nspec:\n  selector:\n    matchLabels:\n      app: frontend\n      tier: webapp\n  template:\n    metadata:\n      labels:\n        app: frontend\n        tier: webapp\n    spec:\n      containers:\n      - image: nginx\n        volumeMounts:\n        - mountPath: /etc/nginx/conf.d/default.conf\n          name: conf-volume\n      volumes:\n      - name: conf-volume\n        hostPath:\n          path: /full/path/to/nginx/default.conf # `$(pwd)/nginx/default.conf`\n# frontend service\nkind: Service\nmetadata:\n  labels:\n    app: frontend\n    tier: webapp\n  name: frontend\nspec:\n  type: NodePort\n  selector:\n    app: frontend\n    tier: webapp\n```\n\n```sh\nkubectl apply -f lab8-2.yaml\nkubectl get svc,pods\ncurl $(minikube ip):$NODE_PORT # shows backend httpd page\nkubectl delete -f lab8-2.yaml\n```\n\n</details>\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n<div id=\"task8-1\">\n\n### Task - Service\n\nCreate a Pod named `webapp` in the `pig` Namespace (create new if required), running `nginx:1.20-alpine` image. The Pod should have a Annotation `motd=\"Welcome to Piouson's CKAD Bootcamp\"`. Expose the Pod on port 8080.\n\n</div>\n\n<div id=\"hint-task8-1\">\n\n<details>\n  <summary>hints</summary>\n\n  <details>\n  <summary>hint 1</summary>\n\n  Did you create the Pod in the `pig` Namespace? You should create the Namespace if it doesn't exist.\n  </details>\n\n  <details>\n  <summary>hint 2</summary>\n\n  You can set Annotation when creating a Pod, see `kubectl run --help`\n  </details>\n\n  <details>\n  <summary>hint 3</summary>\n\n  Actually, besides creating the Namespace, you can complete the rest of the task in a single command. Completing this task any other way is not but time wasting. Have a deeper look at `kubectl run --help`.\n  </details>\n\n  <details>\n  <summary>hint 4</summary>\n\n  Did you test you are able to access the app via the Service? This task is not complete until you confirm the application is accessible via the Service.\n  </details>\n\n  <details>\n  <summary>hint 5</summary>\n\n  You can test the Service by connecting a shell to a temporary Pod `kubectl run -it --rm --image=nginx:alpine -n $NAMESPACE -- sh` and run `curl $SERVICE_NAME:$PORT`. If you did not create the temporary Pod in the same Namespace, you will need to add the Namespace to the hostname `curl $SERVICE_NAME.$NAMESPACE:$PORT`. \\\n  Testing this way, with Service hostname, is also a way to confirm DNS is working in the cluster.\n  </details>\n</details>\n\n</div>\n\n<div id=\"task8-2\">\n\n### Task - Service II\n\nA bootcamp student is stuck on a _simple task_ and would appreciate your expertise. Their goal is to create a `webapp` Deployment running `gcr.io/google-samples/node-hello:1.0` image in the `bat` Namespace, exposed on port 80 and _NodePort_ 32500. The student claims _everything_ was setup as explained in class but still unable to access the application via the Service. Swoop down like a superhero and save the day by picking up where the student left off.\n\n- Command to setup environment:\n  ```sh\n  printf '\\nlab: environment setup in progress...\\n'; echo '{\"apiVersion\":\"v1\",\"kind\":\"List\",\"items\":[{\"apiVersion\":\"v1\",\"kind\":\"Namespace\",\"metadata\":{\"name\":\"bat\"}},{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"metadata\":{\"labels\":{\"appid\":\"webapp\"},\"name\":\"webapp\",\"namespace\":\"bat\"},\"spec\":{\"replicas\":2,\"selector\":{\"matchLabels\":{\"appid\":\"webapp\"}},\"template\":{\"metadata\":{\"labels\":{\"appid\":\"webapp\"}},\"spec\":{\"containers\":[{\"image\":\"gcr.io/google-samples/node-hello:1.0\",\"name\":\"nginx\"}]}}}},{\"apiVersion\":\"v1\",\"kind\":\"Service\",\"metadata\":{\"labels\":{\"appid\":\"webapp\"},\"name\":\"webapp\",\"namespace\":\"bat\"},\"spec\":{\"ports\":[{\"port\":80,\"protocol\":\"TCP\",\"targetPort\":80}],\"selector\":{\"app\":\"webapp\"}}}]}' | kubectl apply -f - >/dev/null; echo 'lab: environment setup complete!'\n  ```\n- Command to destroy environment\n  ```sh\n  kubectl delete ns bat\n  ```\n\n</div>\n\n<div id=\"hint-task8-2\">\n\n<details>\n  <summary>hints</summary>\n\n  <details>\n  <summary>hint 1</summary>\n\n  Did you check for the relationship between the Service, Endpoint and Pods? When a Service with a _Selector_ is created, an Endpoint with the same name is automatically created. See [_lab 8.1 - connecting applications with services_](#lab-81-connecting-applications-with-services).\n  </details>\n\n  <details>\n  <summary>hint 2</summary>\n\n  Did you confirm that the Service configuration matches the requirements with `kubectl describe svc`? You should also run some tests, see [_discovering services_](#discovering-services) and [_lab 8.1 - connecting applications with services_](#lab-81-connecting-applications-with-services).\n  </details>\n\n  <details>\n  <summary>hint 3</summary>\n\n  If you're still unable to access the app but Endpoints have correct IP addresses, you might want to check if there is a working application to begin with. See [_lab 5.1 - creating pods_](#lab-51-creating-pods)\n  </details>\n\n  <details>\n  <summary>hint 4</summary>\n\n  Now you have the container port? Is the Service configured to use this container port? Is the Pod configured to use this container port? 💡\n  </details>\n\n  <details>\n  <summary>hint 5</summary>\n\n  Remember a Service can specify three types of ports: `port | targetPort | nodePort`. Which is the container port?\n  </details>\n\n  <details>\n  <summary>hint 6</summary>\n\n  For a Service, you can quickly verify the configured container port by reviewing the IP addresses of the Service Endpoint, they should be of the form `$POD_IP:CONTAINER_PORT` \\\n  Once resolved, you should be able to access the application via the Service with `curl`.\n  </details>\n\n  <details>\n  <summary>hint 7</summary>\n\n  For a Pod, you can quickly verify the configured container port by reviewing the ReplicaSet config with `kubectl describe rs`. \\\n  Once resolved, you should be able to access the application via the Service with `curl`.\n  </details>\n</details>\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 9. Ingress\n\n[Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/) exposes HTTP and HTTPS routes from outside the cluster to services within the cluster. Traffic routing is controlled by rules defined on the Ingress resource. Ingress may be configured to give Services externally-reachable URLs, [load balance traffic](https://www.cloudflare.com/en-in/learning/performance/what-is-load-balancing/), [terminate SSL/TLS](https://www.f5.com/services/resources/glossary/ssl-termination), and offer [name-based virtual hosting](https://www.tecmint.com/apache-ip-based-and-name-based-virtual-hosting/).\n\n> 💡 Only creating an Ingress resource has no effect! You must have an [Ingress controller](https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/) to satisfy an Ingress. In our local lab, we will use the _Minikube Ingress controller_\n\n<details>\n<summary>ingress-service topology</summary>\n\n![ingress network topology](https://user-images.githubusercontent.com/17856665/188259540-a6755ae5-d885-41f3-8e1e-1cee6f5e1bcc.png)\n\n</details>\n\n```sh\n# list existing minikube addons\nminikube addons list\n# enable ingress on minikube\nminikube addons enable ingress\n# enable ingress manually\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.44.0/deploy/static/provider/cloud/deploy.yaml\n# list existing namespaces\nkubectl get ns\n# list resources in the ingress namespace\nkubectl get all -n ingress-nginx\n# list ingressclass resource in the ingress namespace\nkubectl get ingressclass -n ingress-nginx\n# view ingress spec\nkubectl explain ingress.spec | less\n```\n\n> You can remove the need for a trailing slash `/` in urls by adding annotation `nginx.ingress.kubernetes.io/rewrite-target: /` to ingress spec `ingress.metadata.annotations`\n\n<div id=\"lab9-1\">\n\n### Lab 9.1 Enable Ingress\n\n1. List existing namespaces\n2. Enable Ingress on minikube\n3. List Namespaces and confirm new Ingress Namespace added\n4. List all resources in the Ingress Namespace, including the _ingressclass_\n5. Review the _ingress-nginx-controller_ Service in YAML form, note service type and ports\n6. Review the _ingressclass_ in YAML form, is this marked as the default?\n7. Review the Ingress spec\n\n</div>\n\n<div id=\"soln-lab9-1\">\n\n<details>\n<summary>lab9.1 solution</summary>\n  \n```sh\nkubectl get ns # not showing ingress-nginx namespace \nminikube addons list # ingress not enable\nminikube addons enable ingress\nminikube addons list # ingress enabled\nkubectl get ns # shows ingress-nginx namespace\nkubectl get all,ingressclass -n ingress-nginx # shows pods, services, deployment, replicaset, jobs and ingressclass\nkubectl get svc ingress-nginx-controller -o yaml | less\nkubectl get ingressclass nginx -o yaml | less # annotations - ingressclass.kubernetes.io/is-default-class: \"true\"\nkubectl explain ingress.spec | less\n```\n</details>\n\n</div>\n\n### Ingress Types\n\n- **single-service ingress** defines a single rule to access a single service\n- **simple fanout ingress** defines two or more rules of different paths to access different services\n- **name-based virtual hosting ingress** defines two or more rules with dynamic routes based on host header - requires a DNS entry for each host header\n\n```sh\n# create ingress with a specified rule, see `kubectl create ingress -h`\nkubectl create ingress $INGRESS_NAME --rule=\"$PATH=$SERVICE_NAME:$PORT\"\n# create single-service ingress `myingress`\nkubectl create ingress myingress --rule=\"/=app1:80\"\n# create simple-fanout ingress\nkubectl create ingress myingress --rule=\"/=app1:80\" --rule=\"/about=app2:3000\" --rule=\"/contact=app3:8080\"\n# create name-based-virtual-hosting ingress\nkubectl create ingress myingress --rule=\"api.domain.com/*=apiservice:80\" --rule=\"db.domain.com/*=dbservice:80\" --rule=\"app.domain.com/*=appservice:80\"\n```\n\n<div id=\"lab9-2\">\n\n### Lab 9.2 Understanding ingress\n\n1. Create a Deployment called `web` using a `httpd` image\n2. Expose the deployment with a _Cluster-IP_ Service called `web-svc`\n3. Create an Ingress called `web-ing` with a _Prefix_ rule to redirect `/` requests to the Service\n4. List all created resources - what is the value of Ingress `CLASS`, `HOSTS` & `ADDRESS`?\n   - think about why the `CLASS` and `HOSTS` have such values..\n5. Access the app `web` via ingress `curl $(minikube ip)`\n   - note that unlike Service, a _NodePort_ isn't specified\n6. What if we want another application on `/test` path, will this work? Repeat steps 3-7 to confirm:\n   - create a new deployment `web2` with image `httpd`\n   - expose the new deployment `web2-svc`\n   - add new _Prefix_ path to existing ingress rule to redirect `/test` to `web2-svc`\n   - are you able to access the new `web2` app via `curl $(minikube ip)/test`?\n   - are you still able to access the old `web` app via `curl $(minikube ip)`?\n   - what's missing?\n7. Let's fix this by adding the correct _Annotation_ to the Ingress config, `kubectl edit ingress web-ing`:\n   <details>\n   <summary>fix ingress</summary>\n\n   ```yaml\n   metadata:\n     name: web-ing\n     annotations:\n       nginx.ingress.kubernetes.io/rewrite-target: /\n   ```\n   </details>\n8. Try to access both apps via URLs `curl $(minikube ip)/test` and `curl $(minikube ip)`\n9. Can you access both apps using HTTPS?\n10. Review the _ingress-nginx-controller_ by running: `kubectl get svc -n ingress-nginx`\n   - what is the _ingress-nginx-controller_ Service type?\n   - what are the ports related to HTTP `80` and HTTPS `443`?\n11. Can you access both apps via the _ingress-nginx-controller_ NodePorts for HTTP and HTTPS?\n12. Delete all created resources\n\n</div>\n\n<div id=\"lab9-2\">\n\n<details>\n<summary>lab9.2 solution</summary>\n  \n```sh\nkubectl create deploy web --image=httpd --dry-run=client -oyaml > lab9-2.yml\nkubectl apply -f lab9-2.yml\necho --- >> lab9-2.yml\nkubectl expose deploy web --name=web-svc --port=80 --dry-run=client -oyaml >> lab9-2.yml\necho --- >> lab9-2.yml\nkubectl create ingress web-ing --rule=\"/*=web-svc:80\" --dry-run=client -oyaml >> lab9-2.yml\nkubectl apply -f lab9-2.yml\nkubectl get deploy,po,svc,ing,ingressclass # CLASS=nginx, HOSTS=*, ADDRESS starts empty then populated later\ncurl $(minikube ip) # it works\necho --- >> lab9-2.yml\nkubectl create deploy web2 --image=httpd --dry-run=client -oyaml > lab9-2.yml\nkubectl apply -f lab9-2.yml\necho --- >> lab9-2.yml\nkubectl expose deploy web2 --name=web2-svc --port=80 --dry-run=client -oyaml >> lab9-2.yml\nKUBE_EDITOR=nano kubectl edit ingress web-ing\n```\n\n```yaml\nKind: Ingress\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /\n        pathType: Prefix\n        ...\n      - path: /test\n        pathType: Prefix\n        backend:\n          service:\n            name: web2-svc\n            port:\n              number: 80\n# etc\n```\n\n```sh\ncurl $(minikube ip)/test # 404 not found ???\ncurl $(minikube ip) # it works\nKUBE_EDITOR=nano kubectl edit ingress web-ing\n```\n\n```yaml\nKind: Ingress\nmetadata:\n  name: web-ing\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n# etc\n```\n\n```sh\ncurl $(minikube ip)/test # it works\ncurl $(minikube ip) # it works\ncurl https://$(minikube ip)/test --insecure # it works, see `curl --help`\ncurl https://$(minikube ip) --insecure # it works\nkubectl get svc -n ingress-nginx # NodePort, 80:$HTTP_NODE_PORT/TCP,443:$HTTPS_NODE_PORT/TCP\ncurl $(minikube ip):$HTTP_NODE_PORT\ncurl $(minikube ip):$HTTP_NODE_PORT/test\ncurl https://$(minikube ip):$HTTPS_NODE_PORT --insecure\ncurl https://$(minikube ip):$HTTPS_NODE_PORT/test --insecure\nkubectl delete deploy web web2\nkubectl delete svc web-svc web2-svc\nkubectl delete ingress web-ing web2-ing\n```\n</details>\n\n> Ingress relies on Annotations to specify additional configuration. The supported Annotations depends on the Ingress controller type in use - in this case _Ingress-Nginx_ \\\n> Please visit the [_Ingress-Nginx_ official _Rewrite_ documentation](https://github.com/kubernetes/ingress-nginx/blob/main/docs/examples/rewrite/README.md) for more details\n\n</div>\n\n<div id=\"lab9-3\">\n\n### Lab 9.3. Simple fanout Ingress\n\n1. Create an Ingress `webapp-ingress` that:\n   - redirects requests for path `myawesomesite.com/` to a Service `webappsvc:80`\n   - redirects requests for path `myawesomesite.com/hello` to a Service `hellosvc:8080`\n   - remember to add the _Rewrite_ Annotation\n2. List created resources - compare the value of Ingress `HOSTS` to the previous lab\n3. View more details of the Ingress and review the notes under _Rules_\n4. View the Ingress in YAML form and review the structure of the Rules\n5. Create a Deployment `webapp` with image `httpd`\n6. Expose the `webapp` Deployment as _NodePort_ with service name `webappsvc`\n7. List all created resources - ingress, service, deployment and other resources associated with the deployment\n8. View more details of the Ingress and review the notes under _Rules_\n9. Can you access `webapp` via the minikube Node `curl $(minikube ip)` or `curl myawesomesite.com`?\n10. Create a second Deployment `hello` with image `gcr.io/google-samples/hello-app:1.0`\n11. Expose `hello` as _NodePort_ with service name `hellosvc`\n12. List newly created resources - service, pods, deployment etc\n13. View more details of the Ingress and review the notes under _Rules_\n14. Can you access `hello` via `curl $(minikube ip)/hello` or `myawesomesite.com/hello`?\n15. Add an entry to `/etc/hosts` that maps the minikube Node IP to an hostname `$(minikube ip) myawesomesite.com`\n16. Can you access `webapp` via `curl $(minikube ip)` or `myawesomesite.com` with HTTP and HTTPS \n17. Can you access `hello` via `curl $(minikube ip)/hello` or `myawesomesite.com/hello` with HTTP and HTTPS\n18. Can you access `webapp` and `hello` on `myawesomesite.com` via the NodePorts specified by the `ingress-nginx-controller`, `webappsvc` and `hellosvc` Services?\n19. Delete created resources\n\n</div>\n\n<div id=\"soln-lab9-3\">\n\n<details>\n<summary>lab9.3 solution</summary>\n  \n```sh\nkubectl create ingress webapp-ingress --rule=\"myawesomesite.com/*=webappsvc:80\" --rule=\"myawesomesite.com/hello/*=hellosvc:8080\" --dry-run=client -oyaml > lab9-3.yaml\necho --- >> lab9-3.yaml\nkubectl apply -f lab9-3.yaml\nkubectl get ingress\nkubectl describe ingress webapp-ingress | less # endpoints not found\nkubectl get ingress webapp-ingress -oyaml | less\nkubectl create deploy webapp --image=httpd --dry-run=client -oyaml >> lab9-3.yaml\necho --- >> lab9-3.yaml\nkubectl apply -f lab9-3.yaml\nkubectl expose deploy webapp --name=webappsvc --type=NodePort --port=80 --dry-run=client -o yaml >> lab9-3.yaml\necho --- >> lab9-3.yaml\nkubectl apply -f lab9-3.yaml\nkubectl get ingress,all\nkubectl describe ingress webapp-ingress | less # only webappsvc endpoint found\ncurl $(minikube ip) # 404 not found\ncurl myawesomesite.com # 404 not found\nkubectl create deploy hello --image=gcr.io/google-samples/hello-app:1.0 --dry-run=client -o yaml >> lab9-3.yaml\necho --- >> lab9-3.yaml\nkubectl apply -f lab9-3.yaml\nkubectl expose deploy hello --name=hellosvc --type=NodePort --port=8080 --dry-run=client -o yaml >> lab9-3.yaml\necho --- >> lab9-3.yaml\nkubectl apply -f lab9-3.yaml\nkubectl get all --selector=\"app=hello\"\nkubectl describe ingress webapp-ingress | less # both endpoints found\ncurl $(minikube ip)/hello # 404 not found\ncurl myawesomesite.com/hello # 404 not found\necho \"$(minikube ip) myawesomesite.com\" | sudo tee -a /etc/hosts # see `tee --help`\ncurl $(minikube ip) # 404 not found\ncurl $(minikube ip)/hello # 404 not found\ncurl myawesomesite.com # it works\ncurl myawesomesite.com/hello # hello world\ncurl https://myawesomesite.com --insecure # it works\ncurl https://myawesomesite.com/hello --insecure # hello world\nkubectl get svc -A # find NodePorts for ingress-nginx-controller, webappsvc and hellosvc\ncurl myawesomesite.com:$NODE_PORT_FOR_WEBAPPSVC # it works\ncurl myawesomesite.com:$NODE_PORT_FOR_HELLOSVC # hello world\ncurl myawesomesite.com:$HTTP_NODE_PORT_FOR_NGINX_CONTROLLER # it works\ncurl myawesomesite.com:$HTTP_NODE_PORT_FOR_NGINX_CONTROLLER/hello # hello world\ncurl https://myawesomesite.com:$HTTPS_NODE_PORT_FOR_NGINX_CONTROLLER --insecure\ncurl https://myawesomesite.com:$HTTPS_NODE_PORT_FOR_NGINX_CONTROLLER/hello --insecure\nkubectl delete -f lab9-3.yaml\n```\n</details>\n\n</div>\n\n### Ingress rules\n\nThis is similar to defining API routes on a backend application, except each defined route points to a separate application/service/deployment.\n\n- if no host is specified, the rule applies to all inbound HTTP traffic\n- paths can be defined with a [POSIX regex](https://www.gnu.org/software/findutils/manual/html_node/find_html/)\n- each path points to a resource backend defined with a `service.name` and a `service.port.name` or `service.port.number`posix_002dextended-regular-expression-syntax.html)\n- both the host and path must match the content of an incoming request before the load balancer directs traffic to the referenced Service\n- a default path `.spec.defaultBackend` can be defined on the Ingress or _Ingress controller_ for traffic that doesn't match any known paths, similar to a 404 route - if `defaultBackend` is not set, the default 404 behaviour will depend on the type of _Ingress controller_ in use\n\n### Path types\n\nEach rule-path in an Ingress must have a [`pathType`](https://kubernetes.io/docs/concepts/services-networking/ingress/#path-types). Paths without a `pathType` will fail validation.\n\nThere are three supported path types:\n\n- `ImplementationSpecific` - matching is up to the _IngressClass_\n- `Exact` - case sensitive matching of exact URL path\n- `Prefix` - case sensitive matching of URL path prefix, split into elements by `/`, on element by element basis\n\n> Please read the official docs on [path matching examples](https://kubernetes.io/docs/concepts/services-networking/ingress/#examples) and [using wildcards](https://kubernetes.io/docs/concepts/services-networking/ingress/#hostname-wildcards)\n\n### Ingress Class\n\nIngresses can be implemented by different controllers, often with different configuration. Each Ingress should specify a class, a reference to an [_IngressClass_](https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-class) resource that contains additional configuration including the name of the controller that should implement the class.\n\nDepending on your ingress controller, you may be able to use parameters that you set cluster-wide, or just for one namespace.\n\n- cluster-wide _IngressClass_: this is the default scope configured if you set the `ingressclass.spec.parameters` field without setting `ingressclass.spec.parameters.scope`, or setting `ingressclass.spec.parameters.scope: Cluster`\n- namespace _IngressClass_: if you set the `ingressclass.spec.parameters` field and set `ingressclass.spec.parameters.scope: Namespace`\n\nA particular _IngressClass_ can be configured as default for a cluster by setting the `ingressclass.kubernetes.io/is-default-class` annotation to `true`\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: IngressClass\nmetadata:\n  annotations:\n    ingressclass.kubernetes.io/is-default-class: \"true\"\n# etc, see https://k8s.io/examples/service/networking/external-lb.yaml\n```\n\n```sh\n# list existing namespaces\nkubectl get ns\n# list ingressclasses in the ingress namespace\nkubectl get ingressclass -n ingress-nginx\n# list ingressclasses in the default namespace - present in all namespaces\nkubectl get ingressclass\n# view ingressclass object\nkubectl explain ingressclass | less\n```\n\n<div id=\"lab9-4\">\n\n### Lab 9.4. Multiple hosts ingress\n\n1. Review the _IngressClass_ resource object\n2. List the Ingress classes created by the minikube ingress addon\n3. Create two Deployments `nginx` and `httpd`\n4. Expose both deployments as `Cluster-IP` on port 80\n5. Create an Ingress with the following:\n   - redirects requests for `nginx.yourchosenhostname.com` to the `nginx` Service\n   - redirects requests for `httpd.yourchosenhostname.com` to the `httpd` Service\n   - both rules should use a `Prefix` path type\n6. Review created resources\n7. Confirm Ingress _PathType_ and _IngressClass_\n8. Review the _IngressClass_ resource YAML form to determine why it was assigned by default\n9. Add an entry to `/etc/hosts` that maps the minikube Node IP to hostnames below:\n   - `$(minikube ip)  nginx.yourchosenhostname.com`\n   - `$(minikube ip)  httpd.yourchosenhostname.com`\n10. Verify you can access both deployments via their subdomains\n11. Delete created resources\n\n</div>\n\n<div id=\"soln-lab9-4\">\n\n<details>\n<summary>lab9.4 solution</summary>\n  \n```sh\nkubectl explain ingressclass | less\nkubectl explain ingressclass --recursive | less\nkubectl create deploy nginx --image=nginx --dry-run=client -o yaml > lab9-4.yaml\necho --- >> lab9-4.yaml\nkubectl expose deploy nginx --port=80 --dry-run=client -o yaml >> lab9-4.yaml\necho --- >> lab9-4.yaml\nkubectl create deploy httpd --image=httpd --dry-run=client -o yaml >> lab9-4.yaml\necho --- >> lab9-4.yaml\nkubectl expose deploy httpd --port=80 --dry-run=client -o yaml >> lab9-4.yaml\necho --- >> lab9-4.yaml\nkubectl create ingress myingress --rule=\"nginx.yourchosenhostname.com/*=nginx:80\" --rule=\"httpd.yourchosenhostname.com/*=httpd:80\" --dry-run=client -o yaml > lab9-4.yaml\necho --- >> lab9-4.yaml\nkubectl apply -f lab9-4.yaml\nkubectl get ingress,all\nkubectl get ingress myingress -o yaml | less # `pathType: Prefix` and `ingressClassName: nginx`\nkubectl get ingressclass nginx -o yaml | less # annotation `ingressclass.kubernetes.io/is-default-class: \"true\"` makes this class the default\necho \"\n$(minikube ip)  nginx.yourchosenhostname.com\n$(minikube ip)  httpd.yourchosenhostname.com\n\" | sudo tee -a /etc/hosts\ncurl nginx.yourchosenhostname.com\ncurl httpd.yourchosenhostname.com\nkubectl delete -f lab9-4.yaml\n# note that when specifying ingress path, `/*` creates a `Prefix` path type and `/` creates an `Exact` path type\n```\n</details>\n\n</div>\n\n### Network policies\n\nThere are two kinds of Pod isolation: isolation for egress (outbound), and isolation for ingress (inbound). By default, all ingress and egress traffic is allowed to and from pods in a namespace, until you have a [NetworkPolicy](https://kubernetes.io/docs/concepts/services-networking/network-policies/) in that namespace.\n\nNetwork policies are implemented by a [_network plugin_](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/network-plugins/). A _NetworkPolicy_ will have no effect if a _network plugin_ that supports _NetworkPolicy_ is not installed in the cluster.\n\nThere are [three different identifiers](https://kubernetes.io/docs/concepts/services-networking/network-policies/#behavior-of-to-and-from-selectors) that controls entities that a Pod can communicate with:\n\n- `podSelector`: selects pods within the _NetworkPolicy_ namespace allowed for ingress/egress using _selector_ matching (note: a pod cannot block itself)\n- `namespaceSelector`: selects all pods in specific namespaces allowed for ingress/egress using _selector_ matching\n- `ipBlock`: selects IP CIDR ranges (cluster-external IPs) allowed for ingress/egress (note: node traffic is always allowed - not for CKAD)\n\n```sh\nminikube stop\nminikube delete\n# start minikube with calico plugin\nminikube start --kubernetes-version=1.23.9 --cni=calico\n# verify calico plugin running, allow enough time (+5mins) for all pods to enter `running` status\nkubectl get pods -n kube-system --watch\n# create network policy\nkubectl apply -f /path/to/networlpolicy/manifest/file\n# list network policies\nkubectl get networkpolicy\n# view more details of network policies `mynetpol`\nkubectl describe networkpolicy mynetpol\n```\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: test-netpol\n# create default deny all ingress/egress traffic\nspec:\n  podSelector: {}\n  policyTypes:\n  - Ingress # or Egress\n# create allow all ingress/egress traffic\nspec:\n  podSelector: {}\n  ingress: # or egress\n  - {}\n```\n\n<div id=\"lab9-5\">\n\n### Lab 9.5. Declare network policy\n\nYou may follow the [official declare network policy walkthrough](https://kubernetes.io/docs/tasks/administer-cluster/declare-network-policy/)\n\n> Minikube Calico plugin might conflict with the rest of the labs, so disabled Calico addon after this lab \\\n> Prepend `https://k8s.io/examples/` to any example files in the official docs to use the file locally\n\n1. Create a kubernetes cluster in minikube with Calico enabled\n2. Confirm Calico is up and running\n3. Create a Deployment called `webapp` using image `httpd`\n4. Expose the Deployment on port 80\n5. Review created resources and confirm pods running\n6. Create a busybox Pod and connect an interactive shell\n7. Run command in the Pod container `wget --spider --timeout=1 nginx`\n8. Limit access to the Service so that only Pods with label `tier=frontend` have access - see official manifest example `service/networking/nginx-policy.yaml`\n9. View more details of the _NetworkPolicy_ created \n10. Create a busybox Pod and connect an interactive shell\n11. Run command in the Pod container `wget --spider --timeout=1 nginx`\n12. Create another busybox Pod with label `tier=frontend` and connect an interactive shell\n13. Run command in the Pod container `wget --spider --timeout=1 nginx`\n14. Delete created resources\n15. Revert to a cluster without Calico\n\n</div>\n\n<div id=\"soln-lab9-5\">\n\n<details>\n<summary>lab9.5 solution</summary>\n  \n```sh\n# host terminal\nminikube stop\nminikube delete\nminikube start --kubernetes-version=1.23.9 --driver=docker --cni=calico\nkubectl get pods -n kube-system --watch # allow enough time, under 5mins if lucky, more than 10mins if you have bad karma 😼\nkubectl create deploy webapp --image=httpd --dry-run=client -o yaml > lab9-5.yaml\nkubectl apply -f lab9-5.yaml\necho --- >> lab9-5.yaml\nkubectl expose deploy webapp --port=80 --dry-run=client -o yaml > lab9-5.yaml\nkubectl apply -f lab9-5.yaml\nkubectl get svc,pod\nkubectl get pod --watch # wait if pod not in running status\nkubectl run mypod --rm -it --image=busybox\n# container terminal\nwget --spider --timeout=1 webapp # remote file exists\nexit\n# host terminal\necho --- >> lab9-5.yaml\nwget -qO- https://k8s.io/examples/service/networking/nginx-policy.yaml >> lab9-5.yaml\nnano lab9-5.yaml\n```\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: mynetpol\nspec:\n  podSelector:\n    matchLabels:\n      app: webapp\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          tier: frontend\n```\n\n```sh\nkubectl apply -f lab9-5.yaml\nkubectl describe networkpolicy mynetpol | less\nkubectl run mypod --rm -it --image=busybox\n# container terminal\nwget --spider --timeout=1 webapp # wget: download timed out\nexit\n# host terminal\nkubectl run mypod --rm -it --image=busybox --labels=\"tier=frontend\"\n# container terminal\nwget --spider --timeout=1 webapp # remote file exists\nexit\n# host terminal\nkubectl delete -f lab9-5.yaml\nminikube stop\nminikube delete\nminikube start --kubernetes-version=1.23.9 --driver=docker\n```\n</details>\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n<div id=\"task9-1\">\n\n### Task - Ingress\n\nThe application is meant to be accessible at `ckad-bootcamp.local`. Please debug and resolve the issue without creating any new resource.\n\n- Command to setup environment:\n  ```sh\n  printf '\\nlab: environment setup in progress...\\n'; echo '{\"apiVersion\":\"v1\",\"kind\":\"List\",\"items\":[{\"apiVersion\":\"v1\",\"kind\":\"Namespace\",\"metadata\":{\"name\":\"bat\"}},{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"metadata\":{\"labels\":{\"appid\":\"webapp\"},\"name\":\"webapp\",\"namespace\":\"bat\"},\"spec\":{\"replicas\":2,\"selector\":{\"matchLabels\":{\"appid\":\"webapp\"}},\"template\":{\"metadata\":{\"labels\":{\"appid\":\"webapp\"}},\"spec\":{\"containers\":[{\"image\":\"gcr.io/google-samples/node-hello:1.0\",\"name\":\"nginx\"}]}}}},{\"apiVersion\":\"v1\",\"kind\":\"Service\",\"metadata\":{\"labels\":{\"appid\":\"webapp\"},\"name\":\"webapp\",\"namespace\":\"bat\"},\"spec\":{\"ports\":[{\"port\":80,\"protocol\":\"TCP\",\"targetPort\":80}],\"selector\":{\"app\":\"webapp\"}}},{\"kind\":\"Ingress\",\"apiVersion\":\"networking.k8s.io/v1\",\"metadata\":{\"name\":\"webapp\",\"namespace\":\"bat\"},\"spec\":{\"ingressClassName\":\"ngnx\",\"rules\":[{\"http\":{\"paths\":[{\"path\":\"/\",\"pathType\":\"Prefix\",\"backend\":{\"service\":{\"name\":\"webapp\",\"port\":{\"number\":80}}}}]}}]}}]}' | kubectl apply -f - >/dev/null; echo 'lab: environment setup complete!'\n  ```\n- Command to destroy environment:\n  ```sh\n  kubectl delete ns dog\n  ```\n\n</div>\n\n<div id=\"task9-2\">\n\n### Task - Network policy\n\nGiven several Pods in Namespaces `pup` and `cat`, create network policies as follows:\n  - Pods in the same Namespace can communicate together\n  - `webapp` Pod in the `pup` Namespace can communicate with `microservice` Pod in the `cat` Namespace\n  - DNS resolution on UDP/TCP port 53 is allowed for all Pods in all Namespaces\n\n- Command to setup environment:\n  ```sh\n  printf '\\nlab: environment setup in progress...\\n'; echo '{\"apiVersion\":\"v1\",\"kind\":\"List\",\"items\":[{\"apiVersion\":\"v1\",\"kind\":\"Namespace\",\"metadata\":{\"name\":\"pup\"}},{\"apiVersion\":\"v1\",\"kind\":\"Namespace\",\"metadata\":{\"name\":\"cat\"}},{\"apiVersion\":\"v1\",\"kind\":\"Pod\",\"metadata\":{\"labels\":{\"server\":\"frontend\"},\"name\":\"webapp\",\"namespace\":\"pup\"},\"spec\":{\"containers\":[{\"image\":\"nginx:1.22-alpine\",\"name\":\"nginx\"}],\"dnsPolicy\":\"ClusterFirst\",\"restartPolicy\":\"Always\"}},{\"apiVersion\":\"v1\",\"kind\":\"Pod\",\"metadata\":{\"labels\":{\"server\":\"backend\"},\"name\":\"microservice\",\"namespace\":\"cat\"},\"spec\":{\"containers\":[{\"image\":\"node:16-alpine\",\"name\":\"nodejs\",\"args\":[\"sleep\",\"7200\"]}],\"dnsPolicy\":\"ClusterFirst\",\"restartPolicy\":\"Always\"}}]}' | kubectl apply -f - >/dev/null; echo 'lab: environment setup complete!'\n  ```\n- Command to destroy environment:\n  ```sh\n  kubectl delete ns cat pup\n  ```\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 10. Storage\n\n[PersistentVolume (PV)](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#introduction) is a piece of storage in the cluster that has been provisioned by an administrator or dynamically provisioned using Storage Classes, with a lifecycle independent of any individual Pod that uses the PV.\n\nPersistentVolumeClaim (PVC) is a request for storage by a user. It is similar to a Pod. Pods consume node resources and PVCs consume PV resources. Claims can request specific size and [access modes (ReadWriteOnce, ReadOnlyMany, ReadWriteMany, or ReadWriteOncePod)](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes).\n\n- Pods connect to the PVC, and a PVC connects to the PV, both in a 1-1 relationship (only one PVC can connect to a PV)\n- PVC can be created from an existing PVC\n- PVC will remain in `STATUS=Pending` until it finds and connects to a matching PV and thus **`STATUS=Bound`**\n- PV supports a number of [raw block volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#raw-block-volume-support)\n\n### Access modes\n\n- ReadWriteOnce: volume can be mounted as read-write by a single node - allows multiple pods running on the node access the volume\n- ReadOnlyMany: volume can be mounted as read-only by many nodes\n- ReadWriteMany: volume can be mounted as read-write by many nodes\n- ReadWriteOncePod: volume can be mounted as read-write by a single Pod\n\n### PV and PVC attributes\n\n| PV attributes    | PVC attributes   |\n| ---------------- | ---------------- |\n| capacity         | resources        |\n| volume modes     | volume modes     |\n| access modes     | access modes     |\n| storageClassName | storageClassName |\n| mount options    | selector         |\n| reclaim policy   |                  |\n| node affinity    |                  |\n| phase            |                  |\n\n### Storage Class\n\nA [StorageClass](https://kubernetes.io/docs/concepts/storage/storage-classes/) provides a way for administrators to describe the \"classes\" of storage they offer. It enables automatic PV provisioning to meet PVC requests, thus removing the need to manually create PVs. StorageClass must have a specified **provisioner** that determines what volume plugin is used for provisioning PVs.\n\n- A PV with a specified `storageClassName` can only be bound to PVCs that request that `storageClassName`\n- A PV with `storageClassName` attribute not set is intepreted as _a PV with no class_, and can only be bound to PVCs that request a PV with no class.\n- A PVC with `storageClassName=\"\"` (empty string) is intepreted as _a PVC requesting a PV with no class_.\n- A PVC with `storageClassName` attribute not set is not quite the same and behaves different whether [the `DefaultStorageClass` admission plugin is enabled](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#defaultstorageclass)\n  - if the admission plugin is enabled, and a default StorageClass specified, all PVCs with no `storageClassName` can be bound to PVs of that default\n  - if a default StorageClass is not specified, PVC creation is treated as if the admission plugin is disabled\n  - if the admission plugin is disabled, all PVCs that have no `storageClassName` can only be bound to PVs with no class\n\n> If a PVC doesn't find a PV with matching access modes and storage, StorageClass may dynamically create a matching PV\n\n> `hostPath` volumes is created on the host, in minikube use the `minikube ssh` command to access the host (requires starting the cluster with `--driver=docker`)\n\n<div id=\"lab10-1\">\n\n### Lab 10.1. PVs and PVCs\n\n```sh\n# list PVCs, PVs\nkubectl get {pvc|pv|storageclass}\n# view more details of a PVC\nkubectl decribe {pvc|pv|storageclass} $NAME\n```\n\n1. Create a PV with 3Gi capacity using official docs `pods/storage/pv-volume.yaml` manifest file as base\n2. Create a PVC requesting 1Gi capacity using official docs `pods/storage/pv-claim.yaml` manifest file as base\n3. List created resources\n   - What `STATUS` and `VOLUME` does the PVC have?\n   - Does the PVC use the existing PV and why or why not?\n4. What happens when a PV and PVC are created without specifying a `StorageClass`?\n   - repeat steps 1-3 after removing `storageClassName` from both YAML files\n   - what was the results?\n\n</div>\n\n<div id=\"soln-lab10-1\">\n\n<details>\n<summary>lab 10.1 solution</summary>\n\n```sh\nwget -q https://k8s.io/examples/pods/storage/pv-volume.yaml\nwget -q https://k8s.io/examples/pods/storage/pv-claim.yaml\nnano pv-volume.yaml\nnano pv-claim.yaml\n```\n\n```yaml\n# pv-volume.yaml\nkind: PersistentVolume\nspec:\n  storageClassName: manual\n  capacity:\n    storage: 3Gi\n# pv-claim.yaml\nkind: PersistentVolumeClaim\nspec:\n  storageClassName: manual\n  resources:\n    requests:\n      storage: 1Gi\n# etc\n```\n\n```sh\nkubectl get pv,pvc # STATUS=Bound, task-pv-volume uses task-pv-claim\n# when `storageClassName` is not specified, the StorageClass creates a new PV for the PVC\n```\n</details>\n\n</div>\n\n<div id=\"lab10-2\">\n\n### Lab 10.2. Configuring Pods storage with PVs and PVCs\n\nThe benefit of configuring Pods with PVCs is to decouple site-specific details.\n\nYou can follow the [official _configure a Pod to use a PersistentVolume for storage_ docs](https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/#create-a-persistentvolume) to complete this lab.\n\n1. Create a `/mnt/data/index.html` file on cluster host `minikube ssh` with some message, e.g. \"Hello, World!\"\n2. Create a PV with the following parameters, see `https://k8s.io/examples/pods/storage/pv-volume.yaml`\n   - uses `hostPath` storage\n   - allows multiple pods in the Node access the storage\n3. Create a Pod running a webserver to consume the storage, see `https://k8s.io/examples/pods/storage/pv-pod.yaml`\n   - uses PVC, see `https://k8s.io/examples/pods/storage/pv-claim.yaml`\n   - image is `httpd` and default documentroot is `/usr/local/apache2/htdocs` or `/var/www/html`\n4. Verify all resources created `pod,pv,pvc,storageclass`, and also review each detailed information\n   - review `STATUS` for PV and PVC\n   - did the PVC in [3] bind to the PV in [2], why or why not?\n5. Connect to the Pod via an interactive shell and confirm you can view the contents of cluster host file `curl localhost`\n6. Clean up all resources created\n\n</div>\n\n<div id=\"soln-lab10-2\">\n\n<details>\n  <summary>lab 10.2 solution</summary>\n\n```sh\n# host terminal\nminikube ssh\n# node terminal\nsudo mkdir /mnt/data\nsudo sh -c \"echo 'Hello from Kubernetes storage' > /mnt/data/index.html\"\ncat /mnt/data/index.html\nexit\n# host terminal\necho --- > lab10-2.yaml\nwget https://k8s.io/examples/pods/storage/pv-volume.yaml -O- >> lab10-2.yaml\necho --- >> lab10-2.yaml\nwget https://k8s.io/examples/pods/storage/pv-claim.yaml -O- >> lab10-2.yaml\necho --- >> lab10-2.yaml\nwget https://k8s.io/examples/pods/storage/pv-pod.yaml -O- >> lab10-2.yaml\necho --- >> lab10-2.yaml\nnano lab10-2.yaml # edit the final file accordingly\nkubectl apply -f lab10-2.yaml\nkubectl get pod,pv,pvc,storageclass\nkubectl describe pod,pv,pvc,storageclass | less\nkubectl exec -it task-pv-pod -- /bin/bash\nkubectl delete -f lab10-2.yaml\n```\n\n</details>\n\nFor further learning, see [mounting the same persistentVolume in two places](https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/#mounting-the-same-persistentvolume-in-two-places) and [access control](https://kubernetes.io/docs/tasks/configure-pod-container/configure-persistent-volume-storage/#access-control)\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n<div id=\"task10-1\">\n\n### Task - Persistent volumes\n\nIn the `kid` Namespace (create if required), create a Deployment `webapp` with two replicas, running the `nginx:1.22-alpine` image, that serves an `index.html` HTML document (see below) from the Cluster Node's `/mnt/data` directory. The HTML document should be made available via a Persistent Volume with 5Gi storage and no class name specified. The Deployment should use Persistent Volume claim with 2Gi storage.\n\n```html\n<!-- index.html -->\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n    <title>K8s Bootcamp (CKAD)</title>\n  </head>\n  <body>\n    <h1>Welcome to K8s Bootcamp!</h1>\n  </body>\n</html>\n```\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 11. Variables, ConfigMaps and Secrets\n\n### Variables\n\n[Variables](https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/) can be specified via the command-line when creating a _naked_ Pod with `kubectl run mypod --image=nginx --env=\"MY_VARIABLE=myvalue\"`. However _naked_ Pods are not recommended in live environments, so our main focus is creating variables for deployments.\n\nThe `kubectl create deploy` command does not currently support the `--env` option, thus the easiest way to add variables to a deployment is to use `kubectl set env deploy` command after the deployment is created.\n\n> Note that doing `kubectl set env deploy --dry-run=client` will only work if the deployment is already created \\\n> To generate a YAML file with variables via command-line, first `kubectl create deploy`, then `kubectl set env deploy --dry-run=client -o yaml` and edit to remove unnecessary metadata and statuses\n\n<div id=\"lab11-1\">\n\n### Lab 11.1. Deployment variables\n\n1. Create a `db` Deployment using `mysql` image\n2. Troubleshoot and fix any deployment issues to get a running `STATUS`\n3. View more details of the Deployment and note where env-var is specified\n4. Review the Deployment in YAML form and note how the env-var is specified\n5. Create a `db` Pod with an appropriate environment variable specified\n6. Confirm Pod running as expected\n7. View more details of the Pod and note where env-var is specified\n8. Review the Pod in YAML form and note how the env-var is specified\n9. Delete created resources\n\n</div>\n\n<div id=\"soln-lab11-1\">\n\n<details>\n<summary>lab11.1 solution</summary>\n  \n```sh\nkubectl create deploy db --image=mysql\nkubectl get po --watch # status=containercreating->error->crashloopbackoff->error->etc, ctrl+c to quit\nkubectl describe po $POD_NAME # not enough info to find issue, so check logs\nkubectl logs $POD_NAME|less # found issue, must specify one of `MYSQL_ROOT_PASSWORD|MYSQL_ALLOW_EMPTY_PASSWORD|MYSQL_RANDOM_ROOT_PASSWORD`\nkubectl set env deploy db MYSQL_ROOT_PASSWORD=mysecret\nkubectl get po # status=running\nkubectl describe deploy db # review deployment env-var format\nkubectl get deploy db -oyaml|less # review deployment env-var format\nkubectl run db --image=mysql --env=MYSQL_ROOT_PASSWORD=mypwd\nkubectl get po # status=running\nkubectl describe deploy db # review pod env-var format\nkubectl describe deploy,po db | grep -iEA15 \"pod template:|containers:\" | less # see `grep -h`\nkubectl get po db -oyaml|less # review pod env-var format\nkubectl delete deploy,po db\n```\n</details>\n\n> Note that you can [use Pod fields as env-vars](https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/#use-pod-fields-as-values-for-environment-variables), as well as [use container fields as env-vars](https://kubernetes.io/docs/tasks/inject-data-application/environment-variable-expose-pod-information/#use-container-fields-as-values-for-environment-variables)\n\n</div>\n\n### ConfigMaps\n\n[ConfigMaps](https://kubernetes.io/docs/concepts/configuration/configmap/) are used to decouple configuration data from application code. The configuration data may be variables, files or command-line args.\n\n- ConfigMaps should be created before creating an application that relies on it\n- A ConfigMap created from a directory includes all the files in that directory and the default behaviour is to use the filenames as keys\n\n```sh\n# create configmap `mycm` from file or directory, see `kubectl create cm -h`\nkubectl create configmap mycm --from-file=path/to/file/or/directory\n# create configmap from file with specified key\nkubectl create configmap mycm --from-file=key=path/to/file\n# create configmap from a varibales file (file contains KEY=VALUE on each line)\nkubectl create configmap mycm --from-env-file=path/to/file.env\n# create configmap from literal values\nkubectl create configmap mycm --from-literal=KEY1=value1 --from-literal=KEY2=value2\n# display details of configmap `mycm`\nkubectl describe cm mycm\nkubectl get cm mycm -o yaml\n# use configmap `mycm` in deployment `web`, see `kubectl set env -h`\nkubectl set env deploy web --from=configmap/mycm\n# use specific keys from configmap with mutliple env-vars, see `kubectl set env deploy -h`\nkubectl set env deploy web --keys=KEY1,KEY2 --from=configmap/mycm\n# remove env-var KEY1 from deployment web\nkubectl set env deploy web KEY1-\n```\n\n<div id=\"lab11-2\">\n\n### Lab 11.2. ConfigMaps as environment variables\n\n1. Create a `file.env` file with the following content:\n   ```sh\n   MYSQL_ROOT_PASSWORD=pwd\n   MYSQL_ALLOW_EMPTY_PASSWORD=true\n   ```\n2. Create a File ConfigMap `mycm-file` from the file using `--from-file` option\n3. Create an Env-Var ConfigMap `mycm-env` from the file using `--from-env-file` option\n4. Compare details of both ConfigMaps, what can you find?\n5. Compare the YAML form of both ConfigMaps, what can you find?\n6. Create manifest files for the two Deployments with `mysql` image using the ConfigMaps as env-vars:\n   - a Deployment called `web-file` for ConfigMap `mycm-file`\n   - a Deployment called `web-env` for ConfigMap `mycm-env`\n7. Review both manifest files to confirm if env-vars configured correctly, what did you find?\n   - any Deployment with correctly configured env-var?\n   - which ConfigMap was used for the working Deployment?\n   - Are you aware of the issue here?\n8. Create a Deployment with two env-vars from the working ConfigMap\n9. Connect a shell to a Pod from the Deployment and run `printenv` to confirm env-vars\n10. Create a Pod with env-vars from the working ConfigMap\n   - how will you set the env-vars for the Pod?\n11. Confirm Pod running or troubleshoot/fix any issues\n12. Connect a shell to the new Pod and run `printenv` to confirm env-vars\n13. Delete all created resources\n\n</div>\n\n<div id=\"soln-lab11-2\">\n\n<details>\n<summary>lab11.2 solution</summary>\n  \n```sh\necho \"MYSQL_ROOT_PASSWORD=mypwd\nMYSQL_ALLOW_EMPTY_PASSWORD=true\" > file.env\nkubectl create cm mycm-file --keys=MYSQL_ROOT_PASSWORD,MYSQL_ALLOW_EMPTY_PASSWORD --from-file=file.env\nkubectl create cm mycm-env --keys=MYSQL_ROOT_PASSWORD,MYSQL_ALLOW_EMPTY_PASSWORD --from-env-file=file.env\nkubectl describe cm mycm-file mycm-env |less # mycm-file has one filename key while mycm-env has two env-var keys\nkubectl get cm mycm-file mycm-env -oyaml|less\nkubectl create deploy web-file --image=mysql --dry-run=client -oyaml > webfile.yml\nkubectl apply -f webfile.yml # need an existing deployment to generate yaml for env-vars\nkubectl set env deploy web-file --keys=MYSQL_ROOT_PASSWORD,MYSQL_ALLOW_EMPTY_PASSWORD --from=configmap/mycm-file --dry-run=client -oyaml\nkubectl create deploy web-env --image=mysql --dry-run=client -oyaml | less # no output = keys not found in configmap\nkubectl create deploy web-env --image=mysql --dry-run=client -oyaml > webenv.yml\nkubectl apply -f webenv.yml # need an existing deployment to generate yaml for env-vars\nkubectl set env deploy web-env --keys=MYSQL_ROOT_PASSWORD,MYSQL_ALLOW_EMPTY_PASSWORD --from=configmap/mycm-env --dry-run=client -oyaml|less # output OK and two env-var keys set\n# copy the working env-var within the container spec to webenv.yml to avoid adding unnecessary fields\nkubectl apply -f webenv.yml\nkubectl get deploy,po # deployment web-env shows 1/1 READY, copy pod name\nkubectl exec -it $POD_NAME -- printenv # shows MYSQL_ROOT_PASSWORD,MYSQL_ALLOW_EMPTY_PASSWORD\nkubectl run mypod --image=mysql --dry-run=client -oyaml > pod.yml\nkubectl apply -f pod.yml # need existing pod to generate yaml for env-vars\nkubectl set env pod mypod --keys=MYSQL_ROOT_PASSWORD,MYSQL_ALLOW_EMPTY_PASSWORD --from=configmap/mycm-env --dry-run=client -oyaml|less\n# copy env-var from output container spec to pod.yml to avoid clutter\nkubectl delete -f pod.yml # naked pod cannot update env-var, only deployment\nkubectl apply -f pod.yml\nkubectl get all,cm # mypod in running state\nkubectl exec -it mypod -- printenv\nkubectl delete deploy,po,cm mycm-file mycm-env web-file web-env mypod\nrm file.env\n```\n</details>\n\n</div>\n\n<div id=\"lab11-3\">\n\n### Lab 11.3. Mounting ConfigMaps\n\nIn the previous lab, only the Env-Var ConfigMap worked for our use-case. In this lab we will see how we can use the File ConfigMap.\n\nYou may also follow the [offical _add ConfigMap data to a Volume_ docs](https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#add-configmap-data-to-a-volume)\n\n1. Create a `file.env` file with the following content:\n   ```sh\n   MYSQL_ROOT_PASSWORD=pwd\n   ```\n2. Create a File ConfigMap `mycm` from the file and verify resource details\n3. Create a manifest file for a Pod with the following:\n   - uses `mysql` image\n   - specify an env-var `MYSQL_ROOT_PASSWORD_FILE=/etc/config/file.env`, see the [_Docker Secrets section of MYSQL image_](https://hub.docker.com/_/mysql)\n   - mount ConfigMap `mycm` as a volume to `/etc/config/`, see [Populate a volume with ConfigMap](https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#populate-a-volume-with-data-stored-in-a-configmap)\n4. Create the Pod and verify all works and env-var set in container\n5. Create a `html/index.html` file with any content\n6. Create a ConfigMap from the file and verify resource details\n7. Create a `webserver` deployment with an appropriate image and mount the file to the DocumentRoot via ConfigMap\n   - option `nginx` DocumentRoot - /usr/share/nginx/html\n   - option `httpd` DocumentRoot - /usr/local/apache2/htdocs\n8. Connect a shell to the container and confirm your file is being served\n9. Delete created resources\n\n</div>\n\n<div id=\"soln-lab11-3\">\n\n<details>\n<summary>lab11.3 solution</summary>\n  \n```sh\necho \"MYSQL_ROOT_PASSWORD=pwd\" > file.env\nkubectl create cm mycm --from-file=file.env --dry-run=client -oyaml > lab11-3.yml\necho --- >> lab11-3.yml\nkubectl run mypod --image=mysql --env=MYSQL_ROOT_PASSWORD_FILE=/etc/config/file.env --dry-run=client -oyaml >> lab11-3.yml\nwget -qO- https://k8s.io/examples/pods/pod-configmap-volume.yaml | less # copy relevant details to lab11-3.yml\nnano lab11-3.yml\n```\n\n```yaml\nkind: Pod\nspec:\n  volumes:\n  - name: config-volume\n    configMap:\n      name: mycm\n  containers:\n  - name: mypod\n    volumeMounts:\n    - name: config-volume\n      mountPath: /etc/config\n# etc, rest same as generated\n```\n\n```sh\nkubectl apply -f lab11-3.yml\nkubectl get po # mypod in running state\nkubectl exec mypod -it -- printenv # shows MYSQL_ROOT_PASSWORD_FILE\n# part 2 of lab\nmkdir html\necho \"Welcome to Lab 11.3 - Part 2\" > html/index.html\nkubectl create cm webcm --from-file=html/index.html\necho --- >> 11-3.yml\nkubectl create deploy webserver --image=httpd --dry-run=client -oyaml > lab11-3.yml\nnano lab11-3.yml # copy yaml format above and fix indentation\n```\n\n```yaml\nkind: Deployment\nspec:\n  template:\n    spec:\n      volumes:\n      - name: config-volume\n        configMap:\n          name: webcm\n      containers:\n      - name: httpd\n        volumeMounts:\n        - name: config-volume\n          mountPath: /usr/local/apache2/htdocs\n```\n\n```sh\nkubectl get deploy,po # note pod name and running status\nkubectl exec $POD_NAME -it -- ls /usr/local/apache2/htdocs # index.html\nkubectl port-forward pod/$POD_NAME 3000:80 & # bind port 3000 in background\ncurl localhost:3000 # Welcome to Lab 11.3 - Part 2\nfg # bring job to fore-ground, then ctrl+c to terminate\nkubectl delete -f lab11-3.yml\n```\n</details>\n\n> Pay attention to the types of ConfigMaps, File vs Env-Var, and also note their YAML form differences\n\n</div>\n\n### Secrets\n\nSecrets are similar to ConfigMaps but specifically intended to hold sensitive data such as passwords, auth tokens, etc. By default, Kubernetes Secrets are not encrypted but base64 encoded.\n\nTo safely use Secrets, ensure to:\n\n1. [Enable Encryption at Rest](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/) for Secrets.\n2. [Enable or configure RBAC rules](https://kubernetes.io/docs/reference/access-authn-authz/authorization/) to\n   - restrict read/write\n   - limit access to create/replace secrets\n\n#### Uses of secrets\n\n- [as files](https://kubernetes.io/docs/concepts/configuration/secret/?ref=faun#using-secrets-as-files-from-a-pod) which may be mounted in Pods, e.g. accessing secret data in a Pod, TLS, etc\n  - consider using `defaultMode` when mounting secrets to set file permissions to `user:readonly - 0400`\n  - mounted secrets are automatically updated in the Pod when they change\n- [as container environment variable](https://kubernetes.io/docs/concepts/configuration/secret/?ref=faun#using-secrets-as-environment-variables) which may be managed with `kubectl set env`\n- [as `image registry credentials`](https://kubernetes.io/docs/concepts/configuration/secret/?ref=faun#using-imagepullsecrets), e.g. docker image registry creds\n\n> Secrets are basically encoded [ConfigMaps](#configmaps) and are both managed with `kubectl` in a similar way, see `kubectl create secret -h` for more details\n\n```sh\n# secret `myscrt` as file for tls keys, see `kubectl create secret tls -h`\nkubectl create secret tls myscrt --cert=path/to/file.crt --key=path/to/file.key\n# secret as file for ssh private key, see `kubectl create secret generic -h`\nkubectl create secret generic myscrt --from-file=ssh-private-key=path/to/id_rsa\n# secret as env-var for passwords, ADMIN_PWD=shush\nkubectl create secret generic myscrt --from-literal=ADMIN_PWD=shush\n# secrets as image registry creds, `docker-registry` works for other registry types\nkubectl create secret docker-registry myscrt --docker-username=dev --docker-password=shush --docker-email=dev@ckad.io --docker-server=localhost:3333\n# view details of the secret, shows base64 encoded value\nkubectl describe secret myscrt\nkubectl get secret myscrt -o yaml\n# view the base64 encoded contents of secret `myscrt`\nkubectl get secret myscrt -o jsonpath='{.data}'\n# for secret with nested data, '{\"game\":{\".config\":\"yI6eyJkb2NrZXIua\"}}'\nkubectl get secret myscrt -o jsonpath='{.data.game.\\.config}'\n# decode secret \".config\" in '{\"game\":{\".config\":\"yI6eyJkb2NrZXIua\"}}'\nkubectl get secret myscrt -o jsonpath='{.data.game.\\.config}' | base --decode\n# get a service account `mysa`\nkubectl get serviceaccount mysa -o yaml\n```\n\n> See the [Kubernetes JSONPath support docs](https://kubernetes.io/docs/reference/kubectl/jsonpath/) to learn more about using `jsonpath`\n\n<div id=\"lab11-4\">\n\n### Lab 11.4. Decoding secrets\n\nYou may follow the [official _managing secrets using kubectl_ docs](https://kubernetes.io/docs/tasks/configmap-secret/managing-secret-using-kubectl/)\n\n1. Review the CoreDNS Pod in the `kube-system` namespace and determine its `serviceAccountName`\n2. Review the ServiceAccount and determine the name of the `Secret` in use\n3. View the contents of the `Secret` and decode the value of its keys: `ca.crt` `namespace` and `token`.\n\n</div>\n\n<div id=\"soln-lab11-4\">\n\n<details>\n<summary>lab11.4 solution</summary>\n  \n```sh\nkubectl -nkube-system get po # shows name of coredns pod\nkubectl -nkube-system get po $COREDNS_POD_NAME -oyaml | grep serviceAccountName\nkubectl -nkube-system get sa $SERVICE_ACCOUNT_NAME -oyaml # shows secret name\nkubectl -nkube-system get secret $SECRET_NAME -ojsonpath=\"{.data}\" | less # shows the secret keys\nkubectl -nkube-system get secret $SECRET_NAME -ojsonpath=\"{.data.ca\\.crt}\" | base64 -d # decode ca.crt, BEGIN CERTIFICATE... long string\nkubectl -nkube-system get secret $SECRET_NAME -ojsonpath=\"{.data.namespace}\" | base64 -d # decode namespace, kube-system\nkubectl -nkube-system get secret $SECRET_NAME -ojsonpath=\"{.data.token}\" | base64 -d # decode token, ey... long string\n```\n</details>\n\n</div>\n\n<div id=\"lab11-5\">\n\n### Lab 11.5. Secrets as environment variables\n\nRepeat [lab 11.2](#lab112-configmaps-as-environment-variables) with secrets\n\n> See the [official _secrets as container env-vars_ docs](https://kubernetes.io/docs/concepts/configuration/secret/#use-case-as-container-environment-variables)\n\n</div>\n\n<div id=\"soln-lab11-5\">\n\n<details>\n<summary>lab11.5 solution</summary>\n  \n```sh\n# very similar to configmap solution, accepting pull-requests\n```\n</details>\n\n</div>\n\n<div id=\"lab11-6\">\n\n### Lab 11.6. Secrets as files\n\nRepeat [lab 11.3](#lab113-mounting-configmaps) with secrets.\n\n> See the [official _using secrets as files_ docs](https://kubernetes.io/docs/concepts/configuration/secret/#using-secrets-as-files-from-a-pod)\n\n</div>\n\n<div id=\"soln-lab11-6\">\n\n<details>\n<summary>lab11.6 solution</summary>\n  \n```sh\n# very similar to configmap solution, accepting pull-requests\n```\n</details>\n\n</div>\n\n<div id=\"lab11-7\">\n\n### Lab 11.7. Secrets as docker registry credentials\n\n1. Create a secret with the details of your docker credentials\n2. View more details of the resource created `kubectl describe`\n3. View details of the secret in `yaml`\n4. Decode the contents of the `.dockerconfigjson` key with `jsonpath`\n\n> See the [official _create an `imagePullSecret`_ docs](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#create-an-imagepullsecret)\n\n</div>\n\n<div id=\"soln-lab11-7\">\n\n<details>\n<summary>lab11.7 solution</summary>\n  \n```sh\n# one-line command can be found in `kubectl create secret -h` examples, accepting pull-requests\n```\n</details>\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n<div id=\"task11-1\">\n\n### Task - ConfigMap and Secrets\n\nThe latest Bootcamp cohort have requested a new database in the `rig` Namespace. This should be created as a single replica Deployment named `db` running the `mysql:8.0.22` image with container named `mysql`. The container should start with 128Mi memory and 0.25 CPU but should not exceed 512Mi memory and 1 CPU.\n\nThe Resource limit values should be available in the containers as env-vars `MY_CPU_LIMIT` and `MY_MEM_LIMIT` for the values of the cpu limit and memory limit respectively. The Pod IP address should also be available as env-var `MY_POD_IP` in the container.\n\nA Secret named `db-secret` should be created with variables `MYSQL_DATABASE=bootcamp` and `MYSQL_ROOT_PASSWORD=\"shhhh!\"` to be used by the Deployment as the database credentials. A ConfigMap named `db-config` should be used to load the `.env` file (see below) and provide environment variable `DEPLOY_ENVIRONMENT` to the Deployment.\n\n```sh\n# .env\nDEPLOY_CITY=manchester\nDEPLOY_REGION=north-west\nDEPLOY_ENVIRONMENT=staging\n```\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 12. Pod Lifecycle and Update Strategies\n\n### Pod states\n\nWhilst a Pod is running, the kubelet is able to restart containers to handle some kind of faults. Within a Pod, Kubernetes tracks different container states and determines what action to take to make the Pod healthy again. See [Pod lifecycle](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle) for more details.\n\nPod states can be viewed with `kubectl get pods` under `STATUS` column:\n\n- Pending - Pod starts here and waits to be scheduled, image download, etc\n- Running - at least one container running\n- Completed - all containers terminated successfully\n- Failed - all containers have terminated, at least one terminated in failure\n- CrashLoopbackOff - the Pod had failed and was restarted\n- Terminating - the Pod is being deleted\n- Unknown - pod state cannot be obtained, either node communication breakdown or other\n\n### Pod phase\n\nA Pod's `status` field is a [PodStatus](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/#podstatus-v1-core) object, which has a `phase` field that can have the values: `Pending | Running | Succeeded | Failed | Unknown`.\n\n### Container probes\n\nA [_probe_](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes) is a diagnostic performed periodically by the kubelet on a container, either by executing code within the container, or by network request. A probe will either return: `Success | Failure | Unknown`. There are four different ways to check a container using a probe:\n\n- `exec`: executes a specified command within the container, status code 0 means `Success`.\n- `grpc`: performs a remote procedure call using gRPC, this feature is in `alpha` stage (not for CKAD)\n- `httpGet`: performs HTTP GET request against the Pod's IP on a specified port and path, status code greater than or equal to 200 and less than 400 means `Success`.\n- `tcpSocket`: performs a TCP check against the Pod's IP on a specified port, port is open means `Success`, even if connection is closed immediately.\n\n#### Types of probe\n\nThe kubelet can optionally perform and react to three kinds of probes on running containers:\n\n- `livenessProbe`: indicates if container is running, On failure, the kubelet kills the container which triggers restart policy. Defaults to `Success` if not set. See [when to use liveness probe](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#when-should-you-use-a-liveness-probe).\n- `readinessProbe`: indicates if container is ready to respond to requests. On failure, the endpoints controller removes the Pod's IP address from the endpoints of all Services that match the Pod. Defaults to `Success` if not set. If set, starts as `Failure`. See [when to use readiness probe?](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#when-should-you-use-a-readiness-probe).\n- `startupProbe`: indicates if application within container is started. All other probes are disabled if a startup probe is set, until it succeeds. On failure, the kubelet kills the container which triggers restart policy. Defaults to `Success` if not set. See [when to use startup probe?](https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#when-should-you-use-a-startup-probe).\n\n> For more details, see [configuring Liveness, Readiness and Startup Probes](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)\n\n<div id=\"lab12-1\">\n\n### Lab 12.1. Liveness probe\n\nMany applications running for long periods of time eventually transition to broken states, and cannot recover except by being restarted. Kubernetes provides liveness probes to detect and remedy such situations. \\\nYou may follow the [official _define a liveness command_ tutorial](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-command) to complete this lab.\n\n```sh\n# get events\nkubectl get events\n# get events of a specific resource, pod, deployment, etc\nkubectl get events --field-selector=involvedObject.name=$RESOURCE_NAME\n# watch events for updates\nkubectl get events --watch\n```\n\n1. Using the official manifest file `pods/probe/exec-liveness.yaml` as base, create a Deployment `myapp` manifest file as follows:\n   - busybox image\n   - commandline arguments `mkdir /tmp/healthy; sleep 30; rm -d /tmp/healthy; sleep 60; mkdir /tmp/healthy; sleep 600;`\n   - a _liveness probe_ that checks for the presence of `/tmp/healthy` directory\n   - the Probe should be initiated 10secs after container starts\n   - the Probe should perform the checks every 10secs\n   > the container creates a directory `/tmp/healthy` on startup, deletes the directory 30secs later, recreates the directory 60secs later \\\n   > your goal is to monitor the Pod behaviour/statuses during these events, you can repeat this lab until you understand liveness probes\n2. Apply the manifest file to create the Deployment\n3. Review and monitor created Pod events for 3-5mins\n4. Delete created resources\n\n</div>\n\n<div id=\"soln-lab12-1\">\n\n<details>\n<summary>lab12.1 solution</summary>\n  \n```sh\nkubectl create deploy myapp --image=busybox --dry-run=client -oyaml -- /bin/sh -c \"touch /tmp/healthy; sleep 30; rm -f /tmp/healthy; sleep 60; touch /tmp/healthy; sleep 600;\" >lab12-1.yml\nwget -qO- https://k8s.io/examples/pods/probe/exec-liveness.yaml | less # copy the liveness probe section\nnano lab12-1.yml # paste, edit and fix indentation\n```\n\n```yaml\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n        livenessProbe:\n          exec:\n            command:\n            - ls # `cat` for file\n            - /tmp/healthy\n          initialDelaySeconds: 10\n          periodSeconds: 10\n```\n\n```sh\nkubectl apply -f lab12-1.yml\nkubectl get po # find pod name\nkubectl get events --field-selector=involvedObject.name=$POD_NAME --watch\nkubectl delete -f lab12-1.yml\n```\n</details>\n\n</div>\n\n### Configure probes\n\nProbes have a number of fields that you can use to more precisely control the behavior of liveness and readiness checks:\n\n- `initialDelaySeconds`: Seconds to wait after container starts before initiating liveness/readiness probes - default 0, minimum 0.\n- `periodSeconds`: How often (in seconds) to perform the probe - default 10, minimum 1.\n- `timeoutSeconds`: Seconds after which the probe times out - default 1, minimum 1.\n- `successThreshold`: Number of consecutive successes after a failure for the probe to be considered successful - default 1, minimum 1, must be 1 for liveness/startup Probes\n- `failureThreshold`: Number of consecutive retries on failure before giving up, liveness probe restarts the container after giving up, readiness probe marks the Pod as Unready - defaults 3, minimum 1.\n\n<div id=\"lab12-2\">\n\n### Lab 12.2. Readiness probe\n\nSometimes, applications are temporarily unable to serve traffic, for example, a third party service become unavailable, etc. In such cases, you don't want to kill the application, but you don't want to send it requests either. Kubernetes provides readiness probes to detect and mitigate these situations. Both _readiness probe_ and _liveness probe_ use similar configuration.\n\n1. Using the official manifest files `pods/probe/http-liveness.yaml` as base, create a Deployment `myapp` manifest file as follows:\n   - `nginx:1.22-alpine` image\n   - 2 replicas\n   - a _readiness probe_ that uses an HTTP GET request to check that the root endpoint `/` on port 80 returns a success status code\n   - the _readiness probe_ should be initiated 3secs after container starts, and perform the checks every 5secs\n   - a _liveness probe_ that uses an HTTP GET request to check that the root endpoint `/` on port 80 returns a success status code\n   - the _liveness probe_ should be initiated 8secs after the container is ready, and perform checks every 6secs\n2. Apply the manifest file to create the Deployment\n3. View more details of the Deployment and:\n   - confirm how Probe configuration appear, note values for `delay | timeout | period | success | failure`, how do you set these values?\n   - review Events for probe-related entries\n   - note that no Events generated when Probes successful\n4. List running Pods\n5. View more details of one of the Pods and:\n   - confirm both probes are configured\n   - review Events for probe-related entries\n6. Lets trigger a probe failure to confirm all works, edit the Deployment and change _readiness probe_ port to 8080\n7. Review more details of the Deployment and individual Pods and determine how Probe failures are recorded, on Deployment or Pod?\n8. Lets overload our Probe configuration, using official manifest `pods/probe/tcp-liveness-readiness.yaml` as example, edit the Deployment as follows:\n   - replace the _readiness probe_ with one that uses TCP socket to check that port 80 is open\n   - the _readiness probe_ should be initiated 5secs after container starts, and perform the checks every 10secs\n   - replace the _liveness probe_ with one that uses TCP socket to check that port 80 is open\n   - the _liveness probe_ should be initiated 15secs after the container starts, and perform checks every 10secs\n   - note that these changes trigger a rolling update - chainging parameters within `deploy.spec.template`\n9. Review more details of one of the Pod\n10. Delete created resources\n\n</div>\n\n<div id=\"soln-lab12-2\">\n\n<details>\n<summary>lab 12.2 solution</summary>\n\n```sh\nkubectl create deploy myapp --image=nginx:1.22-alpine --replicas=2 --dry-run=client -oyaml > lab12-2.yml\nwget -qO- https://k8s.io/examples/pods/probe/http-liveness.yaml | less # copy probe section\nnano lab12-2.yml # paste, fix indentation, edit correctly\n```\n\n```yaml\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n      - name: nginx\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 80 # change this to 8080 in later steps\n          initialDelaySeconds: 3\n          periodSeconds: 5\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 8\n          periodSeconds: 6\n# etc\n```\n\n```sh\nkubectl apply -f lab12-2.yml\nkubectl describe deploy myapp # review `Pod Template > Containers` and Events\nkubectl get po\nkubectl describe po $POD_NAME # review Containers and Events\nKUBE_EDITOR=nano kubectl edit deploy myapp # change port to 8080 and save\nkubectl describe deploy myapp # only shows rollout events\nkubectl get po # get new pod names\nkubectl describe po $NEW_POD_NAME # review Containers and Events\nKUBE_EDITOR=nano kubectl edit deploy myapp # replace probes config with below\n```\n\n```yaml\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n      - name: nginx\n        readinessProbe:\n          tcpSocket:\n            port: 80\n          initialDelaySeconds: 5\n          periodSeconds: 10\n        livenessProbe:\n          tcpSocket:\n            port: 80\n          initialDelaySeconds: 15\n          periodSeconds: 10\n# etc\n```\n\n```sh\nkubectl get po # get new pod names\nkubectl describe po $ANOTHER_NEW_POD_NAME # review Containers and Events, no news is good news\nkubectl delete -f lab12-2.yml\n```\n</details>\n\n</div>\n\n<div id=\"lab12-3\">\n\n### Lab 12.3. Protect slow starting containers with startup probe\n\nSometimes, you have to deal with legacy applications that might require additional startup time on first initialization. In such cases, it can be tricky to set up _liveness probe_ without compromising the fast response to deadlocks that motivated such a probe. The trick is to set up a _startup probe_ with the same command, HTTP or TCP check, with a `failureThreshold * periodSeconds` long enough to cover the worse case startup time.\n\n1. Using the official manifest files `pods/probe/http-liveness.yaml` as base, create a Deployment `myapp` manifest file as follows:\n   - `nginx:1.22-alpine` image\n   - 2 replicas\n   - a _readiness probe_ that uses an HTTP GET request to check that the root endpoint `/` on port 80 returns a success status code\n   - the _readiness probe_ should be initiated 3secs after container starts, and perform the checks every 5secs\n   - a _liveness probe_ that uses an HTTP GET request to check that the root endpoint `/` on port 80 returns a success status code\n   - the _liveness probe_ should be initiated 8secs after the container is ready, and perform checks every 6secs\n   - a _startup probe_ with the same command as the _liveness probe_ but checks every 5secs up to a maximum of 3mins\n2. Apply the manifest file to create the Deployment\n3. View more details of the Deployment and confirm how all Probe configuration appear\n4. List running Pods\n5. View more details of one of the Pods and confirm how Probe configuration appear\n6. Delete created resources\n\n</div>\n\n<div id=\"soln-lab12-3\">\n\n<details>\n<summary>lab 12.3 solution</summary>\n\n```sh\nkubectl create deploy myapp --image=nginx:1.22-alpine --replicas=2 --dry-run=client -oyaml > lab12-3.yml\nnano lab12-3.yml # add probes\n```\n\n```yaml\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n      - name: nginx\n        readinessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 3\n          periodSeconds: 5\n        livenessProbe:\n          httpGet:\n            path: /\n            port: 80\n          initialDelaySeconds: 8\n          periodSeconds: 6\n        startupProbe:\n          httpGet:\n            path: /\n            port: 80\n          periodSeconds: 5\n          failureThreshold: 36 # 5secs x 36 = 3mins\n# etc\n```\n\n```sh\nkubectl apply -f lab12-3.yml\nkubectl describe deploy myapp\nkubectl get po\nkubectl describe po $POD_NAME\nkubectl delete -f lab12-2.yml\n```\n</details>\n\n</div>\n\n<div id=\"lab12-4\">\n\n### Lab 12.4. Blue/Green deployments\n\n[Blue/green deployment](https://kubernetes.io/blog/2018/04/30/zero-downtime-deployment-kubernetes-jenkins/#blue-green-deployment) is a update-strategy used to accomplish zero-downtime deployments. The current version application is marked blue and the new version application is marked green. In Kubernetes, blue/green deployment can be easily implemented with Services.\n\n<details>\n  <summary>blue/green update strategy</summary>\n  \n  ![blue-green update strategy from https://engineering-skcc.github.io/performancetest/Cloud-%ED%99%98%EA%B2%BD-%EC%84%B1%EB%8A%A5%EB%B6%80%ED%95%98%ED%85%8C%EC%8A%A4%ED%8A%B8/](https://user-images.githubusercontent.com/17856665/185770858-83a088c2-4701-4fd6-943e-ebfb020aa498.gif)\n</details>\n\n1. Create a `blue` Deployment\n   - three replicas\n   - image `nginx:1.19-alpine`\n   - on the cluster Node, create an HTML document `/mnt/data/index.html` with any content\n   - mount the `index.html` file to the DocumentRoot as a _HostPath_ volume\n2. Expose `blue` Deployment on port 80 with Service name `bg-svc`\n3. Verify created resources and test access with `curl`\n4. Create a new `green` Deployment using [1] as base\n   - three replicas\n   - use a newer version of the image `nginx:1.21-alpine`\n   - on the cluster Node, create a new HTML document `/mnt/data2/index.html` with different content\n   - mount the `index.html` file to the DocumentRoot as a _HostPath_ volume\n5. Verify created resources and test access with `curl`\n6. Edit `bg-svc` Service _Selector_ as `app=green` to redirect traffic to `green` Deployment\n7. Confirm all working okay with `curl`\n8. Delete created resources\n\n</div>\n\n<div id=\"soln-lab12-4\">\n\n<details>\n<summary>lab 12.4 solution</summary>\n\n```sh\n# host terminal\nminikube ssh\n# node terminal\nsudo mkdir /mnt/data /mnt/data2\necho \"This is blue deployment\" | sudo tee /mnt/data/index.html\necho \"Green deployment\" | sudo tee /mnt/data2/index.html\nexit\n# host terminal\nkubectl create deploy blue --image=nginx:1.19-alpine --replicas=3 --dry-run=client -oyaml>12-4.yml\nnano 12-4.yml # add hostpath volume and pod template label\n```\n\n```yaml\nkind: Deployment\nspec:\n  template:\n    spec:\n      containers:\n        volumeMounts:\n        - mountPath: /usr/share/nginx/html\n          name: testvol\n      volumes:\n      - name: testvol\n        hostPath:\n          path: /mnt/data\n```\n\n```sh\nkubectl apply -f lab12-4.yml\nkubectl expose deploy blue --name=bg-svc --port=80\nkubectl get all,ep -owide\nkubectl run mypod --rm -it --image=nginx:alpine -- sh\n# container terminal\ncurl bg-svc # This is blue deployment\nexit\n# host terminal\ncp lab12-4.yml lab12-4b.yml\nnano lab12-4b.yml # change `blue -> green`, hostpath `/mnt/data2`, image `nginx:1.21-alpine\nkubectl apply -f lab12-4b.yml\nkubectl edit svc bg-svc # change selector `blue -> green`\nkubectl run mypod --rm -it --image=nginx:alpine -- sh\n# container terminal\ncurl bg-svc # Green deployment\nexit\nkubectl delete -f lab12-4.yml,lab12-4b.yml\n```\n\n</details>\n\n</div>\n\n<div id=\"lab12-5\">\n\n### Lab 12.5. Canary deployments\n\nCanary deployment is an update strategy where updates are deployed to a subset of users/servers (canary application) for testing prior to full deployment. This is a scenario where Labels are required to distinguish deployments by release or configuration.\n\n<details>\n  <summary>canary update strategy</summary>\n  \n  ![canary update strategy from https://life.wongnai.com/project-ceylon-iii-argorollouts-55ec70110f0a](https://user-images.githubusercontent.com/17856665/185770905-7c3901ec-f97a-4046-8411-7a722b0601a4.png)\n</details>\n\n1. Create a webserver application\n   - three replicas\n   - _Pod Template_ label `updateType=canary`\n   - use image` nginx:1.19-alpine`\n   - create an HTML document `index.html` with any content\n   - mount the `index.html` file to the DocumentRoot as a _ConfigMap_ volume\n2. Expose the Deployment on port 80 with Service name `canary-svc`\n3. Verify created resources and test access with `curl`\n4. Create a new application using [1] as base\n   - one replica\n   - _Pod Template_ label `updateType=canary`\n   - use a newer version of the image `nginx:1.22-alpine`\n   - create a new HTML document `index.html` with different content\n   - mount the `index.html` file to the DocumentRoot as a _ConfigMap_ volume\n5. Verify created resources and confirm the Service targets both webservers\n6. Run multiple `curl` requests to the IP in [2] and confirm access to both webservers\n7. Scale up the new webserver to three replicas and confirm all Pods running\n8. Scale down the old webserver to zero and confirm no Pods running\n9. Delete created resources\n\n> Scaling down to zero instead of deleting provides an easy option to revert changes when there are issues\n\n</div>\n\n<div id=\"soln-lab12-5\">\n\n<details>\n<summary>lab 12.5 solution</summary>\n\n```sh\n# host terminal\nkubectl create cm cm-web1 --from-literal=index.html=\"This is current version\"\nkubectl create deploy web1 --image=nginx:1.19-alpine --replicas=3 --dry-run=client -oyaml>12-5.yml\nnano 12-5.yml # add configmap volume and pod template label\n```\n\n```yaml\nkind: Deployment\nspec:\n  selector:\n    matchLabels:\n      app: web1\n      updateType: canary\n  template:\n    metadata:\n      labels:\n        app: web1\n        updateType: canary\n    spec:\n      containers:\n        volumeMounts:\n        - mountPath: /usr/share/nginx/html\n          name: testvol\n      volumes:\n      - name: testvol\n        configMap:\n          name: cm-web1\n```\n\n```sh\nkubectl apply -f lab12-5.yml\nkubectl expose deploy web1 --name=canary-svc --port=80\nkubectl get all,ep -owide\nkubectl run mypod --rm -it --image=nginx:alpine -- sh\n# container terminal\ncurl canary-svc # This is current version\nexit\n# host terminal\ncp lab12-5.yml lab12-5b.yml\nkubectl create cm cm-web2 --from-literal=index.html=\"New version\"\nnano lab12-5b.yml # change `web1 -> web2`, image `nginx:1.22-alpine`, replicas 1, add pod template label\nkubectl apply -f lab12-5b.yml\nkubectl get all,ep -owide # more ip addresses added to endpoint\nkubectl run mypod --rm -it --image=nginx:alpine -- sh\n# container terminal\nwatch \"curl canary-svc\" # both \"New version\" and \"This is current version\"\nkubectl scale deploy web2 --replicas=3\nkubectl get rs,po -owide\nkubectl scale deploy web1 --replicas=0\nkubectl get rs,po -owide\nkubectl delete -f lab12-5.yml,lab12-5b.yml\n```\n\n</details>\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n<div id=\"task12-1\">\n\n### Task - Probes\n\nYou have a legacy application `legacy` running in the `dam` Namespace that has a long startup time. Once startup is complete, the `/healthz:8080` endpoint returns 200 status. If this application is down at anytime or starting up, this endpoint will return a 500 status. The container port for this application often changes and will not always be `8080`.\n\nCreate a probe for the existing Deployment that checks the endpoint every 10secs, for a maximum of 5mins, to ensure that the application does not receive traffic until startup is complete. 20 secs after startup, a probe should continue to check, every 30secs, that the application is up and running, otherwise, the Pod should be killed and restarted anytime the application is down.\n\nYou do not need to test that the probes work, you only need to configure them. Another test engineer will perform all tests.\n\n- Command to setup environment:\n  ```sh\n  printf '\\nlab: lab environment setup in progress...\\n'; echo '{\"apiVersion\":\"v1\",\"kind\":\"List\",\"items\":[{\"apiVersion\":\"v1\",\"kind\":\"Namespace\",\"metadata\":{\"name\":\"dam\"}},{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"metadata\":{\"labels\":{\"app\":\"legacy\"},\"name\":\"legacy\",\"namespace\":\"dam\"},\"spec\":{\"replicas\":1,\"selector\":{\"matchLabels\":{\"app\":\"legacy\"}},\"template\":{\"metadata\":{\"labels\":{\"app\":\"legacy\"}},\"spec\":{\"containers\":[{\"args\":[\"/server\"],\"image\":\"registry.k8s.io/liveness\",\"name\":\"probes\",\"ports\":[{\"containerPort\":8080}]}],\"restartPolicy\":\"OnFailure\"}}}}]}' | kubectl apply -f - >/dev/null; echo 'lab: environment setup complete!'\n  ```\n- Command to destroy environment:\n  ```sh\n  kubectl delete ns dam\n  ```\n\n</div>\n\n<div id=\"task12-2\">\n\n### Task - Zero Downtime Updates\n\nIn the `hog` Namespace, you will find a Deployment named `high-app`, and a Service named `high-svc`. It is currently unknown if these resources are working together as expected. Make sure the Service is a _NodePort_ type exposed on TCP port 8080 and that you're able to reach the application via the _NodePort_.\n\nCreate a single replica Deployment named `high-appv2` based on `high-app.json` file running `nginx:1.18-alpine`.\n\n- Update `high-appv2` Deployment such that 20% of all traffic going to existing `high-svc` Service is routed to `high-appv2`. The total Pods between `high-app` and `high-appv2` should be 5.\n- Next, update `high-app` and `high-appv2` Deployments such that 100% of all traffic going to `high-svc` Service is routed to `high-appv2`. The total Pods between `high-app` and `high-appv2` should be 5.\n\nFinally, create a new Deployment named `high-appv3` based on `high-app.json` file running `nginx:1.20-alpine` with 5 replicas and _Pod Template_ label `box: high-app-new`.\n\n- Update `high-svc` Service such that 100% of all incoming traffic is routed to `high-appv3`.\n- Since `high-appv2` Deployment will no longer be used, perform a cleanup to delete all Pods related to `high-appv2` only keeping the Deployment and ReplicaSet.\n\n- Command to setup environment (also creates `high-app.json` file):\n  ```sh\n  printf '\\nlab: environment setup in progress...\\n'; echo '{\"apiVersion\":\"v1\",\"kind\":\"List\",\"items\":[{\"apiVersion\":\"v1\",\"kind\":\"Namespace\",\"metadata\":{\"name\":\"hog\"}},{\"apiVersion\":\"v1\",\"kind\":\"Service\",\"metadata\":{\"labels\":{\"kit\":\"high-app\"},\"name\":\"high-svc\",\"namespace\":\"hog\"},\"spec\":{\"ports\":[{\"port\":8080,\"protocol\":\"TCP\",\"targetPort\":8080}],\"selector\":{\"box\":\"high-svc-child\"}}}]}' | kubectl apply -f - >/dev/null; echo '{\"apiVersion\":\"apps/v1\",\"kind\":\"Deployment\",\"metadata\":{\"labels\":{\"kit\":\"high-app\"},\"name\":\"high-app\",\"namespace\":\"hog\"},\"spec\":{\"replicas\":4,\"selector\":{\"matchLabels\":{\"box\":\"high-app-child\"}},\"template\":{\"metadata\":{\"labels\":{\"box\":\"high-app-child\"}},\"spec\":{\"containers\":[{\"image\":\"nginx:1.15-alpine\",\"name\":\"nginx\",\"ports\":[{\"containerPort\":80}]}]}}}}' > high-app.json; kubectl apply -f high-app.json  >/dev/null; echo 'lab: environment setup complete!';\n  ```\n- Command to destroy environment:\n  ```sh\n  kubectl delete ns hog\n  ```\n\n<div style=\"page-break-after: always;\"></div>\n\n</div>\n\n## 13 K8s API\n\n### Understanding the API\n\nWhen you deploy Kubernetes, you get a cluster. See [Kubernetes cluster components](https://kubernetes.io/docs/concepts/overview/components) for more details.\n\n<details>\n<summary><i>kubectl</i> flow diagram</summary>\n\n<a href=\"https://medium.com/jorgeacetozi/kubernetes-master-components-etcd-api-server-controller-manager-and-scheduler-3a0179fc8186\">![kubectl flow diagram from medium.com](https://user-images.githubusercontent.com/17856665/188337178-851605cc-838e-4c0c-987c-c1f43a42abd0.png)</a>\n\n<ol>\n  <li>kubectl forwards command to the API Server</li>\n  <li>API Server validates the request and persists it to etcd</li>\n  <li>etcd notifies the API Server</li>\n  <li>API Server invokes the Scheduler</li>\n  <li>Scheduler will lookup eligible nodes to run the pod and return that to the API Server</li>\n  <li>API Server persists it to etcd</li>\n  <li>etcd notifies the API Server</li>\n  <li>API Server invokes the Kubelet in the corresponding node</li>\n  <li>Kubelet talks to the Docker daemon using the API over the Docker socket to create the container</li>\n  <li>Kubelet updates the pod status to the API Server (success or failure, failure invokes RestartPolicy)</li>\n  <li>API Server persists the new state in etcd</li>\n</ol>\n\n</details>\n\nUse `kubectl api-resources | less` for an overview of available API resources.\n\n- `APIVERSION`\n  - `v1` core kubernetes API group\n  - `apps/v1` first extension to the core group\n  - during deprecation/transition, multiple versions of the same resource may be available, e.g. `policy/v1` and `policy/v1beta1`\n- `NAMESPACED` controls visibility\n\n> The Kubernetes **release cycle is 3 months** and deprecated features are supported for a minimum of 2 release cycles (6 months).\n> Respond to deprecation message swiftly, you may use **`kubectl api-versions`** to view a short list of API versions and **`kubectl explain --recursive`** to get more details on affected resources. \\\n> The current API docs at time of writing is `https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.25/`\n\n#### kube-apiserver\n\nThe [Kubernetes API server `kube-apiserver`](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/) is the interface to access all Kubernetes features, which include pods, services, replicationcontrollers, and others.\n\nFrom within a Pod, the API server is accessible via a Service named `kubernetes` in the `default` namespace. Therefore, Pods can use the **`kubernetes.default.svc`** hostname to query the API server.\n\n#### kube-proxy\n\nIn our minikube lab so far, we have been working with direct access to a cluster node, which removes the need for `kube-proxy`. When using the Kubernetes CLI `kubectl`, it uses stored TLS certificates in `~/.kube/config` to make secured requests to the `kube-apiserver`.\n\nHowever, direct access is not always possible with K8s in the cloud. The [Kubernetes network proxy `kube-proxy`](https://kubernetes.io/docs/reference/command-line-tools-reference/kube-proxy/) runs on each node and make it possible to access `kube-apiserver` securely by other applications like `curl` or programmatically.\n\n> See the [official _so many proxies_ docs](https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#so-many-proxies) for the different proxies you may encounter when using Kubernetes.\n\n```sh\n# view a more verbose pod detais\nkubectl --v=10 get pods\n# start kube-proxy\nkubectl proxy --port=PORT\n# explore the k8s API with curl\ncurl localhost:PORT/api\n# get k8s version with curl\ncurl localhost:PORT/version\n# list pods with curl\ncurl localhost:PORT/api/v1/namespaces/default/pods\n# get specific pod with curl\ncurl localhost:PORT/api/v1/namespaces/default/pods/$POD_NAME\n# delete specific pod with curl\ncurl -XDELETE localhost:PORT/api/v1/namespaces/default/pods/$POD_NAME\n```\n\n### Directly accessing the REST API\n\nTwo things are required to access a cluster - the **location** of the cluster and the **credentials** to access it. Thus far, we have used `kubectl` to access the API by running `kubectl` commands. The location and credentials that `kubectl` uses were automatically configured by Minikube during our [Minikube environment setup](#4-kubernetes-lab-environment).\n\nRun `kubectl config view` to see the location and credentials configured for `kubectl`.\n\n<details>\n  <summary><code>kubectl config view</code></summary>\n  \n  ![image](https://user-images.githubusercontent.com/17856665/184899506-47878132-dc9b-4a6a-8491-080fe56c6261.png)\n</details>\n\n<div id=\"lab13-1\">\n\n### Lab 13.1. Using kubectl proxy to access the API\n\nRather than run `kubectl` commands directly, we can use `kubectl` as a reverse proxy to provide the location and authenticate requests. See [access the API using kubectl proxy](https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#using-kubectl-proxy) for more details.\n\nYou may follow the [official _accessing the rest api_ docs](https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#directly-accessing-the-rest-api)\n\n1. Expose the API with `kube-proxy`\n2. Confirm k8s version information with `curl`\n3. Explore the k8s API with curl\n4. Create a deployment\n5. List the pods created with `curl`\n6. Get details of a specific pod with `curl`\n7. Delete the pod with `curl`\n8. Confirm pod deletion\n\n</div>\n\n### Checking API access\n\n`kubectl` provides the `auth can-i` subcommand for [quickly querying the API authorization layer](https://kubernetes.io/docs/reference/access-authn-authz/authorization/#checking-api-access).\n\n```sh\n# check if deployments can be created in a namespace\nkubectl auth can-i create deployments --namespace dev\n# check if pods can be listed\nkubectl auth can-i get pods\n# check if a specific user can list secrets\nkubectl auth can-i list secrets --namespace dev --as dave\n```\n\n### Service Accounts\n\nJust as user accounts identifies humans, a service account identifies processes running in a Pod.\n\n- Service Accounts are the recommended way to authenticate to the API server within the k8s cluster\n- A Pod created without specifying a ServiceAccount is automatically assigned the `default` ServiceAccount\n- When a new ServiceAccount is created, a Secret is auto-created to hold the credentials required to access the API server\n- The ServiceAccount credentials of a Pod are automounted with the Secret in each container within the Pod at:\n  - token `/var/run/secrets/kubernetes.io/serviceaccount/token`\n  - certificate (if available) `/var/run/secrets/kubernetes.io/serviceaccount/ca.crt`\n  - default namespace `/var/run/secrets/kubernetes.io/serviceaccount/namespace`\n- You can opt out of automounting API credentials for a ServiceAccount by setting `automountServiceAccountToken: false` on the ServiceAccount. Note that the pod spec takes precedence over the service account if both specify a `automountServiceAccountToken` value\n\n<div id=\"lab13-2\">\n\n### Lab 13.2. Accessing the API without kubectl proxy\n\nThis requires using the token of the default ServiceAccount. The token can be read directly (see [lab 11.4 - decoding secrets](#lab-114-decoding-secrets)), but the recommended way to get the token is via the [TokenRequest API](https://kubernetes.io/docs/reference/kubernetes-api/authentication-resources/token-request-v1/).\n\nYou may follow the [official _access the API **without** kubectl proxy_ docs](https://kubernetes.io/docs/tasks/access-application-cluster/access-cluster/#without-kubectl-proxy).\n\n1. Request the ServiceAccount token by YAML. You can also request by [`kubectl create token $SERVICE_ACCOUNT_NAME`](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#-em-token-em-) on Kubernetes v1.24+.\n2. Wait for the token controller to populate the Secret with a token\n3. Use `curl` to access the API with the generated token as credentials\n\n</div>\n\n<div id=\"soln-lab13-2\">\n\n<details>\n  <summary>lab 13.2 solution</summary>\n\n```sh\n# request token\nkubectl apply -f - <<EOF\napiVersion: v1\nkind: Secret\nmetadata:\n  name: default-token\n  annotations:\n    kubernetes.io/service-account.name: default\ntype: kubernetes.io/service-account-token\nEOF\n# confirm token generated (optional)\nkubectl get secret default-token -o yaml\n# use token\nAPISERVER=$(kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}')\nTOKEN=$(kubectl get secret default-token -o jsonpath='{.data.token}' | base64 --decode)\ncurl $APISERVER/api --header \"Authorization: Bearer $TOKEN\" --insecure\n```\n\n</details>\n\n> Using `curl` with the `--insecure` option [skips TLS certificate validation](https://curl.se/docs/sslcerts.html)\n\n</div>\n\n<div id=\"lab13-3\">\n\n### Lab 13.3. Accessing the API from inside a Pod\n\nYou may follow the [official _access the API from within a Pod_ docs](https://kubernetes.io/docs/tasks/run-application/access-api-from-pod/#without-using-a-proxy).\n\n> From within a Pod, the Kubernetes API is accessible via the `kubernetes.default.svc` hostname\n\n1. Connect an interactive shell to a container in a running Pod (create one or use existing)\n2. Use `curl` to access the API at `kubernetes.default.svc/api` with the automounted ServiceAccount credentials (`token` and `certificate`)\n3. Can you access the Pods list at `kubernetes.default.svc/api/v1/namespaces/default/pods`?\n\n</div>\n\n<div id=\"soln-lab13-3\">\n\n<details>\n  <summary>lab 13.3 solution</summary>\n\n```sh\n# connect an interactive shell to a container within the Pod\nkubectl exec -it $POD_NAME -- /bin/sh\n# use token stored within container to access API\nSA=/var/run/secrets/kubernetes.io/serviceaccount\nCERT_FILE=$($SA/ca.crt)\nTOKEN=$(cat $SA/token)\ncurl --cacert $CERT_FILE --header \"Authorization: Bearer $TOKEN\" https://kubernetes.default.svc/api\n```\n\n</details>\n\n</div>\n\n### RBAC\n\nRole-based access control (RBAC) is a method of regulating access to computer or network resources based on the roles of individual users within your organization. RBAC authorization uses the `rbac.authorization.k8s.io` [API group](https://kubernetes.io/docs/concepts/overview/kubernetes-api/#api-groups-and-versioning) for dynamic policy configuration through the Kubernetes API. RBAC is beyond [CKAD](https://www.cncf.io/certification/ckad/), however, a basic understanding of RBAC can help understand ServiceAccount permissions.\n\nThe RBAC API declares four kinds of Kubernetes object: [Role, ClusterRole](https://kubernetes.io/docs/reference/access-authn-authz/rbac/#role-and-clusterrole), [RoleBinding and ClusterRoleBinding](https://kubernetes.io/docs/reference/access-authn-authz/rbac/#rolebinding-and-clusterrolebinding).\n\n- Role is a namespaced resource; when you create a Role, you have to specify its namespace\n- ClusterRole, by contrast, is a non-namespaced resource\n- RoleBinding grants the permissions defined in a Role/ClusterRole to a user or set of users within a specific namespace\n- ClusterRoleBinding grants permissions that access cluster-wide.\n\n### ServiceAccount permissions\n\nThe Default RBAC policies grant scoped permissions to control-plane components, nodes, and controllers, but grant no permissions to service accounts outside the kube-system namespace (beyond discovery permissions given to all authenticated users).\n\nThere are [different ServiceAccount permission approaches](https://kubernetes.io/docs/reference/access-authn-authz/rbac/#service-account-permissions), but we will only go over two:\n\n- Grant a role to an application-specific service account (**best practice**)\n  - requires the `serviceAccountName` specified in the pod spec, and for the ServiceAccount to have been created\n- Grant a role to the `default` service account in a namespace\n  - permissions given to the `default` service account are available to any pod in the namespace that does not specify a `serviceAccountName`. **This is a security concern in live environments without RBAC**\n\n```sh\n# create a service account imperatively\nkubectl create service account $SERVICE_ACCOUNT_NAME\n# assign service account to a deployment\nkubectl set serviceaccount deploy $DEPLOYMENT_NAME $SERVICE_ACCOUNT_NAME\n# create a role that allows users to perform get, watch and list on pods, see `kubectl create role -h`\nkubectl create role $ROLE_NAME --verb=get --verb=list --verb=watch --resource=pods\n# grant permissions in a Role to a user within a namespace\nkubectl create rolebinding $ROLE_BINDING_NAME --role=$ROLE_NAME --user=$USER --namespace=$NAMESPACE\n# grant permissions in a ClusterRole to a user within a namespace\nkubectl create rolebinding $ROLE_BINDING_NAME --clusterrole=$CLUSTERROLE_NAME --user=$USER --namespace=$NAMESPACE\n# grant permissions in a ClusterRole to a user across the entire cluster\nkubectl create clusterrolebinding $CLUSTERROLE_BINDING_NAME --clusterrole=$CLUSTERROLE_NAME --user=$USER\n# grant permissions in a ClusterRole to an application-specific service account within a namespace\nkubectl create rolebinding $ROLE_BINDING_NAME --clusterrole=$CLUSTERROLE_NAME --serviceaccount=$NAMESPACE:$SERVICE_ACCOUNT_NAME --namespace=$NAMESPACE\n# grant permissions in a ClusterRole to the \"default\" service account within a namespace\nkubectl create rolebinding $ROLE_BINDING_NAME --clusterrole=$CLUSTERROLE_NAME --serviceaccount=$NAMESPACE:default --namespace=$NAMESPACE\n```\n\n<div id=\"lab13-4\">\n\n### Lab 13.4. Exploring RBAC\n\nIn [lab 13.3](#lab-123-accessing-the-api-from-a-pod-without-kubectl) we were unable to access the PodList API at `kubernetes.default.svc/api/v1/namespaces/default/pods`. Lets apply the required permissions to make this work.\n\n1. Create a ServiceAccount and verify\n2. Create a Role with permissions to list pods and verify\n3. Create a RoleBinding that grants the Role permissions to the ServiceAccount, within the `default` namespace, and verify\n4. Create a \"naked\" Pod bound to the ServiceAccount\n5. Connect an interactive shell to the Pod and use `curl` to PodList API\n6. Can you access the API to get a specific Pod like the one you're running? Hint: Role permissions\n7. Can you use a deployment instead of a \"naked\" Pod?\n\n</div>\n\n<details>\n  <summary>lab 13.4 solution</summary>\n\n```sh\n# create service account yaml\nkubectl create serviceaccount test-sa --dry-run=client -o yaml > lab13-4.yaml\necho --- >> lab13-4.yaml\n# create role yaml\nkubectl create role test-role --resource=pods --verb=list --dry-run=client -o yaml >> lab13-4.yaml\necho --- >> lab13-4.yaml\n# create rolebinding yaml\nkubectl create rolebinding test-rolebinding --role=test-role --serviceaccount=default:test-sa --namespace=default --dry-run=client -o yaml >> lab13-4.yaml\necho --- >> lab13-4.yaml\n# create configmap yaml\nkubectl create configmap test-cm --from-literal=\"SA=/var/run/secrets/kubernetes.io/serviceaccount\" --dry-run=client -o yaml >> lab13-4.yaml\necho --- >> lab13-4.yaml\n# create pod yaml\nkubectl run test-pod --image=nginx --dry-run=client -o yaml >> lab13-4.yaml\n# review & edit yaml to add configmap and service account in pod spec, see `https://k8s.io/examples/pods/pod-single-configmap-env-variable.yaml`\nnano lab13-4.yaml\n# create all resources\nkubectl apply -f lab13-4.yaml\n# verify resources\nkubectl get sa test-sa\nkubectl describe sa test-sa | less\nkubectl get role test-role\nkubectl describe role test-role | less\nkubectl get rolebinding test-rolebinding\nkubectl describe rolebinding test-rolebinding | less\nkubectl get configmap test-cm\nkubectl describe configmap test-cm | less\nkubectl get pod test-pod\nkubectl describe pod test-pod | less\n# access k8s API from within the pod\nkubectl exec -it test-pod -- bash\nTOKEN=$(cat $SA/token)\nHEADER=\"Authorization: Bearer $TOKEN\"\ncurl -H $HEADER https://kubernetes.default.svc/api --insecure\ncurl -H $HEADER https://kubernetes.default.svc/api/v1/namespaces/default/pods --insecure\ncurl -H $HEADER https://kubernetes.default.svc/api/v1/namespaces/default/pods/$POD_NAME --insecure\ncurl -H $HEADER https://kubernetes.default.svc/api/v1/namespaces/default/deployments --insecure\nexit\n# clean up\nkubectl delete -f lab13-4.yaml\n```\n\n</details>\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n<div id=\"task13-1\">\n\n### Task - Service account\n\nComing soon, accepting pull-requests\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 14. DevOps\n\n### Helm\n\nThere are thousands of people and companies packaging their applications for deployment on Kubernetes. A [best practice](https://kubernetes.io/blog/2016/10/helm-charts-making-it-simple-to-package-and-deploy-apps-on-kubernetes/) is to package these applications as [Helm Charts](https://helm.sh/docs/topics/charts/).\n\n[Helm](https://helm.sh/) is a package manager you can install, like [winget](https://docs.microsoft.com/en-us/windows/package-manager/winget/), npm, yum and apt, and Charts are packages stored locally or on remote Helm repositories, like msi, debs and rpms.\n\n```sh\n# helm installation steps\nVER=$(curl -s https://api.github.com/repos/helm/helm/releases/latest | grep tag_name | cut -d '\"' -f 4 | sed 's/v//g')\nwget https://get.helm.sh/helm-v$VER-linux-amd64.tar.gz # macOS replace with `darwin-amd64`\ntar xvf helm-v3.9.3-linux-amd64.tar.gz\nsudo install linux-amd64/helm /usr/local/bin\nrm helm-v$VER-linux-amd64.tar.gz\nhelm version\n```\n\n### ArtifactHUB\n\n[ArtifactHUB](https://artifacthub.io/) is a Helm Charts registry, like [docker hub](https://hub.docker.com/) or the [npm registry](https://www.npmjs.com/), used to find, install and publish Charts.\n\n```sh\n# add a helm repo\nhelm repo add $RELEASE_NAME $RELEASE_URL\n# install helm chart from an added repo\nhelm install $RELEASE_NAME $RELEASE_NAME/$CHART_NAME\n# list helm repo\nhelm repo list\n# search for charts in a repo\nhelm search repo $RELEASE_NAME\n# update helm repos (running update command after adding new repo is good practice)\nhelm repo update\n# list currently installed charts\nhelm list\n# show details of a chart\nhelm show chart $RELEASE_NAME/$CHART_NAME\nhelm show all $RELEASE_NAME/$CHART_NAME\n# view status of a chart\nhelm status $CHART_NAME\n# delete currently installed charts\nhelm delete\n# uninstall helm chart\nhelm uninstall $RELEASE_NAME\n```\n\n<div id=\"lab14-1\">\n\n### Lab 14.1. Explore Helm Charts\n\n1. [Install Helm](https://github.com/helm/helm#install)\n2. List installed Helm Charts\n3. List installed Helm repos\n4. Find and install a Chart from [ArtifactHUB](https://artifacthub.io/)\n5. View resources created in your cluster by the Helm Chart\n6. Update Helm repo\n7. List installed Helm Charts\n8. List installed Helm repos\n9. View details of installed Chart\n10. View status of installed Chart\n11. Search for available Charts in added Helm repo\n\n</div>\n\n### Helm templates\n\nHelm Charts come with preset configuration stored in a YAML file, some of which may not be of use to you. One powerful feature of Helm is the option to customise the base chart configuration before installation.\n\n```sh\n# view chart preset configuration\nhelm show values $RELEASE_NAME/$CHART_NAME | less\n# download a copy of a chart configuation file\nhelm pull $RELEASE_NAME/$CHART_NAME\n# verify a chart template\nhelm template --debug /path/to/template/directory\n# install chart from template\nhelm install -f /path/to/values.yaml {$NAME|--generate-name} /path/to/template/directory\n\n# working with {tar,tar.gz,tgz,etc} archives, see `tar --help`\n# extract tar file to current directory, `-x|--extract`, `-v|--verbose, `-f|--file`\ntar -xvf file.tgz\n# extract tar file to specified directory, `-C|--directory`\ntar -xvf file.tgz -C /path/to/directory\n# list contents of a tar file, `-t|--list`\ntar -tvf file.tar\n```\n\n<div id=\"lab14-2\">\n\n### Lab 14.2. Customising Helm Charts\n\n1. Download a Chart template and extract the content to a specified directory\n2. Edit the template and change any value\n3. Verify the edited template\n4. Install the edited template\n5. View resources created by the Helm Chart\n6. List installed Charts\n7. List installed Helm repos\n\n</div>\n\n### Kustomize\n\n[Kustomize](https://github.com/kubernetes-sigs/kustomize) is a Kubernetes standalone tool to customize Kubernetes resources through a [kustomization.yaml file](https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#kustomization).\n\n> Kustomize is not currently part of the [CKAD curriculum](https://github.com/cncf/curriculum) but good to know for general DevOps practice.\n\n[Kustomize can manage configuration files in three ways](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/#overview-of-kustomize):\n\n- generating resources from other sources, e.g. generate with [`secretGenerator`](https://kubernetes.io/docs/tasks/configmap-secret/managing-secret-using-kustomize/#create-the-kustomization-file) and [`configMapGenerator`](https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#create-a-configmap-from-generator)\n   <details>\n     <summary>configmap generator example</summary>\n\n  ```sh\n  cat <<EOF >./kustomization.yaml\n  configMapGenerator:\n  - name: example-configmap-2\n    literals:\n    - FOO=Bar\n  EOF\n  ```\n\n   </details>\n\n- composing and customising collections of resources, e.g. composing two resources together or adding a patch, see example:\n   <details>\n     <summary>composing & customising example</summary>\n\n  ```sh\n  cat <<EOF >./kustomization.yaml\n  resources:\n  - deployment.yaml # uses 1 replica\n  - service.yaml\n  patchesStrategicMerge:\n  - patch.yaml # change Deployment to 3 replicas\n  EOF\n  ```\n\n   </details>\n\n- setting cross-cutting fields for resources, e.g. setting same namespaces, name prefix/suffix, labels or annotations to all resources\n   <details>\n     <summary>cross-cutting fields example</summary>\n\n  ```sh\n  cat <<EOF >./kustomization.yaml\n  namespace: my-namespace\n  namePrefix: dev-\n  nameSuffix: \"-001\"\n  commonLabels:\n    app: bingo\n  commonAnnotations:\n    oncallPager: 800-555-1212\n  resources:\n  - deployment.yaml\n  - service.yaml\n  EOF\n  ```\n\n   </details>\n\n```sh\n# create resources from a kustomization file\nkubectl apply -k /path/to/directory/containing/kustomization.yaml\n# view resources found in a directory containing a kustomization file\nkubectl kustomize /path/to/directory/containing/kustomization.yaml\n# view resources found in a directory containing a kustomization file\nkubectl kustomize /path/to/directory/containing/kustomization.yaml\n```\n\nWe can take advantage of Kustomization's \"composing and customising\" feature to create deployment pipelines by using a directory layout where multiple [_overlay_](https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#overlay) kustomizations ([variants](https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#variant)) refer to a [_base_](https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#base) kustomization:\n\n<details>\n  <summary>pipeline layout example</summary>\n\n```sh\n├── base\n│   ├── deployment.yaml\n│   ├── kustomization.yaml\n│   └── service.yaml\n└── overlays\n    ├── dev\n    │   ├── kustomization.yaml # `bases: ['../../base']`, `namePrefix: dev-`\n    │   └── patch.yaml\n    ├── prod\n    │   ├── kustomization.yaml # `bases: ['../../base']`, `namePrefix: prod-`\n    │   └── patch.yaml\n    └── staging\n        ├── kustomization.yaml # `bases: ['../../base']`, `namePrefix: staging-`\n        └── patch.yaml\n```\n\n</details>\n\n<div id=\"lab14-3\">\n\n### Lab 14.3. Kustomize resources\n\n1. Create a `service.yaml` resource file for a service\n2. Create a `deployment.yaml` resource file for an app using the service\n3. Create a `kustomization.yaml` file with name prefix/suffix and common labels for both resource files\n4. Apply the Kustomization file to create the resources\n5. Review resources created and confirm that the prefix/suffix and labels are applied\n\n</div>\n\n### Custom Resource Definition (CRD)\n\nA _Resource_ is an endpoint in the Kubernetes API that stores a collection of [API objects](https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/) of a certain kind; for example, the Pods resource contains a collection of Pod objects.\n\nA [_Custom Resource_](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/) is an extension of the Kubernetes API that is not necessarily available in a default Kubernetes installation. Many core Kubernetes functions are now built using custom resources, making Kubernetes more modular.\n\nAlthough, we only focus on one, there are [two ways to add custom resources](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/#comparing-ease-of-use) to your cluster:\n\n- [CRDs](https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/#create-a-customresourcedefinition) allows user-defined resources to be added to the cluster. They are simple and can be created without any programming. In reality, [Operators](#operator-pattern) are preferred to CRDs.\n- [API Aggregation](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/apiserver-aggregation/) requires programming, but allows more control over API behaviors like how data is stored and conversion between API versions.\n\n```sh\n# CRD example \"resourcedefinition.yaml\"\napiVersion: apiextensions.k8s.io/v1\nkind: CustomResourceDefinition\nmetadata:\n  name: crontabs.stable.example.com # must match `<plural>.<group>` spec fields below\nspec:\n  group: stable.example.com # REST API: /apis/<group>/<version>\n  versions: # list of supported versions\n    - name: v1\n      served: true # enabled/disabled this version, controls deprecations\n      storage: true # one and only one version must be storage version.\n      schema:\n        openAPIV3Schema:\n          type: object\n          properties:\n            spec:\n              type: object\n              properties:\n                cronSpec:\n                  type: string\n                image:\n                  type: string\n                replicas:\n                  type: integer\n  scope: Namespaced # or Cluster\n  names:\n    plural: crontabs # REST API: /apis/<group>/<version>/<plural>\n    singular: crontab # used for display and as alias on CLI\n    kind: CronTab # CamelCased singular type for resource manifests.\n    shortNames:\n    - ct # allow `crontab|ct` to match this resource on CLI\n```\n\n<div id=\"lab14-4\">\n\n### Lab 14.4. Custom objects\n\nYou can follow the [official CRD tutorial](https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/).\n\n1. Create a custom resource from the snippet above\n2. Confirm a new API resource added\n3. Create a custom object of the custom resource\n   ```sh\n   apiVersion: \"stable.example.com/v1\"\n   kind: CronTab\n   metadata:\n     name: my-new-cron-object\n   spec:\n     cronSpec: \"* * * * */5\"\n     image: my-awesome-cron-image\n   ```\n4. Review all resources created and confirm the `shortName` works\n5. Directly access the Kubernetes REST API and confirm endpoints for:\n   - group `/apis/<group>`\n   - version `/apis/<group>/<version>`\n   - plural `/apis/<group>/<version>/<plural>`\n6. Clean up by deleting with the manifest files\n\n</div>\n\n### Operator pattern\n\n[Operators](https://kubernetes.io/docs/concepts/extend-kubernetes/operator/) are software extensions to Kubernetes that make use of custom resources to manage applications and their components. The operator pattern captures how you can write code to automate a task beyond what Kubernetes itself provides.\n\nKubernetes' operator pattern concept lets you extend the cluster's behaviour without modifying the code of Kubernetes itself by linking [controllers](https://kubernetes.io/docs/concepts/architecture/controller/) (a non-terminating loop, or control loop, that regulates the cluster to a desired state) to one or more custom resources. Operators are clients of the Kubernetes API that act as controllers for a Custom Resource.\n\nAlthough, you can write your own operator, majority prefer to find ready-made operators on community websites like [OperatorHub.io](https://operatorhub.io/). Many Kubernetes solutions are provided as operators like [Prometheus](https://prometheus.io/) or Tigera (calico).\n\n> This lab requires the Calico plugin. You will need to delete and start a new cluster if your current one doesn't support Calico\n\n<div id=\"lab14-5\">\n\n### Lab 14.5. Operators\n\nSee the [official Calico install steps](https://projectcalico.docs.tigera.io/getting-started/kubernetes/minikube).\n\n```sh\n# 1. start a new cluster with network `192.168.0.0/16` or `10.10.0.0/16` whichever subnet is free in your network\nminikube start --kubernetes-version=1.23.9 --network-plugin=cni --extra-config=kubeadm.pod-network-cidr=10.10.0.0/16\n# 2. install tigera calico operator\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.0/manifests/tigera-operator.yaml\n# 3. install custom resource definitions\nkubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.0/manifests/custom-resources.yaml\n# 4. view an installation resource\nkubectl get installation -o yaml | less\n# 5. verify calico installation\nwatch kubectl get pods -l k8s-app=calico-node -A\n# you can use wget to view a file without saving\nwget -O- https://url/to/file | less\nwget -qO- https://url/to/file | less # quiet mode\n```\n\n1. Start a Minikube cluster with the `cni` network plugin and a suitable subnet\n2. List existing namespaces\n3. Install the Tigera Calico operator\n4. Confirm resources added:\n   - new API resources for `tigera`\n   - new namespaces\n   - resources in the new namespaces\n5. Review the CRDs manifest file and ensure matching `cidr`, then install\n6. Confirm resources added:\n   - new `Installation` resource\n   - new namespaces\n   - resources in the new namespaces (Calico Pods take awhile to enter `Running` status)\n\n</div>\n\n### StatefulSets\n\n[StatefulSet](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/) is similar to Deployments but provides guarantees about the ordering and uniqueness of managed Pods. Unlike Deployments, StatefulSet Pods are not interchangeable: each has a persistent identifier and storage volume that it maintains across any rescheduling.\n\n#### Using StatefulSets\n\nStatefulSets are valuable for applications that require one or more of the following.\n\n- Stable - persistence across Pod (re)scheduling, unique network identifiers.\n- Stable, persistent storage.\n- Ordered, graceful deployment and scaling.\n- Ordered, automated rolling updates.\n\n#### Limitations of StatefulSets\n\n- Storage must either be provisioned by a [PersistentVolume Provisioner]() based on StorageClass, or pre-provisioned by an admin\n- To ensure data safety, deleting and/or scaling a StatefulSet down will not delete associated volumes\n- You are responsible for creating a [Headless Service](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services) to provide network access to the Pods\n- To achieve ordered and graceful termination of Pods, scale the StatefulSet down to 0 prior to deletion\n- It's possible to get into a broken state that requires [manual repair](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#forced-rollback) when using [Rolling Updates](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#rolling-updates) with the default [Pod Management Policy](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies) (`OrderedReady`)\n\n<div id=\"lab14-6\">\n\n### Lab 14.6. Components of a StatefulSet\n\nSee the [example manifest](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#components)\n\n1. Create a StatefulSet based on the example manifest\n2. Verify resources created and compare to a regular deployment\n3. Confirm persistent volume claims created\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n<div id=\"task14-1\">\n\n### Task - Helm\n\nComing soon, accepting pull-requests\n\n</div>\n\n<div style=\"page-break-after: always;\"></div>\n\n## 15. Exam\n\nIn the [Certified Kubernetes Application Developer (CKAD)](https://training.linuxfoundation.org/certification/certified-kubernetes-application-developer-ckad/) exam, you are expected to solve about 15 questions in 2 hours. What makes this exam difficult is the time required to verify all your answers. Just providing a solution to a question is not enough, you must always test that your solutions work as expected, otherwise, you are guaranteed to fail.\n\nPlease read through the [kubectl cheat sheet](https://kubernetes.io/docs/reference/kubectl/cheatsheet/) before taking the exam.\n\n### Exam simulation\n\nThe _Tasks_ provided in this bootcamp require more time to solve than standard exam question, which makes them more difficult. Therefore, you can simulate an exam by completing all _Tasks_ under 2 hours.\n\nIn addition, after paying for the exam, you will be provided access to an exam simulation from [Killer.sh](https://killer.sh/) which you can attempt twice. The simulation environment will be similar to the exam environment, and the questions are also similar in difficulty to exam questions. However, you will need to solve about 20 questions in the same time, which makes the simulation more difficult.\n\nIf you are able to complete all 16 _Tasks_ provided here under 2 hours, you will find that you are also able to complete Killer exam simulation under 2 hours. This is all the confidence you need to pass your CKAD exam, you really don't need anything else.\n\nRemember to use the rest of the tips below during your simulation!\n\n> Tasks: [Docker image](#task---docker-image) | [Pods](#task---pods) | [Pods II](#task---pods-ii) | [CronJobs](#task---cronjobs) | [Resources and Security Context](#task---resources-and-security-context) | [Deployment](#task---deployment) | [Service](#task---service) | [Service II](#task---service-ii) | [Ingress](#task---ingress) | [Network policy](#task---network-policy) | [Persistent volumes](#task---persistent-volumes) | [ConfigMap and Secrets](#task---configmap-and-secrets) | [Probes](#task---probes) | [Zero Downtime Updates](#task---zero-downtime-updates) | [Service account](#task---service-account) | [Helm](#task---helm)\n\n### Environment setup\n\nAs soon as your exam starts, you will want to setup `kubectl` and your chosen text editor as follows:\n\n1. Setup `kubectl`\n   ```sh\n   alias k=kubectl # this is usually preconfigured in exam\n   export dr=\"--dry-run=client -oyaml\"\n   ```\n2. Setup text editor\n   ```sh\n   # vim\n   printf \"set tabstop=2\\nset shiftwidth=2\\nset expandtab\" > ~/.vimrc\n   # nano\n   printf \"set tabsize 2\\nset tabstospaces\" > ~/.nanorc\n   ```\n\nQuestions use different Clusters and different Namespaces. Therefore, for each question:\n\n1. Make sure you always run the command to switch to the Cluster for that question - command will be provided\n2. Create a variable for the question's Namespace `ns=$QUESTION_NAMESPACE` to make things easy for yourself\n3. Do not assume the default Namespace is `default`, always set and use your variable `ns=default`\n\n```sh\n# example using variable/alias\nk create deploy webapp --image=nginx:alpine $dr $ns > 2.yml\n```\n\n### Commandline copy-paste\n\nRemember that copy/paste works different in a terminal:\n\n- Copy - right click on mouse or two finger tap on touchpad (or check your touchpad settings if different)\n- Paste - right click on mouse or two finger tap on touchpad\n\n### Text editor proficiency\n\nGet familiar with your text editor to improve your speed:\n\n1. Use search and replace for bulk changes (assume `^C = Ctrl+C` and `M-C = Alt+C`)\n   - vim:\n     1. `:s/foo/bar/g` - find each `foo` in current line and replace with `bar`\n     2. `:s/foo/bar/g` - find each `foo` in all lines and replace with `bar`  \n   - nano:\n     1. press keyboard `^\\`\n     2. type search word and hit `Enter`\n     3. type replacement word and hit `Enter`\n     4. press `Y` to replace a match, `N` to skip a match, `A` to replace all matches\n2. Indent multiple lines using markers - in many situations, you might want to copy Pod YAML into a Deployment YAML or vice-versa\n   - vim (indent size = `shiftwidth`):\n     1. move cursor to the start/end of lines\n     2. press keyboard `V` to enter visual mode\n     3. press arrow keys up/down/left/right to highlight text in arrow direction\n     4. to indent highlighted text forwards, press `>` to indent once, or `3>` to indent 3 times\n     5. to indent highlighted text backwards, press `<` to indent once, or `4<` to indent 4 times\n   - nano (indent size = `tabsize`):\n     1. move cursor to the start/end of lines\n     2. press keyboard `M-A` to set mark\n     3. press arrow up/down/left/right to highlight text in arrow direction\n     4. to indent highlighted text, press `TAB` to indent forwards or `SHIFT+TAB` to indent backwards\n     5. press keyboard `M-A` again to unset mark\n3. Undo/Redo\n   - vim: in normal mode `:undo` to undo last change, `^R` to redo\n   - nano: `M-U` to undo, `M-E` to redo\n\n> This is not a bootcamp on `vim` or `nano`, there are more flashy magic you can achieve with these tools, especially `vim`, but the above should get you through CKAD!\n\n### Exam questions approach\n\nDo not begin your exam from Question 1! Each question has a _Task Weight_ and you should aim to complete higher score questions first.\n\nWhen your exam starts, and after going through the other setup above, you will want to **review all your questions** to create a _question-to-score-grid_ to help you decide the best order to answer them. See the scenarios below:\n\n```sh\n# scenario 1, 5-by-x grid to easily identify questions - lines ends in multiples of 5: Q5, Q10, Q15, etc\n4 4 4 8 4\n8 4 4 8 8\n4 8 8 8 8\n8\n# Start from Q9-Q16, then Q1-Q8\n```\n\n```sh\n# scenario 2, 5-by-x grid to easily identify questions - lines ends in multiples of 5: Q5, Q10, Q15, etc\n1 2 2 5 3\n7 4 4 5 4\n7 8 6 4 5\n6 4 4 9\n# Start from Q11-Q19, then Q4-Q10, then Q1-Q3\n```\n\nStore the grid in a Text Editor. When you encounter a troublesome question and its been more than 5mins without a clear idea of solution, update the question on the grid with an asterix and move on. Trust me, you do not want to waste additional 2mins on a question you will fail when you can answer another question in the same time!\n\n```sh\n# update troublesome questions with * and return to them after completing all other questions\n4 4 4 8 4\n8 4 4 8* 8\n4 8 8* 8 8\n8\n```\n\nBest of luck :+1: and please star [this repo](https://github.com/piouson/kubernetes-bootcamp) to say thank you!\n","url":"https://github.com/toluwalase09/kubernetes-bootcamp","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:16.340Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:16.340Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"Biottendance","title":"Biottendance","icon":null,"blueprint":"service","team":[],"properties":{"readme":"# Biottendance\nBIOmetrics aTTENDANCE (BIO-TTENDNCE) System Built With ESP32, Arduino and Python\n","url":"https://github.com/toluwalase09/Biottendance","language":null,"slack":null,"tier":null},"relations":{},"createdAt":"2024-11-07T11:22:16.435Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-07T11:22:16.435Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"SUCCESS","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":true}]},{"identifier":"usesSupportedLang","status":"FAILURE","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":false},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Bronze"}},"scorecardsStats":33.333,"scorecardsRuleCount":3},{"identifier":"savannah-tech","title":"savannah-tech","icon":null,"blueprint":"service","team":[],"properties":{"readme":null,"url":"https://github.com/toluwalase09/savannah-tech","language":"Python","slack":null,"tier":null},"relations":{},"createdAt":"2024-11-15T12:51:20.816Z","createdBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","updatedAt":"2024-11-15T20:35:55.687Z","updatedBy":"Cp8PAICHIMK0XKIcuNoe9vj9FiNclf1A","scorecards":{"ProductionReadiness":{"rules":[{"identifier":"hasReadme","status":"FAILURE","level":"Bronze","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"readme"},"result":false}]},{"identifier":"usesSupportedLang","status":"SUCCESS","level":"Silver","ruleResults":[{"condition":{"operator":"=","property":"language","value":"Python"},"result":true},{"condition":{"operator":"=","property":"language","value":"JavaScript"},"result":false},{"condition":{"operator":"=","property":"language","value":"React"},"result":false},{"condition":{"operator":"=","property":"language","value":"GoLang"},"result":false}]},{"identifier":"hasTeam","status":"FAILURE","level":"Gold","ruleResults":[{"condition":{"operator":"isNotEmpty","property":"$team"},"result":false}]}],"level":"Basic"}},"scorecardsStats":33.333,"scorecardsRuleCount":3}]}
